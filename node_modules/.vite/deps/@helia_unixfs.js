import {
  CustomProgressEvent,
  PQueue,
  ScalableCuckooFilter,
  Uint8ArrayList,
  code,
  code2,
  code3,
  decode2 as decode,
  decode3 as decode2,
  decode4 as decode3,
  decodeMessage,
  encode2 as encode,
  encodeMessage,
  enumeration,
  mergeOptions,
  message,
  parallel,
  prepare,
  src_default as src_default3,
  src_exports3 as src_exports
} from "./chunk-T5CRBQFB.js";
import {
  concat
} from "./chunk-BPCL3VPU.js";
import "./chunk-DYETMQ3U.js";
import "./chunk-GEK5MXOV.js";
import {
  pipe,
  pushable,
  src_default as src_default2,
  src_default2 as src_default4
} from "./chunk-U7AWOMBT.js";
import {
  logger,
  src_default3 as src_default
} from "./chunk-K7PRM5O7.js";
import {
  fromString
} from "./chunk-E7RDS3JU.js";
import "./chunk-I4N6U4EZ.js";
import "./chunk-BSIOSPHI.js";
import "./chunk-NJ2IMHHP.js";
import "./chunk-BIDMXIGI.js";
import "./chunk-HHC25657.js";
import "./chunk-2YJ6SRAI.js";
import "./chunk-FNOUKXXE.js";
import {
  __commonJS,
  __export,
  __toESM
} from "./chunk-QEK2ZTOW.js";

// node_modules/murmurhash3js-revisited/lib/murmurHash3js.js
var require_murmurHash3js = __commonJS({
  "node_modules/murmurhash3js-revisited/lib/murmurHash3js.js"(exports, module) {
    (function(root, undefined2) {
      "use strict";
      var library = {
        "version": "3.0.0",
        "x86": {},
        "x64": {},
        "inputValidation": true
      };
      function _validBytes(bytes) {
        if (!Array.isArray(bytes) && !ArrayBuffer.isView(bytes)) {
          return false;
        }
        for (var i = 0; i < bytes.length; i++) {
          if (!Number.isInteger(bytes[i]) || bytes[i] < 0 || bytes[i] > 255) {
            return false;
          }
        }
        return true;
      }
      function _x86Multiply(m, n) {
        return (m & 65535) * n + (((m >>> 16) * n & 65535) << 16);
      }
      function _x86Rotl(m, n) {
        return m << n | m >>> 32 - n;
      }
      function _x86Fmix(h) {
        h ^= h >>> 16;
        h = _x86Multiply(h, 2246822507);
        h ^= h >>> 13;
        h = _x86Multiply(h, 3266489909);
        h ^= h >>> 16;
        return h;
      }
      function _x64Add(m, n) {
        m = [m[0] >>> 16, m[0] & 65535, m[1] >>> 16, m[1] & 65535];
        n = [n[0] >>> 16, n[0] & 65535, n[1] >>> 16, n[1] & 65535];
        var o = [0, 0, 0, 0];
        o[3] += m[3] + n[3];
        o[2] += o[3] >>> 16;
        o[3] &= 65535;
        o[2] += m[2] + n[2];
        o[1] += o[2] >>> 16;
        o[2] &= 65535;
        o[1] += m[1] + n[1];
        o[0] += o[1] >>> 16;
        o[1] &= 65535;
        o[0] += m[0] + n[0];
        o[0] &= 65535;
        return [o[0] << 16 | o[1], o[2] << 16 | o[3]];
      }
      function _x64Multiply(m, n) {
        m = [m[0] >>> 16, m[0] & 65535, m[1] >>> 16, m[1] & 65535];
        n = [n[0] >>> 16, n[0] & 65535, n[1] >>> 16, n[1] & 65535];
        var o = [0, 0, 0, 0];
        o[3] += m[3] * n[3];
        o[2] += o[3] >>> 16;
        o[3] &= 65535;
        o[2] += m[2] * n[3];
        o[1] += o[2] >>> 16;
        o[2] &= 65535;
        o[2] += m[3] * n[2];
        o[1] += o[2] >>> 16;
        o[2] &= 65535;
        o[1] += m[1] * n[3];
        o[0] += o[1] >>> 16;
        o[1] &= 65535;
        o[1] += m[2] * n[2];
        o[0] += o[1] >>> 16;
        o[1] &= 65535;
        o[1] += m[3] * n[1];
        o[0] += o[1] >>> 16;
        o[1] &= 65535;
        o[0] += m[0] * n[3] + m[1] * n[2] + m[2] * n[1] + m[3] * n[0];
        o[0] &= 65535;
        return [o[0] << 16 | o[1], o[2] << 16 | o[3]];
      }
      function _x64Rotl(m, n) {
        n %= 64;
        if (n === 32) {
          return [m[1], m[0]];
        } else if (n < 32) {
          return [m[0] << n | m[1] >>> 32 - n, m[1] << n | m[0] >>> 32 - n];
        } else {
          n -= 32;
          return [m[1] << n | m[0] >>> 32 - n, m[0] << n | m[1] >>> 32 - n];
        }
      }
      function _x64LeftShift(m, n) {
        n %= 64;
        if (n === 0) {
          return m;
        } else if (n < 32) {
          return [m[0] << n | m[1] >>> 32 - n, m[1] << n];
        } else {
          return [m[1] << n - 32, 0];
        }
      }
      function _x64Xor(m, n) {
        return [m[0] ^ n[0], m[1] ^ n[1]];
      }
      function _x64Fmix(h) {
        h = _x64Xor(h, [0, h[0] >>> 1]);
        h = _x64Multiply(h, [4283543511, 3981806797]);
        h = _x64Xor(h, [0, h[0] >>> 1]);
        h = _x64Multiply(h, [3301882366, 444984403]);
        h = _x64Xor(h, [0, h[0] >>> 1]);
        return h;
      }
      library.x86.hash32 = function(bytes, seed) {
        if (library.inputValidation && !_validBytes(bytes)) {
          return undefined2;
        }
        seed = seed || 0;
        var remainder = bytes.length % 4;
        var blocks = bytes.length - remainder;
        var h1 = seed;
        var k1 = 0;
        var c1 = 3432918353;
        var c2 = 461845907;
        for (var i = 0; i < blocks; i = i + 4) {
          k1 = bytes[i] | bytes[i + 1] << 8 | bytes[i + 2] << 16 | bytes[i + 3] << 24;
          k1 = _x86Multiply(k1, c1);
          k1 = _x86Rotl(k1, 15);
          k1 = _x86Multiply(k1, c2);
          h1 ^= k1;
          h1 = _x86Rotl(h1, 13);
          h1 = _x86Multiply(h1, 5) + 3864292196;
        }
        k1 = 0;
        switch (remainder) {
          case 3:
            k1 ^= bytes[i + 2] << 16;
          case 2:
            k1 ^= bytes[i + 1] << 8;
          case 1:
            k1 ^= bytes[i];
            k1 = _x86Multiply(k1, c1);
            k1 = _x86Rotl(k1, 15);
            k1 = _x86Multiply(k1, c2);
            h1 ^= k1;
        }
        h1 ^= bytes.length;
        h1 = _x86Fmix(h1);
        return h1 >>> 0;
      };
      library.x86.hash128 = function(bytes, seed) {
        if (library.inputValidation && !_validBytes(bytes)) {
          return undefined2;
        }
        seed = seed || 0;
        var remainder = bytes.length % 16;
        var blocks = bytes.length - remainder;
        var h1 = seed;
        var h2 = seed;
        var h3 = seed;
        var h4 = seed;
        var k1 = 0;
        var k2 = 0;
        var k3 = 0;
        var k4 = 0;
        var c1 = 597399067;
        var c2 = 2869860233;
        var c3 = 951274213;
        var c4 = 2716044179;
        for (var i = 0; i < blocks; i = i + 16) {
          k1 = bytes[i] | bytes[i + 1] << 8 | bytes[i + 2] << 16 | bytes[i + 3] << 24;
          k2 = bytes[i + 4] | bytes[i + 5] << 8 | bytes[i + 6] << 16 | bytes[i + 7] << 24;
          k3 = bytes[i + 8] | bytes[i + 9] << 8 | bytes[i + 10] << 16 | bytes[i + 11] << 24;
          k4 = bytes[i + 12] | bytes[i + 13] << 8 | bytes[i + 14] << 16 | bytes[i + 15] << 24;
          k1 = _x86Multiply(k1, c1);
          k1 = _x86Rotl(k1, 15);
          k1 = _x86Multiply(k1, c2);
          h1 ^= k1;
          h1 = _x86Rotl(h1, 19);
          h1 += h2;
          h1 = _x86Multiply(h1, 5) + 1444728091;
          k2 = _x86Multiply(k2, c2);
          k2 = _x86Rotl(k2, 16);
          k2 = _x86Multiply(k2, c3);
          h2 ^= k2;
          h2 = _x86Rotl(h2, 17);
          h2 += h3;
          h2 = _x86Multiply(h2, 5) + 197830471;
          k3 = _x86Multiply(k3, c3);
          k3 = _x86Rotl(k3, 17);
          k3 = _x86Multiply(k3, c4);
          h3 ^= k3;
          h3 = _x86Rotl(h3, 15);
          h3 += h4;
          h3 = _x86Multiply(h3, 5) + 2530024501;
          k4 = _x86Multiply(k4, c4);
          k4 = _x86Rotl(k4, 18);
          k4 = _x86Multiply(k4, c1);
          h4 ^= k4;
          h4 = _x86Rotl(h4, 13);
          h4 += h1;
          h4 = _x86Multiply(h4, 5) + 850148119;
        }
        k1 = 0;
        k2 = 0;
        k3 = 0;
        k4 = 0;
        switch (remainder) {
          case 15:
            k4 ^= bytes[i + 14] << 16;
          case 14:
            k4 ^= bytes[i + 13] << 8;
          case 13:
            k4 ^= bytes[i + 12];
            k4 = _x86Multiply(k4, c4);
            k4 = _x86Rotl(k4, 18);
            k4 = _x86Multiply(k4, c1);
            h4 ^= k4;
          case 12:
            k3 ^= bytes[i + 11] << 24;
          case 11:
            k3 ^= bytes[i + 10] << 16;
          case 10:
            k3 ^= bytes[i + 9] << 8;
          case 9:
            k3 ^= bytes[i + 8];
            k3 = _x86Multiply(k3, c3);
            k3 = _x86Rotl(k3, 17);
            k3 = _x86Multiply(k3, c4);
            h3 ^= k3;
          case 8:
            k2 ^= bytes[i + 7] << 24;
          case 7:
            k2 ^= bytes[i + 6] << 16;
          case 6:
            k2 ^= bytes[i + 5] << 8;
          case 5:
            k2 ^= bytes[i + 4];
            k2 = _x86Multiply(k2, c2);
            k2 = _x86Rotl(k2, 16);
            k2 = _x86Multiply(k2, c3);
            h2 ^= k2;
          case 4:
            k1 ^= bytes[i + 3] << 24;
          case 3:
            k1 ^= bytes[i + 2] << 16;
          case 2:
            k1 ^= bytes[i + 1] << 8;
          case 1:
            k1 ^= bytes[i];
            k1 = _x86Multiply(k1, c1);
            k1 = _x86Rotl(k1, 15);
            k1 = _x86Multiply(k1, c2);
            h1 ^= k1;
        }
        h1 ^= bytes.length;
        h2 ^= bytes.length;
        h3 ^= bytes.length;
        h4 ^= bytes.length;
        h1 += h2;
        h1 += h3;
        h1 += h4;
        h2 += h1;
        h3 += h1;
        h4 += h1;
        h1 = _x86Fmix(h1);
        h2 = _x86Fmix(h2);
        h3 = _x86Fmix(h3);
        h4 = _x86Fmix(h4);
        h1 += h2;
        h1 += h3;
        h1 += h4;
        h2 += h1;
        h3 += h1;
        h4 += h1;
        return ("00000000" + (h1 >>> 0).toString(16)).slice(-8) + ("00000000" + (h2 >>> 0).toString(16)).slice(-8) + ("00000000" + (h3 >>> 0).toString(16)).slice(-8) + ("00000000" + (h4 >>> 0).toString(16)).slice(-8);
      };
      library.x64.hash128 = function(bytes, seed) {
        if (library.inputValidation && !_validBytes(bytes)) {
          return undefined2;
        }
        seed = seed || 0;
        var remainder = bytes.length % 16;
        var blocks = bytes.length - remainder;
        var h1 = [0, seed];
        var h2 = [0, seed];
        var k1 = [0, 0];
        var k2 = [0, 0];
        var c1 = [2277735313, 289559509];
        var c2 = [1291169091, 658871167];
        for (var i = 0; i < blocks; i = i + 16) {
          k1 = [bytes[i + 4] | bytes[i + 5] << 8 | bytes[i + 6] << 16 | bytes[i + 7] << 24, bytes[i] | bytes[i + 1] << 8 | bytes[i + 2] << 16 | bytes[i + 3] << 24];
          k2 = [bytes[i + 12] | bytes[i + 13] << 8 | bytes[i + 14] << 16 | bytes[i + 15] << 24, bytes[i + 8] | bytes[i + 9] << 8 | bytes[i + 10] << 16 | bytes[i + 11] << 24];
          k1 = _x64Multiply(k1, c1);
          k1 = _x64Rotl(k1, 31);
          k1 = _x64Multiply(k1, c2);
          h1 = _x64Xor(h1, k1);
          h1 = _x64Rotl(h1, 27);
          h1 = _x64Add(h1, h2);
          h1 = _x64Add(_x64Multiply(h1, [0, 5]), [0, 1390208809]);
          k2 = _x64Multiply(k2, c2);
          k2 = _x64Rotl(k2, 33);
          k2 = _x64Multiply(k2, c1);
          h2 = _x64Xor(h2, k2);
          h2 = _x64Rotl(h2, 31);
          h2 = _x64Add(h2, h1);
          h2 = _x64Add(_x64Multiply(h2, [0, 5]), [0, 944331445]);
        }
        k1 = [0, 0];
        k2 = [0, 0];
        switch (remainder) {
          case 15:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 14]], 48));
          case 14:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 13]], 40));
          case 13:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 12]], 32));
          case 12:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 11]], 24));
          case 11:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 10]], 16));
          case 10:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 9]], 8));
          case 9:
            k2 = _x64Xor(k2, [0, bytes[i + 8]]);
            k2 = _x64Multiply(k2, c2);
            k2 = _x64Rotl(k2, 33);
            k2 = _x64Multiply(k2, c1);
            h2 = _x64Xor(h2, k2);
          case 8:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 7]], 56));
          case 7:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 6]], 48));
          case 6:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 5]], 40));
          case 5:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 4]], 32));
          case 4:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 3]], 24));
          case 3:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 2]], 16));
          case 2:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 1]], 8));
          case 1:
            k1 = _x64Xor(k1, [0, bytes[i]]);
            k1 = _x64Multiply(k1, c1);
            k1 = _x64Rotl(k1, 31);
            k1 = _x64Multiply(k1, c2);
            h1 = _x64Xor(h1, k1);
        }
        h1 = _x64Xor(h1, [0, bytes.length]);
        h2 = _x64Xor(h2, [0, bytes.length]);
        h1 = _x64Add(h1, h2);
        h2 = _x64Add(h2, h1);
        h1 = _x64Fmix(h1);
        h2 = _x64Fmix(h2);
        h1 = _x64Add(h1, h2);
        h2 = _x64Add(h2, h1);
        return ("00000000" + (h1[0] >>> 0).toString(16)).slice(-8) + ("00000000" + (h1[1] >>> 0).toString(16)).slice(-8) + ("00000000" + (h2[0] >>> 0).toString(16)).slice(-8) + ("00000000" + (h2[1] >>> 0).toString(16)).slice(-8);
      };
      if (typeof exports !== "undefined") {
        if (typeof module !== "undefined" && module.exports) {
          exports = module.exports = library;
        }
        exports.murmurHash3 = library;
      } else if (typeof define === "function" && define.amd) {
        define([], function() {
          return library;
        });
      } else {
        library._murmurHash3 = root.murmurHash3;
        library.noConflict = function() {
          root.murmurHash3 = library._murmurHash3;
          library._murmurHash3 = undefined2;
          library.noConflict = undefined2;
          return library;
        };
        root.murmurHash3 = library;
      }
    })(exports);
  }
});

// node_modules/murmurhash3js-revisited/index.js
var require_murmurhash3js_revisited = __commonJS({
  "node_modules/murmurhash3js-revisited/index.js"(exports, module) {
    module.exports = require_murmurHash3js();
  }
});

// node_modules/sparse-array/index.js
var require_sparse_array = __commonJS({
  "node_modules/sparse-array/index.js"(exports, module) {
    "use strict";
    var BITS_PER_BYTE = 7;
    module.exports = class SparseArray {
      constructor() {
        this._bitArrays = [];
        this._data = [];
        this._length = 0;
        this._changedLength = false;
        this._changedData = false;
      }
      set(index, value) {
        let pos = this._internalPositionFor(index, false);
        if (value === void 0) {
          if (pos !== -1) {
            this._unsetInternalPos(pos);
            this._unsetBit(index);
            this._changedLength = true;
            this._changedData = true;
          }
        } else {
          let needsSort = false;
          if (pos === -1) {
            pos = this._data.length;
            this._setBit(index);
            this._changedData = true;
          } else {
            needsSort = true;
          }
          this._setInternalPos(pos, index, value, needsSort);
          this._changedLength = true;
        }
      }
      unset(index) {
        this.set(index, void 0);
      }
      get(index) {
        this._sortData();
        const pos = this._internalPositionFor(index, true);
        if (pos === -1) {
          return void 0;
        }
        return this._data[pos][1];
      }
      push(value) {
        this.set(this.length, value);
        return this.length;
      }
      get length() {
        this._sortData();
        if (this._changedLength) {
          const last2 = this._data[this._data.length - 1];
          this._length = last2 ? last2[0] + 1 : 0;
          this._changedLength = false;
        }
        return this._length;
      }
      forEach(iterator) {
        let i = 0;
        while (i < this.length) {
          iterator(this.get(i), i, this);
          i++;
        }
      }
      map(iterator) {
        let i = 0;
        let mapped = new Array(this.length);
        while (i < this.length) {
          mapped[i] = iterator(this.get(i), i, this);
          i++;
        }
        return mapped;
      }
      reduce(reducer, initialValue) {
        let i = 0;
        let acc = initialValue;
        while (i < this.length) {
          const value = this.get(i);
          acc = reducer(acc, value, i);
          i++;
        }
        return acc;
      }
      find(finder) {
        let i = 0, found, last2;
        while (i < this.length && !found) {
          last2 = this.get(i);
          found = finder(last2);
          i++;
        }
        return found ? last2 : void 0;
      }
      _internalPositionFor(index, noCreate) {
        const bytePos = this._bytePosFor(index, noCreate);
        if (bytePos >= this._bitArrays.length) {
          return -1;
        }
        const byte = this._bitArrays[bytePos];
        const bitPos = index - bytePos * BITS_PER_BYTE;
        const exists2 = (byte & 1 << bitPos) > 0;
        if (!exists2) {
          return -1;
        }
        const previousPopCount = this._bitArrays.slice(0, bytePos).reduce(popCountReduce, 0);
        const mask = ~(4294967295 << bitPos + 1);
        const bytePopCount = popCount(byte & mask);
        const arrayPos = previousPopCount + bytePopCount - 1;
        return arrayPos;
      }
      _bytePosFor(index, noCreate) {
        const bytePos = Math.floor(index / BITS_PER_BYTE);
        const targetLength = bytePos + 1;
        while (!noCreate && this._bitArrays.length < targetLength) {
          this._bitArrays.push(0);
        }
        return bytePos;
      }
      _setBit(index) {
        const bytePos = this._bytePosFor(index, false);
        this._bitArrays[bytePos] |= 1 << index - bytePos * BITS_PER_BYTE;
      }
      _unsetBit(index) {
        const bytePos = this._bytePosFor(index, false);
        this._bitArrays[bytePos] &= ~(1 << index - bytePos * BITS_PER_BYTE);
      }
      _setInternalPos(pos, index, value, needsSort) {
        const data = this._data;
        const elem = [index, value];
        if (needsSort) {
          this._sortData();
          data[pos] = elem;
        } else {
          if (data.length) {
            if (data[data.length - 1][0] >= index) {
              data.push(elem);
            } else if (data[0][0] <= index) {
              data.unshift(elem);
            } else {
              const randomIndex = Math.round(data.length / 2);
              this._data = data.slice(0, randomIndex).concat(elem).concat(data.slice(randomIndex));
            }
          } else {
            this._data.push(elem);
          }
          this._changedData = true;
          this._changedLength = true;
        }
      }
      _unsetInternalPos(pos) {
        this._data.splice(pos, 1);
      }
      _sortData() {
        if (this._changedData) {
          this._data.sort(sortInternal);
        }
        this._changedData = false;
      }
      bitField() {
        const bytes = [];
        let pendingBitsForResultingByte = 8;
        let pendingBitsForNewByte = 0;
        let resultingByte = 0;
        let newByte;
        const pending = this._bitArrays.slice();
        while (pending.length || pendingBitsForNewByte) {
          if (pendingBitsForNewByte === 0) {
            newByte = pending.shift();
            pendingBitsForNewByte = 7;
          }
          const usingBits = Math.min(pendingBitsForNewByte, pendingBitsForResultingByte);
          const mask = ~(255 << usingBits);
          const masked = newByte & mask;
          resultingByte |= masked << 8 - pendingBitsForResultingByte;
          newByte = newByte >>> usingBits;
          pendingBitsForNewByte -= usingBits;
          pendingBitsForResultingByte -= usingBits;
          if (!pendingBitsForResultingByte || !pendingBitsForNewByte && !pending.length) {
            bytes.push(resultingByte);
            resultingByte = 0;
            pendingBitsForResultingByte = 8;
          }
        }
        for (var i = bytes.length - 1; i > 0; i--) {
          const value = bytes[i];
          if (value === 0) {
            bytes.pop();
          } else {
            break;
          }
        }
        return bytes;
      }
      compactArray() {
        this._sortData();
        return this._data.map(valueOnly);
      }
    };
    function popCountReduce(count, byte) {
      return count + popCount(byte);
    }
    function popCount(_v) {
      let v = _v;
      v = v - (v >> 1 & 1431655765);
      v = (v & 858993459) + (v >> 2 & 858993459);
      return (v + (v >> 4) & 252645135) * 16843009 >> 24;
    }
    function sortInternal(a, b) {
      return a[0] - b[0];
    }
    function valueOnly(elem) {
      return elem[1];
    }
  }
});

// node_modules/rabin-wasm/src/rabin.js
var require_rabin = __commonJS({
  "node_modules/rabin-wasm/src/rabin.js"(exports, module) {
    var Rabin = class {
      /**
       * Creates an instance of Rabin.
       * @param { import("./../dist/rabin-wasm") } asModule
       * @param {number} [bits=12]
       * @param {number} [min=8 * 1024]
       * @param {number} [max=32 * 1024]
       * @param {number} polynomial
       * @memberof Rabin
       */
      constructor(asModule, bits = 12, min = 8 * 1024, max = 32 * 1024, windowSize = 64, polynomial) {
        this.bits = bits;
        this.min = min;
        this.max = max;
        this.asModule = asModule;
        this.rabin = new asModule.Rabin(bits, min, max, windowSize, polynomial);
        this.polynomial = polynomial;
      }
      /**
       * Fingerprints the buffer
       *
       * @param {Uint8Array} buf
       * @returns {Array<number>}
       * @memberof Rabin
       */
      fingerprint(buf) {
        const {
          __retain,
          __release,
          __allocArray,
          __getInt32Array,
          Int32Array_ID,
          Uint8Array_ID
        } = this.asModule;
        const lengths = new Int32Array(Math.ceil(buf.length / this.min));
        const lengthsPtr = __retain(__allocArray(Int32Array_ID, lengths));
        const pointer = __retain(__allocArray(Uint8Array_ID, buf));
        const out = this.rabin.fingerprint(pointer, lengthsPtr);
        const processed = __getInt32Array(out);
        __release(pointer);
        __release(lengthsPtr);
        const end = processed.indexOf(0);
        return end >= 0 ? processed.subarray(0, end) : processed;
      }
    };
    module.exports = Rabin;
  }
});

// node_modules/@assemblyscript/loader/index.js
var require_loader = __commonJS({
  "node_modules/@assemblyscript/loader/index.js"(exports) {
    "use strict";
    var ID_OFFSET = -8;
    var SIZE_OFFSET = -4;
    var ARRAYBUFFER_ID = 0;
    var STRING_ID = 1;
    var ARRAYBUFFERVIEW = 1 << 0;
    var ARRAY = 1 << 1;
    var SET = 1 << 2;
    var MAP = 1 << 3;
    var VAL_ALIGN_OFFSET = 5;
    var VAL_ALIGN = 1 << VAL_ALIGN_OFFSET;
    var VAL_SIGNED = 1 << 10;
    var VAL_FLOAT = 1 << 11;
    var VAL_NULLABLE = 1 << 12;
    var VAL_MANAGED = 1 << 13;
    var KEY_ALIGN_OFFSET = 14;
    var KEY_ALIGN = 1 << KEY_ALIGN_OFFSET;
    var KEY_SIGNED = 1 << 19;
    var KEY_FLOAT = 1 << 20;
    var KEY_NULLABLE = 1 << 21;
    var KEY_MANAGED = 1 << 22;
    var ARRAYBUFFERVIEW_BUFFER_OFFSET = 0;
    var ARRAYBUFFERVIEW_DATASTART_OFFSET = 4;
    var ARRAYBUFFERVIEW_DATALENGTH_OFFSET = 8;
    var ARRAYBUFFERVIEW_SIZE = 12;
    var ARRAY_LENGTH_OFFSET = 12;
    var ARRAY_SIZE = 16;
    var BIGINT = typeof BigUint64Array !== "undefined";
    var THIS = Symbol();
    var CHUNKSIZE = 1024;
    function getStringImpl(buffer, ptr) {
      const U32 = new Uint32Array(buffer);
      const U16 = new Uint16Array(buffer);
      var length5 = U32[ptr + SIZE_OFFSET >>> 2] >>> 1;
      var offset = ptr >>> 1;
      if (length5 <= CHUNKSIZE) return String.fromCharCode.apply(String, U16.subarray(offset, offset + length5));
      const parts = [];
      do {
        const last2 = U16[offset + CHUNKSIZE - 1];
        const size = last2 >= 55296 && last2 < 56320 ? CHUNKSIZE - 1 : CHUNKSIZE;
        parts.push(String.fromCharCode.apply(String, U16.subarray(offset, offset += size)));
        length5 -= size;
      } while (length5 > CHUNKSIZE);
      return parts.join("") + String.fromCharCode.apply(String, U16.subarray(offset, offset + length5));
    }
    function preInstantiate(imports) {
      const baseModule = {};
      function getString(memory, ptr) {
        if (!memory) return "<yet unknown>";
        return getStringImpl(memory.buffer, ptr);
      }
      const env = imports.env = imports.env || {};
      env.abort = env.abort || function abort(mesg, file, line, colm) {
        const memory = baseModule.memory || env.memory;
        throw Error("abort: " + getString(memory, mesg) + " at " + getString(memory, file) + ":" + line + ":" + colm);
      };
      env.trace = env.trace || function trace(mesg, n) {
        const memory = baseModule.memory || env.memory;
        console.log("trace: " + getString(memory, mesg) + (n ? " " : "") + Array.prototype.slice.call(arguments, 2, 2 + n).join(", "));
      };
      imports.Math = imports.Math || Math;
      imports.Date = imports.Date || Date;
      return baseModule;
    }
    function postInstantiate(baseModule, instance) {
      const rawExports = instance.exports;
      const memory = rawExports.memory;
      const table = rawExports.table;
      const alloc = rawExports["__alloc"];
      const retain = rawExports["__retain"];
      const rttiBase = rawExports["__rtti_base"] || ~0;
      function getInfo(id) {
        const U32 = new Uint32Array(memory.buffer);
        const count = U32[rttiBase >>> 2];
        if ((id >>>= 0) >= count) throw Error("invalid id: " + id);
        return U32[(rttiBase + 4 >>> 2) + id * 2];
      }
      function getBase(id) {
        const U32 = new Uint32Array(memory.buffer);
        const count = U32[rttiBase >>> 2];
        if ((id >>>= 0) >= count) throw Error("invalid id: " + id);
        return U32[(rttiBase + 4 >>> 2) + id * 2 + 1];
      }
      function getValueAlign(info) {
        return 31 - Math.clz32(info >>> VAL_ALIGN_OFFSET & 31);
      }
      function getKeyAlign(info) {
        return 31 - Math.clz32(info >>> KEY_ALIGN_OFFSET & 31);
      }
      function __allocString(str) {
        const length5 = str.length;
        const ptr = alloc(length5 << 1, STRING_ID);
        const U16 = new Uint16Array(memory.buffer);
        for (var i = 0, p = ptr >>> 1; i < length5; ++i) U16[p + i] = str.charCodeAt(i);
        return ptr;
      }
      baseModule.__allocString = __allocString;
      function __getString(ptr) {
        const buffer = memory.buffer;
        const id = new Uint32Array(buffer)[ptr + ID_OFFSET >>> 2];
        if (id !== STRING_ID) throw Error("not a string: " + ptr);
        return getStringImpl(buffer, ptr);
      }
      baseModule.__getString = __getString;
      function getView(alignLog2, signed, float) {
        const buffer = memory.buffer;
        if (float) {
          switch (alignLog2) {
            case 2:
              return new Float32Array(buffer);
            case 3:
              return new Float64Array(buffer);
          }
        } else {
          switch (alignLog2) {
            case 0:
              return new (signed ? Int8Array : Uint8Array)(buffer);
            case 1:
              return new (signed ? Int16Array : Uint16Array)(buffer);
            case 2:
              return new (signed ? Int32Array : Uint32Array)(buffer);
            case 3:
              return new (signed ? BigInt64Array : BigUint64Array)(buffer);
          }
        }
        throw Error("unsupported align: " + alignLog2);
      }
      function __allocArray(id, values) {
        const info = getInfo(id);
        if (!(info & (ARRAYBUFFERVIEW | ARRAY))) throw Error("not an array: " + id + " @ " + info);
        const align = getValueAlign(info);
        const length5 = values.length;
        const buf = alloc(length5 << align, ARRAYBUFFER_ID);
        const arr = alloc(info & ARRAY ? ARRAY_SIZE : ARRAYBUFFERVIEW_SIZE, id);
        const U32 = new Uint32Array(memory.buffer);
        U32[arr + ARRAYBUFFERVIEW_BUFFER_OFFSET >>> 2] = retain(buf);
        U32[arr + ARRAYBUFFERVIEW_DATASTART_OFFSET >>> 2] = buf;
        U32[arr + ARRAYBUFFERVIEW_DATALENGTH_OFFSET >>> 2] = length5 << align;
        if (info & ARRAY) U32[arr + ARRAY_LENGTH_OFFSET >>> 2] = length5;
        const view = getView(align, info & VAL_SIGNED, info & VAL_FLOAT);
        if (info & VAL_MANAGED) {
          for (let i = 0; i < length5; ++i) view[(buf >>> align) + i] = retain(values[i]);
        } else {
          view.set(values, buf >>> align);
        }
        return arr;
      }
      baseModule.__allocArray = __allocArray;
      function __getArrayView(arr) {
        const U32 = new Uint32Array(memory.buffer);
        const id = U32[arr + ID_OFFSET >>> 2];
        const info = getInfo(id);
        if (!(info & ARRAYBUFFERVIEW)) throw Error("not an array: " + id);
        const align = getValueAlign(info);
        var buf = U32[arr + ARRAYBUFFERVIEW_DATASTART_OFFSET >>> 2];
        const length5 = info & ARRAY ? U32[arr + ARRAY_LENGTH_OFFSET >>> 2] : U32[buf + SIZE_OFFSET >>> 2] >>> align;
        return getView(align, info & VAL_SIGNED, info & VAL_FLOAT).subarray(buf >>>= align, buf + length5);
      }
      baseModule.__getArrayView = __getArrayView;
      function __getArray(arr) {
        const input = __getArrayView(arr);
        const len = input.length;
        const out = new Array(len);
        for (let i = 0; i < len; i++) out[i] = input[i];
        return out;
      }
      baseModule.__getArray = __getArray;
      function __getArrayBuffer(ptr) {
        const buffer = memory.buffer;
        const length5 = new Uint32Array(buffer)[ptr + SIZE_OFFSET >>> 2];
        return buffer.slice(ptr, ptr + length5);
      }
      baseModule.__getArrayBuffer = __getArrayBuffer;
      function getTypedArray(Type, alignLog2, ptr) {
        return new Type(getTypedArrayView(Type, alignLog2, ptr));
      }
      function getTypedArrayView(Type, alignLog2, ptr) {
        const buffer = memory.buffer;
        const U32 = new Uint32Array(buffer);
        const bufPtr = U32[ptr + ARRAYBUFFERVIEW_DATASTART_OFFSET >>> 2];
        return new Type(buffer, bufPtr, U32[bufPtr + SIZE_OFFSET >>> 2] >>> alignLog2);
      }
      baseModule.__getInt8Array = getTypedArray.bind(null, Int8Array, 0);
      baseModule.__getInt8ArrayView = getTypedArrayView.bind(null, Int8Array, 0);
      baseModule.__getUint8Array = getTypedArray.bind(null, Uint8Array, 0);
      baseModule.__getUint8ArrayView = getTypedArrayView.bind(null, Uint8Array, 0);
      baseModule.__getUint8ClampedArray = getTypedArray.bind(null, Uint8ClampedArray, 0);
      baseModule.__getUint8ClampedArrayView = getTypedArrayView.bind(null, Uint8ClampedArray, 0);
      baseModule.__getInt16Array = getTypedArray.bind(null, Int16Array, 1);
      baseModule.__getInt16ArrayView = getTypedArrayView.bind(null, Int16Array, 1);
      baseModule.__getUint16Array = getTypedArray.bind(null, Uint16Array, 1);
      baseModule.__getUint16ArrayView = getTypedArrayView.bind(null, Uint16Array, 1);
      baseModule.__getInt32Array = getTypedArray.bind(null, Int32Array, 2);
      baseModule.__getInt32ArrayView = getTypedArrayView.bind(null, Int32Array, 2);
      baseModule.__getUint32Array = getTypedArray.bind(null, Uint32Array, 2);
      baseModule.__getUint32ArrayView = getTypedArrayView.bind(null, Uint32Array, 2);
      if (BIGINT) {
        baseModule.__getInt64Array = getTypedArray.bind(null, BigInt64Array, 3);
        baseModule.__getInt64ArrayView = getTypedArrayView.bind(null, BigInt64Array, 3);
        baseModule.__getUint64Array = getTypedArray.bind(null, BigUint64Array, 3);
        baseModule.__getUint64ArrayView = getTypedArrayView.bind(null, BigUint64Array, 3);
      }
      baseModule.__getFloat32Array = getTypedArray.bind(null, Float32Array, 2);
      baseModule.__getFloat32ArrayView = getTypedArrayView.bind(null, Float32Array, 2);
      baseModule.__getFloat64Array = getTypedArray.bind(null, Float64Array, 3);
      baseModule.__getFloat64ArrayView = getTypedArrayView.bind(null, Float64Array, 3);
      function __instanceof(ptr, baseId) {
        const U32 = new Uint32Array(memory.buffer);
        var id = U32[ptr + ID_OFFSET >>> 2];
        if (id <= U32[rttiBase >>> 2]) {
          do
            if (id == baseId) return true;
          while (id = getBase(id));
        }
        return false;
      }
      baseModule.__instanceof = __instanceof;
      baseModule.memory = baseModule.memory || memory;
      baseModule.table = baseModule.table || table;
      return demangle(rawExports, baseModule);
    }
    function isResponse(o) {
      return typeof Response !== "undefined" && o instanceof Response;
    }
    async function instantiate(source, imports) {
      if (isResponse(source = await source)) return instantiateStreaming(source, imports);
      return postInstantiate(
        preInstantiate(imports || (imports = {})),
        await WebAssembly.instantiate(
          source instanceof WebAssembly.Module ? source : await WebAssembly.compile(source),
          imports
        )
      );
    }
    exports.instantiate = instantiate;
    function instantiateSync(source, imports) {
      return postInstantiate(
        preInstantiate(imports || (imports = {})),
        new WebAssembly.Instance(
          source instanceof WebAssembly.Module ? source : new WebAssembly.Module(source),
          imports
        )
      );
    }
    exports.instantiateSync = instantiateSync;
    async function instantiateStreaming(source, imports) {
      if (!WebAssembly.instantiateStreaming) {
        return instantiate(
          isResponse(source = await source) ? source.arrayBuffer() : source,
          imports
        );
      }
      return postInstantiate(
        preInstantiate(imports || (imports = {})),
        (await WebAssembly.instantiateStreaming(source, imports)).instance
      );
    }
    exports.instantiateStreaming = instantiateStreaming;
    function demangle(exports2, baseModule) {
      var module2 = baseModule ? Object.create(baseModule) : {};
      var setArgumentsLength = exports2["__argumentsLength"] ? function(length5) {
        exports2["__argumentsLength"].value = length5;
      } : exports2["__setArgumentsLength"] || exports2["__setargc"] || function() {
      };
      for (let internalName in exports2) {
        if (!Object.prototype.hasOwnProperty.call(exports2, internalName)) continue;
        const elem = exports2[internalName];
        let parts = internalName.split(".");
        let curr = module2;
        while (parts.length > 1) {
          let part = parts.shift();
          if (!Object.prototype.hasOwnProperty.call(curr, part)) curr[part] = {};
          curr = curr[part];
        }
        let name3 = parts[0];
        let hash = name3.indexOf("#");
        if (hash >= 0) {
          let className = name3.substring(0, hash);
          let classElem = curr[className];
          if (typeof classElem === "undefined" || !classElem.prototype) {
            let ctor = function(...args) {
              return ctor.wrap(ctor.prototype.constructor(0, ...args));
            };
            ctor.prototype = {
              valueOf: function valueOf() {
                return this[THIS];
              }
            };
            ctor.wrap = function(thisValue) {
              return Object.create(ctor.prototype, { [THIS]: { value: thisValue, writable: false } });
            };
            if (classElem) Object.getOwnPropertyNames(classElem).forEach(
              (name4) => Object.defineProperty(ctor, name4, Object.getOwnPropertyDescriptor(classElem, name4))
            );
            curr[className] = ctor;
          }
          name3 = name3.substring(hash + 1);
          curr = curr[className].prototype;
          if (/^(get|set):/.test(name3)) {
            if (!Object.prototype.hasOwnProperty.call(curr, name3 = name3.substring(4))) {
              let getter = exports2[internalName.replace("set:", "get:")];
              let setter = exports2[internalName.replace("get:", "set:")];
              Object.defineProperty(curr, name3, {
                get: function() {
                  return getter(this[THIS]);
                },
                set: function(value) {
                  setter(this[THIS], value);
                },
                enumerable: true
              });
            }
          } else {
            if (name3 === "constructor") {
              (curr[name3] = (...args) => {
                setArgumentsLength(args.length);
                return elem(...args);
              }).original = elem;
            } else {
              (curr[name3] = function(...args) {
                setArgumentsLength(args.length);
                return elem(this[THIS], ...args);
              }).original = elem;
            }
          }
        } else {
          if (/^(get|set):/.test(name3)) {
            if (!Object.prototype.hasOwnProperty.call(curr, name3 = name3.substring(4))) {
              Object.defineProperty(curr, name3, {
                get: exports2[internalName.replace("set:", "get:")],
                set: exports2[internalName.replace("get:", "set:")],
                enumerable: true
              });
            }
          } else if (typeof elem === "function" && elem !== setArgumentsLength) {
            (curr[name3] = (...args) => {
              setArgumentsLength(args.length);
              return elem(...args);
            }).original = elem;
          } else {
            curr[name3] = elem;
          }
        }
      }
      return module2;
    }
    exports.demangle = demangle;
  }
});

// node_modules/rabin-wasm/dist/rabin-wasm.js
var require_rabin_wasm = __commonJS({
  "node_modules/rabin-wasm/dist/rabin-wasm.js"(exports, module) {
    var { instantiate } = require_loader();
    loadWebAssembly.supported = typeof WebAssembly !== "undefined";
    function loadWebAssembly(imp = {}) {
      if (!loadWebAssembly.supported) return null;
      var wasm = new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 78, 14, 96, 2, 127, 126, 0, 96, 1, 127, 1, 126, 96, 2, 127, 127, 0, 96, 1, 127, 1, 127, 96, 1, 127, 0, 96, 2, 127, 127, 1, 127, 96, 3, 127, 127, 127, 1, 127, 96, 0, 0, 96, 3, 127, 127, 127, 0, 96, 0, 1, 127, 96, 4, 127, 127, 127, 127, 0, 96, 5, 127, 127, 127, 127, 127, 1, 127, 96, 1, 126, 1, 127, 96, 2, 126, 126, 1, 126, 2, 13, 1, 3, 101, 110, 118, 5, 97, 98, 111, 114, 116, 0, 10, 3, 54, 53, 2, 2, 8, 9, 3, 5, 2, 8, 6, 5, 3, 4, 2, 6, 9, 12, 13, 2, 5, 11, 3, 2, 3, 2, 3, 2, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 6, 7, 7, 4, 4, 5, 3, 1, 0, 1, 6, 47, 9, 127, 1, 65, 0, 11, 127, 1, 65, 0, 11, 127, 0, 65, 3, 11, 127, 0, 65, 4, 11, 127, 1, 65, 0, 11, 127, 1, 65, 0, 11, 127, 1, 65, 0, 11, 127, 0, 65, 240, 2, 11, 127, 0, 65, 6, 11, 7, 240, 5, 41, 6, 109, 101, 109, 111, 114, 121, 2, 0, 7, 95, 95, 97, 108, 108, 111, 99, 0, 10, 8, 95, 95, 114, 101, 116, 97, 105, 110, 0, 11, 9, 95, 95, 114, 101, 108, 101, 97, 115, 101, 0, 12, 9, 95, 95, 99, 111, 108, 108, 101, 99, 116, 0, 51, 11, 95, 95, 114, 116, 116, 105, 95, 98, 97, 115, 101, 3, 7, 13, 73, 110, 116, 51, 50, 65, 114, 114, 97, 121, 95, 73, 68, 3, 2, 13, 85, 105, 110, 116, 56, 65, 114, 114, 97, 121, 95, 73, 68, 3, 3, 6, 100, 101, 103, 114, 101, 101, 0, 16, 3, 109, 111, 100, 0, 17, 5, 82, 97, 98, 105, 110, 3, 8, 16, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 119, 105, 110, 100, 111, 119, 0, 21, 16, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 119, 105, 110, 100, 111, 119, 0, 22, 21, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 119, 105, 110, 100, 111, 119, 95, 115, 105, 122, 101, 0, 23, 21, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 119, 105, 110, 100, 111, 119, 95, 115, 105, 122, 101, 0, 24, 14, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 119, 112, 111, 115, 0, 25, 14, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 119, 112, 111, 115, 0, 26, 15, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 99, 111, 117, 110, 116, 0, 27, 15, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 99, 111, 117, 110, 116, 0, 28, 13, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 112, 111, 115, 0, 29, 13, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 112, 111, 115, 0, 30, 15, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 115, 116, 97, 114, 116, 0, 31, 15, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 115, 116, 97, 114, 116, 0, 32, 16, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 100, 105, 103, 101, 115, 116, 0, 33, 16, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 100, 105, 103, 101, 115, 116, 0, 34, 21, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 99, 104, 117, 110, 107, 95, 115, 116, 97, 114, 116, 0, 35, 21, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 99, 104, 117, 110, 107, 95, 115, 116, 97, 114, 116, 0, 36, 22, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 99, 104, 117, 110, 107, 95, 108, 101, 110, 103, 116, 104, 0, 37, 22, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 99, 104, 117, 110, 107, 95, 108, 101, 110, 103, 116, 104, 0, 38, 31, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 99, 104, 117, 110, 107, 95, 99, 117, 116, 95, 102, 105, 110, 103, 101, 114, 112, 114, 105, 110, 116, 0, 39, 31, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 99, 104, 117, 110, 107, 95, 99, 117, 116, 95, 102, 105, 110, 103, 101, 114, 112, 114, 105, 110, 116, 0, 40, 20, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 112, 111, 108, 121, 110, 111, 109, 105, 97, 108, 0, 41, 20, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 112, 111, 108, 121, 110, 111, 109, 105, 97, 108, 0, 42, 17, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 109, 105, 110, 115, 105, 122, 101, 0, 43, 17, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 109, 105, 110, 115, 105, 122, 101, 0, 44, 17, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 109, 97, 120, 115, 105, 122, 101, 0, 45, 17, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 109, 97, 120, 115, 105, 122, 101, 0, 46, 14, 82, 97, 98, 105, 110, 35, 103, 101, 116, 58, 109, 97, 115, 107, 0, 47, 14, 82, 97, 98, 105, 110, 35, 115, 101, 116, 58, 109, 97, 115, 107, 0, 48, 17, 82, 97, 98, 105, 110, 35, 99, 111, 110, 115, 116, 114, 117, 99, 116, 111, 114, 0, 20, 17, 82, 97, 98, 105, 110, 35, 102, 105, 110, 103, 101, 114, 112, 114, 105, 110, 116, 0, 49, 8, 1, 50, 10, 165, 31, 53, 199, 1, 1, 4, 127, 32, 1, 40, 2, 0, 65, 124, 113, 34, 2, 65, 128, 2, 73, 4, 127, 32, 2, 65, 4, 118, 33, 4, 65, 0, 5, 32, 2, 65, 31, 32, 2, 103, 107, 34, 3, 65, 4, 107, 118, 65, 16, 115, 33, 4, 32, 3, 65, 7, 107, 11, 33, 3, 32, 1, 40, 2, 20, 33, 2, 32, 1, 40, 2, 16, 34, 5, 4, 64, 32, 5, 32, 2, 54, 2, 20, 11, 32, 2, 4, 64, 32, 2, 32, 5, 54, 2, 16, 11, 32, 1, 32, 0, 32, 4, 32, 3, 65, 4, 116, 106, 65, 2, 116, 106, 40, 2, 96, 70, 4, 64, 32, 0, 32, 4, 32, 3, 65, 4, 116, 106, 65, 2, 116, 106, 32, 2, 54, 2, 96, 32, 2, 69, 4, 64, 32, 0, 32, 3, 65, 2, 116, 106, 32, 0, 32, 3, 65, 2, 116, 106, 40, 2, 4, 65, 1, 32, 4, 116, 65, 127, 115, 113, 34, 1, 54, 2, 4, 32, 1, 69, 4, 64, 32, 0, 32, 0, 40, 2, 0, 65, 1, 32, 3, 116, 65, 127, 115, 113, 54, 2, 0, 11, 11, 11, 11, 226, 2, 1, 6, 127, 32, 1, 40, 2, 0, 33, 3, 32, 1, 65, 16, 106, 32, 1, 40, 2, 0, 65, 124, 113, 106, 34, 4, 40, 2, 0, 34, 5, 65, 1, 113, 4, 64, 32, 3, 65, 124, 113, 65, 16, 106, 32, 5, 65, 124, 113, 106, 34, 2, 65, 240, 255, 255, 255, 3, 73, 4, 64, 32, 0, 32, 4, 16, 1, 32, 1, 32, 2, 32, 3, 65, 3, 113, 114, 34, 3, 54, 2, 0, 32, 1, 65, 16, 106, 32, 1, 40, 2, 0, 65, 124, 113, 106, 34, 4, 40, 2, 0, 33, 5, 11, 11, 32, 3, 65, 2, 113, 4, 64, 32, 1, 65, 4, 107, 40, 2, 0, 34, 2, 40, 2, 0, 34, 6, 65, 124, 113, 65, 16, 106, 32, 3, 65, 124, 113, 106, 34, 7, 65, 240, 255, 255, 255, 3, 73, 4, 64, 32, 0, 32, 2, 16, 1, 32, 2, 32, 7, 32, 6, 65, 3, 113, 114, 34, 3, 54, 2, 0, 32, 2, 33, 1, 11, 11, 32, 4, 32, 5, 65, 2, 114, 54, 2, 0, 32, 4, 65, 4, 107, 32, 1, 54, 2, 0, 32, 0, 32, 3, 65, 124, 113, 34, 2, 65, 128, 2, 73, 4, 127, 32, 2, 65, 4, 118, 33, 4, 65, 0, 5, 32, 2, 65, 31, 32, 2, 103, 107, 34, 2, 65, 4, 107, 118, 65, 16, 115, 33, 4, 32, 2, 65, 7, 107, 11, 34, 3, 65, 4, 116, 32, 4, 106, 65, 2, 116, 106, 40, 2, 96, 33, 2, 32, 1, 65, 0, 54, 2, 16, 32, 1, 32, 2, 54, 2, 20, 32, 2, 4, 64, 32, 2, 32, 1, 54, 2, 16, 11, 32, 0, 32, 4, 32, 3, 65, 4, 116, 106, 65, 2, 116, 106, 32, 1, 54, 2, 96, 32, 0, 32, 0, 40, 2, 0, 65, 1, 32, 3, 116, 114, 54, 2, 0, 32, 0, 32, 3, 65, 2, 116, 106, 32, 0, 32, 3, 65, 2, 116, 106, 40, 2, 4, 65, 1, 32, 4, 116, 114, 54, 2, 4, 11, 119, 1, 1, 127, 32, 2, 2, 127, 32, 0, 40, 2, 160, 12, 34, 2, 4, 64, 32, 2, 32, 1, 65, 16, 107, 70, 4, 64, 32, 2, 40, 2, 0, 33, 3, 32, 1, 65, 16, 107, 33, 1, 11, 11, 32, 1, 11, 107, 34, 2, 65, 48, 73, 4, 64, 15, 11, 32, 1, 32, 3, 65, 2, 113, 32, 2, 65, 32, 107, 65, 1, 114, 114, 54, 2, 0, 32, 1, 65, 0, 54, 2, 16, 32, 1, 65, 0, 54, 2, 20, 32, 1, 32, 2, 106, 65, 16, 107, 34, 2, 65, 2, 54, 2, 0, 32, 0, 32, 2, 54, 2, 160, 12, 32, 0, 32, 1, 16, 2, 11, 155, 1, 1, 3, 127, 35, 0, 34, 0, 69, 4, 64, 65, 1, 63, 0, 34, 0, 74, 4, 127, 65, 1, 32, 0, 107, 64, 0, 65, 0, 72, 5, 65, 0, 11, 4, 64, 0, 11, 65, 176, 3, 34, 0, 65, 0, 54, 2, 0, 65, 208, 15, 65, 0, 54, 2, 0, 3, 64, 32, 1, 65, 23, 73, 4, 64, 32, 1, 65, 2, 116, 65, 176, 3, 106, 65, 0, 54, 2, 4, 65, 0, 33, 2, 3, 64, 32, 2, 65, 16, 73, 4, 64, 32, 1, 65, 4, 116, 32, 2, 106, 65, 2, 116, 65, 176, 3, 106, 65, 0, 54, 2, 96, 32, 2, 65, 1, 106, 33, 2, 12, 1, 11, 11, 32, 1, 65, 1, 106, 33, 1, 12, 1, 11, 11, 65, 176, 3, 65, 224, 15, 63, 0, 65, 16, 116, 16, 3, 65, 176, 3, 36, 0, 11, 32, 0, 11, 45, 0, 32, 0, 65, 240, 255, 255, 255, 3, 79, 4, 64, 65, 32, 65, 224, 0, 65, 201, 3, 65, 29, 16, 0, 0, 11, 32, 0, 65, 15, 106, 65, 112, 113, 34, 0, 65, 16, 32, 0, 65, 16, 75, 27, 11, 169, 1, 1, 1, 127, 32, 0, 32, 1, 65, 128, 2, 73, 4, 127, 32, 1, 65, 4, 118, 33, 1, 65, 0, 5, 32, 1, 65, 248, 255, 255, 255, 1, 73, 4, 64, 32, 1, 65, 1, 65, 27, 32, 1, 103, 107, 116, 106, 65, 1, 107, 33, 1, 11, 32, 1, 65, 31, 32, 1, 103, 107, 34, 2, 65, 4, 107, 118, 65, 16, 115, 33, 1, 32, 2, 65, 7, 107, 11, 34, 2, 65, 2, 116, 106, 40, 2, 4, 65, 127, 32, 1, 116, 113, 34, 1, 4, 127, 32, 0, 32, 1, 104, 32, 2, 65, 4, 116, 106, 65, 2, 116, 106, 40, 2, 96, 5, 32, 0, 40, 2, 0, 65, 127, 32, 2, 65, 1, 106, 116, 113, 34, 1, 4, 127, 32, 0, 32, 0, 32, 1, 104, 34, 0, 65, 2, 116, 106, 40, 2, 4, 104, 32, 0, 65, 4, 116, 106, 65, 2, 116, 106, 40, 2, 96, 5, 65, 0, 11, 11, 11, 111, 1, 1, 127, 63, 0, 34, 2, 32, 1, 65, 248, 255, 255, 255, 1, 73, 4, 127, 32, 1, 65, 1, 65, 27, 32, 1, 103, 107, 116, 65, 1, 107, 106, 5, 32, 1, 11, 65, 16, 32, 0, 40, 2, 160, 12, 32, 2, 65, 16, 116, 65, 16, 107, 71, 116, 106, 65, 255, 255, 3, 106, 65, 128, 128, 124, 113, 65, 16, 118, 34, 1, 32, 2, 32, 1, 74, 27, 64, 0, 65, 0, 72, 4, 64, 32, 1, 64, 0, 65, 0, 72, 4, 64, 0, 11, 11, 32, 0, 32, 2, 65, 16, 116, 63, 0, 65, 16, 116, 16, 3, 11, 113, 1, 2, 127, 32, 1, 40, 2, 0, 34, 3, 65, 124, 113, 32, 2, 107, 34, 4, 65, 32, 79, 4, 64, 32, 1, 32, 2, 32, 3, 65, 2, 113, 114, 54, 2, 0, 32, 2, 32, 1, 65, 16, 106, 106, 34, 1, 32, 4, 65, 16, 107, 65, 1, 114, 54, 2, 0, 32, 0, 32, 1, 16, 2, 5, 32, 1, 32, 3, 65, 126, 113, 54, 2, 0, 32, 1, 65, 16, 106, 32, 1, 40, 2, 0, 65, 124, 113, 106, 32, 1, 65, 16, 106, 32, 1, 40, 2, 0, 65, 124, 113, 106, 40, 2, 0, 65, 125, 113, 54, 2, 0, 11, 11, 91, 1, 2, 127, 32, 0, 32, 1, 16, 5, 34, 4, 16, 6, 34, 3, 69, 4, 64, 65, 1, 36, 1, 65, 0, 36, 1, 32, 0, 32, 4, 16, 6, 34, 3, 69, 4, 64, 32, 0, 32, 4, 16, 7, 32, 0, 32, 4, 16, 6, 33, 3, 11, 11, 32, 3, 65, 0, 54, 2, 4, 32, 3, 32, 2, 54, 2, 8, 32, 3, 32, 1, 54, 2, 12, 32, 0, 32, 3, 16, 1, 32, 0, 32, 3, 32, 4, 16, 8, 32, 3, 11, 13, 0, 16, 4, 32, 0, 32, 1, 16, 9, 65, 16, 106, 11, 33, 1, 1, 127, 32, 0, 65, 172, 3, 75, 4, 64, 32, 0, 65, 16, 107, 34, 1, 32, 1, 40, 2, 4, 65, 1, 106, 54, 2, 4, 11, 32, 0, 11, 18, 0, 32, 0, 65, 172, 3, 75, 4, 64, 32, 0, 65, 16, 107, 16, 52, 11, 11, 140, 3, 1, 1, 127, 2, 64, 32, 1, 69, 13, 0, 32, 0, 65, 0, 58, 0, 0, 32, 0, 32, 1, 106, 65, 1, 107, 65, 0, 58, 0, 0, 32, 1, 65, 2, 77, 13, 0, 32, 0, 65, 1, 106, 65, 0, 58, 0, 0, 32, 0, 65, 2, 106, 65, 0, 58, 0, 0, 32, 0, 32, 1, 106, 34, 2, 65, 2, 107, 65, 0, 58, 0, 0, 32, 2, 65, 3, 107, 65, 0, 58, 0, 0, 32, 1, 65, 6, 77, 13, 0, 32, 0, 65, 3, 106, 65, 0, 58, 0, 0, 32, 0, 32, 1, 106, 65, 4, 107, 65, 0, 58, 0, 0, 32, 1, 65, 8, 77, 13, 0, 32, 1, 65, 0, 32, 0, 107, 65, 3, 113, 34, 1, 107, 33, 2, 32, 0, 32, 1, 106, 34, 0, 65, 0, 54, 2, 0, 32, 0, 32, 2, 65, 124, 113, 34, 1, 106, 65, 4, 107, 65, 0, 54, 2, 0, 32, 1, 65, 8, 77, 13, 0, 32, 0, 65, 4, 106, 65, 0, 54, 2, 0, 32, 0, 65, 8, 106, 65, 0, 54, 2, 0, 32, 0, 32, 1, 106, 34, 2, 65, 12, 107, 65, 0, 54, 2, 0, 32, 2, 65, 8, 107, 65, 0, 54, 2, 0, 32, 1, 65, 24, 77, 13, 0, 32, 0, 65, 12, 106, 65, 0, 54, 2, 0, 32, 0, 65, 16, 106, 65, 0, 54, 2, 0, 32, 0, 65, 20, 106, 65, 0, 54, 2, 0, 32, 0, 65, 24, 106, 65, 0, 54, 2, 0, 32, 0, 32, 1, 106, 34, 2, 65, 28, 107, 65, 0, 54, 2, 0, 32, 2, 65, 24, 107, 65, 0, 54, 2, 0, 32, 2, 65, 20, 107, 65, 0, 54, 2, 0, 32, 2, 65, 16, 107, 65, 0, 54, 2, 0, 32, 0, 32, 0, 65, 4, 113, 65, 24, 106, 34, 2, 106, 33, 0, 32, 1, 32, 2, 107, 33, 1, 3, 64, 32, 1, 65, 32, 79, 4, 64, 32, 0, 66, 0, 55, 3, 0, 32, 0, 65, 8, 106, 66, 0, 55, 3, 0, 32, 0, 65, 16, 106, 66, 0, 55, 3, 0, 32, 0, 65, 24, 106, 66, 0, 55, 3, 0, 32, 1, 65, 32, 107, 33, 1, 32, 0, 65, 32, 106, 33, 0, 12, 1, 11, 11, 11, 11, 178, 1, 1, 3, 127, 32, 1, 65, 240, 255, 255, 255, 3, 32, 2, 118, 75, 4, 64, 65, 144, 1, 65, 192, 1, 65, 23, 65, 56, 16, 0, 0, 11, 32, 1, 32, 2, 116, 34, 3, 65, 0, 16, 10, 34, 2, 32, 3, 16, 13, 32, 0, 69, 4, 64, 65, 12, 65, 2, 16, 10, 34, 0, 65, 172, 3, 75, 4, 64, 32, 0, 65, 16, 107, 34, 1, 32, 1, 40, 2, 4, 65, 1, 106, 54, 2, 4, 11, 11, 32, 0, 65, 0, 54, 2, 0, 32, 0, 65, 0, 54, 2, 4, 32, 0, 65, 0, 54, 2, 8, 32, 2, 34, 1, 32, 0, 40, 2, 0, 34, 4, 71, 4, 64, 32, 1, 65, 172, 3, 75, 4, 64, 32, 1, 65, 16, 107, 34, 5, 32, 5, 40, 2, 4, 65, 1, 106, 54, 2, 4, 11, 32, 4, 16, 12, 11, 32, 0, 32, 1, 54, 2, 0, 32, 0, 32, 2, 54, 2, 4, 32, 0, 32, 3, 54, 2, 8, 32, 0, 11, 46, 1, 2, 127, 65, 12, 65, 5, 16, 10, 34, 0, 65, 172, 3, 75, 4, 64, 32, 0, 65, 16, 107, 34, 1, 32, 1, 40, 2, 4, 65, 1, 106, 54, 2, 4, 11, 32, 0, 65, 128, 2, 65, 3, 16, 14, 11, 9, 0, 65, 63, 32, 0, 121, 167, 107, 11, 49, 1, 2, 127, 65, 63, 32, 1, 121, 167, 107, 33, 2, 3, 64, 65, 63, 32, 0, 121, 167, 107, 32, 2, 107, 34, 3, 65, 0, 78, 4, 64, 32, 0, 32, 1, 32, 3, 172, 134, 133, 33, 0, 12, 1, 11, 11, 32, 0, 11, 40, 0, 32, 1, 32, 0, 40, 2, 8, 79, 4, 64, 65, 128, 2, 65, 192, 2, 65, 163, 1, 65, 44, 16, 0, 0, 11, 32, 1, 32, 0, 40, 2, 4, 106, 65, 0, 58, 0, 0, 11, 38, 0, 32, 1, 32, 0, 40, 2, 8, 79, 4, 64, 65, 128, 2, 65, 192, 2, 65, 152, 1, 65, 44, 16, 0, 0, 11, 32, 1, 32, 0, 40, 2, 4, 106, 45, 0, 0, 11, 254, 5, 2, 1, 127, 4, 126, 32, 0, 69, 4, 64, 65, 232, 0, 65, 6, 16, 10, 34, 0, 65, 172, 3, 75, 4, 64, 32, 0, 65, 16, 107, 34, 5, 32, 5, 40, 2, 4, 65, 1, 106, 54, 2, 4, 11, 11, 32, 0, 65, 0, 54, 2, 0, 32, 0, 65, 0, 54, 2, 4, 32, 0, 65, 0, 54, 2, 8, 32, 0, 66, 0, 55, 3, 16, 32, 0, 66, 0, 55, 3, 24, 32, 0, 66, 0, 55, 3, 32, 32, 0, 66, 0, 55, 3, 40, 32, 0, 66, 0, 55, 3, 48, 32, 0, 66, 0, 55, 3, 56, 32, 0, 66, 0, 55, 3, 64, 32, 0, 66, 0, 55, 3, 72, 32, 0, 66, 0, 55, 3, 80, 32, 0, 66, 0, 55, 3, 88, 32, 0, 66, 0, 55, 3, 96, 32, 0, 32, 2, 173, 55, 3, 80, 32, 0, 32, 3, 173, 55, 3, 88, 65, 12, 65, 4, 16, 10, 34, 2, 65, 172, 3, 75, 4, 64, 32, 2, 65, 16, 107, 34, 3, 32, 3, 40, 2, 4, 65, 1, 106, 54, 2, 4, 11, 32, 2, 32, 4, 65, 0, 16, 14, 33, 2, 32, 0, 40, 2, 0, 16, 12, 32, 0, 32, 2, 54, 2, 0, 32, 0, 32, 4, 54, 2, 4, 32, 0, 66, 1, 32, 1, 173, 134, 66, 1, 125, 55, 3, 96, 32, 0, 66, 243, 130, 183, 218, 216, 230, 232, 30, 55, 3, 72, 35, 4, 69, 4, 64, 65, 0, 33, 2, 3, 64, 32, 2, 65, 128, 2, 72, 4, 64, 32, 2, 65, 255, 1, 113, 173, 33, 6, 32, 0, 41, 3, 72, 34, 7, 33, 8, 65, 63, 32, 7, 121, 167, 107, 33, 1, 3, 64, 65, 63, 32, 6, 121, 167, 107, 32, 1, 107, 34, 3, 65, 0, 78, 4, 64, 32, 6, 32, 8, 32, 3, 172, 134, 133, 33, 6, 12, 1, 11, 11, 65, 0, 33, 4, 3, 64, 32, 4, 32, 0, 40, 2, 4, 65, 1, 107, 72, 4, 64, 32, 6, 66, 8, 134, 33, 6, 32, 0, 41, 3, 72, 34, 7, 33, 8, 65, 63, 32, 7, 121, 167, 107, 33, 1, 3, 64, 65, 63, 32, 6, 121, 167, 107, 32, 1, 107, 34, 3, 65, 0, 78, 4, 64, 32, 6, 32, 8, 32, 3, 172, 134, 133, 33, 6, 12, 1, 11, 11, 32, 4, 65, 1, 106, 33, 4, 12, 1, 11, 11, 35, 6, 40, 2, 4, 32, 2, 65, 3, 116, 106, 32, 6, 55, 3, 0, 32, 2, 65, 1, 106, 33, 2, 12, 1, 11, 11, 65, 63, 32, 0, 41, 3, 72, 121, 167, 107, 172, 33, 7, 65, 0, 33, 2, 3, 64, 32, 2, 65, 128, 2, 72, 4, 64, 35, 5, 33, 1, 32, 2, 172, 32, 7, 134, 34, 8, 33, 6, 65, 63, 32, 0, 41, 3, 72, 34, 9, 121, 167, 107, 33, 3, 3, 64, 65, 63, 32, 6, 121, 167, 107, 32, 3, 107, 34, 4, 65, 0, 78, 4, 64, 32, 6, 32, 9, 32, 4, 172, 134, 133, 33, 6, 12, 1, 11, 11, 32, 1, 40, 2, 4, 32, 2, 65, 3, 116, 106, 32, 6, 32, 8, 132, 55, 3, 0, 32, 2, 65, 1, 106, 33, 2, 12, 1, 11, 11, 65, 1, 36, 4, 11, 32, 0, 66, 0, 55, 3, 24, 32, 0, 66, 0, 55, 3, 32, 65, 0, 33, 2, 3, 64, 32, 2, 32, 0, 40, 2, 4, 72, 4, 64, 32, 0, 40, 2, 0, 32, 2, 16, 18, 32, 2, 65, 1, 106, 33, 2, 12, 1, 11, 11, 32, 0, 66, 0, 55, 3, 40, 32, 0, 65, 0, 54, 2, 8, 32, 0, 66, 0, 55, 3, 16, 32, 0, 66, 0, 55, 3, 40, 32, 0, 40, 2, 0, 32, 0, 40, 2, 8, 16, 19, 33, 1, 32, 0, 40, 2, 8, 32, 0, 40, 2, 0, 40, 2, 4, 106, 65, 1, 58, 0, 0, 32, 0, 32, 0, 41, 3, 40, 35, 6, 40, 2, 4, 32, 1, 65, 3, 116, 106, 41, 3, 0, 133, 55, 3, 40, 32, 0, 32, 0, 40, 2, 8, 65, 1, 106, 32, 0, 40, 2, 4, 111, 54, 2, 8, 32, 0, 35, 5, 40, 2, 4, 32, 0, 41, 3, 40, 34, 6, 66, 45, 136, 167, 65, 3, 116, 106, 41, 3, 0, 32, 6, 66, 8, 134, 66, 1, 132, 133, 55, 3, 40, 32, 0, 11, 38, 1, 1, 127, 32, 0, 40, 2, 0, 34, 0, 65, 172, 3, 75, 4, 64, 32, 0, 65, 16, 107, 34, 1, 32, 1, 40, 2, 4, 65, 1, 106, 54, 2, 4, 11, 32, 0, 11, 55, 1, 2, 127, 32, 1, 32, 0, 40, 2, 0, 34, 2, 71, 4, 64, 32, 1, 65, 172, 3, 75, 4, 64, 32, 1, 65, 16, 107, 34, 3, 32, 3, 40, 2, 4, 65, 1, 106, 54, 2, 4, 11, 32, 2, 16, 12, 11, 32, 0, 32, 1, 54, 2, 0, 11, 7, 0, 32, 0, 40, 2, 4, 11, 9, 0, 32, 0, 32, 1, 54, 2, 4, 11, 7, 0, 32, 0, 40, 2, 8, 11, 9, 0, 32, 0, 32, 1, 54, 2, 8, 11, 7, 0, 32, 0, 41, 3, 16, 11, 9, 0, 32, 0, 32, 1, 55, 3, 16, 11, 7, 0, 32, 0, 41, 3, 24, 11, 9, 0, 32, 0, 32, 1, 55, 3, 24, 11, 7, 0, 32, 0, 41, 3, 32, 11, 9, 0, 32, 0, 32, 1, 55, 3, 32, 11, 7, 0, 32, 0, 41, 3, 40, 11, 9, 0, 32, 0, 32, 1, 55, 3, 40, 11, 7, 0, 32, 0, 41, 3, 48, 11, 9, 0, 32, 0, 32, 1, 55, 3, 48, 11, 7, 0, 32, 0, 41, 3, 56, 11, 9, 0, 32, 0, 32, 1, 55, 3, 56, 11, 7, 0, 32, 0, 41, 3, 64, 11, 9, 0, 32, 0, 32, 1, 55, 3, 64, 11, 7, 0, 32, 0, 41, 3, 72, 11, 9, 0, 32, 0, 32, 1, 55, 3, 72, 11, 7, 0, 32, 0, 41, 3, 80, 11, 9, 0, 32, 0, 32, 1, 55, 3, 80, 11, 7, 0, 32, 0, 41, 3, 88, 11, 9, 0, 32, 0, 32, 1, 55, 3, 88, 11, 7, 0, 32, 0, 41, 3, 96, 11, 9, 0, 32, 0, 32, 1, 55, 3, 96, 11, 172, 4, 2, 5, 127, 1, 126, 32, 2, 65, 172, 3, 75, 4, 64, 32, 2, 65, 16, 107, 34, 4, 32, 4, 40, 2, 4, 65, 1, 106, 54, 2, 4, 11, 32, 2, 33, 4, 65, 0, 33, 2, 32, 1, 40, 2, 8, 33, 5, 32, 1, 40, 2, 4, 33, 6, 3, 64, 2, 127, 65, 0, 33, 3, 3, 64, 32, 3, 32, 5, 72, 4, 64, 32, 3, 32, 6, 106, 45, 0, 0, 33, 1, 32, 0, 40, 2, 0, 32, 0, 40, 2, 8, 16, 19, 33, 7, 32, 0, 40, 2, 8, 32, 0, 40, 2, 0, 40, 2, 4, 106, 32, 1, 58, 0, 0, 32, 0, 32, 0, 41, 3, 40, 35, 6, 40, 2, 4, 32, 7, 65, 3, 116, 106, 41, 3, 0, 133, 55, 3, 40, 32, 0, 32, 0, 40, 2, 8, 65, 1, 106, 32, 0, 40, 2, 4, 111, 54, 2, 8, 32, 0, 35, 5, 40, 2, 4, 32, 0, 41, 3, 40, 34, 8, 66, 45, 136, 167, 65, 3, 116, 106, 41, 3, 0, 32, 1, 173, 32, 8, 66, 8, 134, 132, 133, 55, 3, 40, 32, 0, 32, 0, 41, 3, 16, 66, 1, 124, 55, 3, 16, 32, 0, 32, 0, 41, 3, 24, 66, 1, 124, 55, 3, 24, 32, 0, 41, 3, 16, 32, 0, 41, 3, 80, 90, 4, 127, 32, 0, 41, 3, 40, 32, 0, 41, 3, 96, 131, 80, 5, 65, 0, 11, 4, 127, 65, 1, 5, 32, 0, 41, 3, 16, 32, 0, 41, 3, 88, 90, 11, 4, 64, 32, 0, 32, 0, 41, 3, 32, 55, 3, 48, 32, 0, 32, 0, 41, 3, 16, 55, 3, 56, 32, 0, 32, 0, 41, 3, 40, 55, 3, 64, 65, 0, 33, 1, 3, 64, 32, 1, 32, 0, 40, 2, 4, 72, 4, 64, 32, 0, 40, 2, 0, 32, 1, 16, 18, 32, 1, 65, 1, 106, 33, 1, 12, 1, 11, 11, 32, 0, 66, 0, 55, 3, 40, 32, 0, 65, 0, 54, 2, 8, 32, 0, 66, 0, 55, 3, 16, 32, 0, 66, 0, 55, 3, 40, 32, 0, 40, 2, 0, 32, 0, 40, 2, 8, 16, 19, 33, 1, 32, 0, 40, 2, 8, 32, 0, 40, 2, 0, 40, 2, 4, 106, 65, 1, 58, 0, 0, 32, 0, 32, 0, 41, 3, 40, 35, 6, 40, 2, 4, 32, 1, 65, 3, 116, 106, 41, 3, 0, 133, 55, 3, 40, 32, 0, 32, 0, 40, 2, 8, 65, 1, 106, 32, 0, 40, 2, 4, 111, 54, 2, 8, 32, 0, 35, 5, 40, 2, 4, 32, 0, 41, 3, 40, 34, 8, 66, 45, 136, 167, 65, 3, 116, 106, 41, 3, 0, 32, 8, 66, 8, 134, 66, 1, 132, 133, 55, 3, 40, 32, 3, 65, 1, 106, 12, 3, 11, 32, 3, 65, 1, 106, 33, 3, 12, 1, 11, 11, 65, 127, 11, 34, 1, 65, 0, 78, 4, 64, 32, 5, 32, 1, 107, 33, 5, 32, 1, 32, 6, 106, 33, 6, 32, 2, 34, 1, 65, 1, 106, 33, 2, 32, 4, 40, 2, 4, 32, 1, 65, 2, 116, 106, 32, 0, 41, 3, 56, 62, 2, 0, 12, 1, 11, 11, 32, 4, 11, 10, 0, 16, 15, 36, 5, 16, 15, 36, 6, 11, 3, 0, 1, 11, 73, 1, 2, 127, 32, 0, 40, 2, 4, 34, 1, 65, 255, 255, 255, 255, 0, 113, 34, 2, 65, 1, 70, 4, 64, 32, 0, 65, 16, 106, 16, 53, 32, 0, 32, 0, 40, 2, 0, 65, 1, 114, 54, 2, 0, 35, 0, 32, 0, 16, 2, 5, 32, 0, 32, 2, 65, 1, 107, 32, 1, 65, 128, 128, 128, 128, 127, 113, 114, 54, 2, 4, 11, 11, 58, 0, 2, 64, 2, 64, 2, 64, 32, 0, 65, 8, 107, 40, 2, 0, 14, 7, 0, 0, 1, 1, 1, 1, 1, 2, 11, 15, 11, 32, 0, 40, 2, 0, 34, 0, 4, 64, 32, 0, 65, 172, 3, 79, 4, 64, 32, 0, 65, 16, 107, 16, 52, 11, 11, 15, 11, 0, 11, 11, 137, 3, 7, 0, 65, 16, 11, 55, 40, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 40, 0, 0, 0, 97, 0, 108, 0, 108, 0, 111, 0, 99, 0, 97, 0, 116, 0, 105, 0, 111, 0, 110, 0, 32, 0, 116, 0, 111, 0, 111, 0, 32, 0, 108, 0, 97, 0, 114, 0, 103, 0, 101, 0, 65, 208, 0, 11, 45, 30, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 30, 0, 0, 0, 126, 0, 108, 0, 105, 0, 98, 0, 47, 0, 114, 0, 116, 0, 47, 0, 116, 0, 108, 0, 115, 0, 102, 0, 46, 0, 116, 0, 115, 0, 65, 128, 1, 11, 43, 28, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 28, 0, 0, 0, 73, 0, 110, 0, 118, 0, 97, 0, 108, 0, 105, 0, 100, 0, 32, 0, 108, 0, 101, 0, 110, 0, 103, 0, 116, 0, 104, 0, 65, 176, 1, 11, 53, 38, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 38, 0, 0, 0, 126, 0, 108, 0, 105, 0, 98, 0, 47, 0, 97, 0, 114, 0, 114, 0, 97, 0, 121, 0, 98, 0, 117, 0, 102, 0, 102, 0, 101, 0, 114, 0, 46, 0, 116, 0, 115, 0, 65, 240, 1, 11, 51, 36, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 36, 0, 0, 0, 73, 0, 110, 0, 100, 0, 101, 0, 120, 0, 32, 0, 111, 0, 117, 0, 116, 0, 32, 0, 111, 0, 102, 0, 32, 0, 114, 0, 97, 0, 110, 0, 103, 0, 101, 0, 65, 176, 2, 11, 51, 36, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 36, 0, 0, 0, 126, 0, 108, 0, 105, 0, 98, 0, 47, 0, 116, 0, 121, 0, 112, 0, 101, 0, 100, 0, 97, 0, 114, 0, 114, 0, 97, 0, 121, 0, 46, 0, 116, 0, 115, 0, 65, 240, 2, 11, 53, 7, 0, 0, 0, 16, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 0, 0, 0, 0, 0, 16, 0, 0, 0, 0, 0, 0, 0, 145, 4, 0, 0, 2, 0, 0, 0, 49, 0, 0, 0, 2, 0, 0, 0, 17, 1, 0, 0, 2, 0, 0, 0, 16, 0, 34, 16, 115, 111, 117, 114, 99, 101, 77, 97, 112, 112, 105, 110, 103, 85, 82, 76, 16, 46, 47, 114, 97, 98, 105, 110, 46, 119, 97, 115, 109, 46, 109, 97, 112]);
      return instantiate(new Response(new Blob([wasm], { type: "application/wasm" })), imp);
    }
    module.exports = loadWebAssembly;
  }
});

// node_modules/rabin-wasm/src/index.js
var require_src = __commonJS({
  "node_modules/rabin-wasm/src/index.js"(exports, module) {
    var Rabin = require_rabin();
    var getRabin = require_rabin_wasm();
    var create6 = async (avg, min, max, windowSize, polynomial) => {
      const compiled = await getRabin();
      return new Rabin(compiled, avg, min, max, windowSize, polynomial);
    };
    module.exports = {
      Rabin,
      create: create6
    };
  }
});

// node_modules/it-batch/dist/src/index.js
function isAsyncIterable(thing) {
  return thing[Symbol.asyncIterator] != null;
}
function batch(source, size = 1) {
  size = Number(size);
  if (isAsyncIterable(source)) {
    return async function* () {
      let things = [];
      if (size < 1) {
        size = 1;
      }
      if (size !== Math.round(size)) {
        throw new Error("Batch size must be an integer");
      }
      for await (const thing of source) {
        things.push(thing);
        while (things.length >= size) {
          yield things.slice(0, size);
          things = things.slice(size);
        }
      }
      while (things.length > 0) {
        yield things.slice(0, size);
        things = things.slice(size);
      }
    }();
  }
  return function* () {
    let things = [];
    if (size < 1) {
      size = 1;
    }
    if (size !== Math.round(size)) {
      throw new Error("Batch size must be an integer");
    }
    for (const thing of source) {
      things.push(thing);
      while (things.length >= size) {
        yield things.slice(0, size);
        things = things.slice(size);
      }
    }
    while (things.length > 0) {
      yield things.slice(0, size);
      things = things.slice(size);
    }
  }();
}
var src_default5 = batch;

// node_modules/it-parallel-batch/dist/src/index.js
async function* parallelBatch(source, size = 1) {
  for await (const tasks of src_default5(source, size)) {
    const things = tasks.map(async (p) => {
      return p().then((value) => ({ ok: true, value }), (err) => ({ ok: false, err }));
    });
    for (let i = 0; i < things.length; i++) {
      const result = await things[i];
      if (result.ok) {
        yield result.value;
      } else {
        throw result.err;
      }
    }
  }
}

// node_modules/ipfs-unixfs-importer/dist/src/chunker/fixed-size.js
var DEFAULT_CHUNK_SIZE = 262144;
var fixedSize = (options = {}) => {
  const chunkSize = options.chunkSize ?? DEFAULT_CHUNK_SIZE;
  return async function* fixedSizeChunker(source) {
    let list = new Uint8ArrayList();
    let currentLength = 0;
    let emitted = false;
    for await (const buffer of source) {
      list.append(buffer);
      currentLength += buffer.length;
      while (currentLength >= chunkSize) {
        yield list.slice(0, chunkSize);
        emitted = true;
        if (chunkSize === list.length) {
          list = new Uint8ArrayList();
          currentLength = 0;
        } else {
          const newBl = new Uint8ArrayList();
          newBl.append(list.sublist(chunkSize));
          list = newBl;
          currentLength -= chunkSize;
        }
      }
    }
    if (!emitted || currentLength > 0) {
      yield list.subarray(0, currentLength);
    }
  };
};

// node_modules/ipfs-unixfs/dist/src/errors.js
var InvalidTypeError = class _InvalidTypeError extends Error {
  static name = "InvalidTypeError";
  static code = "ERR_INVALID_TYPE";
  name = _InvalidTypeError.name;
  code = _InvalidTypeError.code;
  constructor(message2 = "Invalid type") {
    super(message2);
  }
};
var InvalidUnixFSMessageError = class _InvalidUnixFSMessageError extends Error {
  static name = "InvalidUnixFSMessageError";
  static code = "ERR_INVALID_MESSAGE";
  name = _InvalidUnixFSMessageError.name;
  code = _InvalidUnixFSMessageError.code;
  constructor(message2 = "Invalid message") {
    super(message2);
  }
};

// node_modules/ipfs-unixfs/dist/src/unixfs.js
var Data;
(function(Data2) {
  let DataType;
  (function(DataType2) {
    DataType2["Raw"] = "Raw";
    DataType2["Directory"] = "Directory";
    DataType2["File"] = "File";
    DataType2["Metadata"] = "Metadata";
    DataType2["Symlink"] = "Symlink";
    DataType2["HAMTShard"] = "HAMTShard";
  })(DataType = Data2.DataType || (Data2.DataType = {}));
  let __DataTypeValues;
  (function(__DataTypeValues2) {
    __DataTypeValues2[__DataTypeValues2["Raw"] = 0] = "Raw";
    __DataTypeValues2[__DataTypeValues2["Directory"] = 1] = "Directory";
    __DataTypeValues2[__DataTypeValues2["File"] = 2] = "File";
    __DataTypeValues2[__DataTypeValues2["Metadata"] = 3] = "Metadata";
    __DataTypeValues2[__DataTypeValues2["Symlink"] = 4] = "Symlink";
    __DataTypeValues2[__DataTypeValues2["HAMTShard"] = 5] = "HAMTShard";
  })(__DataTypeValues || (__DataTypeValues = {}));
  (function(DataType2) {
    DataType2.codec = () => {
      return enumeration(__DataTypeValues);
    };
  })(DataType = Data2.DataType || (Data2.DataType = {}));
  let _codec;
  Data2.codec = () => {
    if (_codec == null) {
      _codec = message((obj, w, opts = {}) => {
        if (opts.lengthDelimited !== false) {
          w.fork();
        }
        if (obj.Type != null) {
          w.uint32(8);
          Data2.DataType.codec().encode(obj.Type, w);
        }
        if (obj.Data != null) {
          w.uint32(18);
          w.bytes(obj.Data);
        }
        if (obj.filesize != null) {
          w.uint32(24);
          w.uint64(obj.filesize);
        }
        if (obj.blocksizes != null) {
          for (const value of obj.blocksizes) {
            w.uint32(32);
            w.uint64(value);
          }
        }
        if (obj.hashType != null) {
          w.uint32(40);
          w.uint64(obj.hashType);
        }
        if (obj.fanout != null) {
          w.uint32(48);
          w.uint64(obj.fanout);
        }
        if (obj.mode != null) {
          w.uint32(56);
          w.uint32(obj.mode);
        }
        if (obj.mtime != null) {
          w.uint32(66);
          UnixTime.codec().encode(obj.mtime, w);
        }
        if (opts.lengthDelimited !== false) {
          w.ldelim();
        }
      }, (reader, length5) => {
        const obj = {
          blocksizes: []
        };
        const end = length5 == null ? reader.len : reader.pos + length5;
        while (reader.pos < end) {
          const tag = reader.uint32();
          switch (tag >>> 3) {
            case 1:
              obj.Type = Data2.DataType.codec().decode(reader);
              break;
            case 2:
              obj.Data = reader.bytes();
              break;
            case 3:
              obj.filesize = reader.uint64();
              break;
            case 4:
              obj.blocksizes.push(reader.uint64());
              break;
            case 5:
              obj.hashType = reader.uint64();
              break;
            case 6:
              obj.fanout = reader.uint64();
              break;
            case 7:
              obj.mode = reader.uint32();
              break;
            case 8:
              obj.mtime = UnixTime.codec().decode(reader, reader.uint32());
              break;
            default:
              reader.skipType(tag & 7);
              break;
          }
        }
        return obj;
      });
    }
    return _codec;
  };
  Data2.encode = (obj) => {
    return encodeMessage(obj, Data2.codec());
  };
  Data2.decode = (buf) => {
    return decodeMessage(buf, Data2.codec());
  };
})(Data || (Data = {}));
var UnixTime;
(function(UnixTime2) {
  let _codec;
  UnixTime2.codec = () => {
    if (_codec == null) {
      _codec = message((obj, w, opts = {}) => {
        if (opts.lengthDelimited !== false) {
          w.fork();
        }
        if (obj.Seconds != null) {
          w.uint32(8);
          w.int64(obj.Seconds);
        }
        if (obj.FractionalNanoseconds != null) {
          w.uint32(21);
          w.fixed32(obj.FractionalNanoseconds);
        }
        if (opts.lengthDelimited !== false) {
          w.ldelim();
        }
      }, (reader, length5) => {
        const obj = {};
        const end = length5 == null ? reader.len : reader.pos + length5;
        while (reader.pos < end) {
          const tag = reader.uint32();
          switch (tag >>> 3) {
            case 1:
              obj.Seconds = reader.int64();
              break;
            case 2:
              obj.FractionalNanoseconds = reader.fixed32();
              break;
            default:
              reader.skipType(tag & 7);
              break;
          }
        }
        return obj;
      });
    }
    return _codec;
  };
  UnixTime2.encode = (obj) => {
    return encodeMessage(obj, UnixTime2.codec());
  };
  UnixTime2.decode = (buf) => {
    return decodeMessage(buf, UnixTime2.codec());
  };
})(UnixTime || (UnixTime = {}));
var Metadata;
(function(Metadata2) {
  let _codec;
  Metadata2.codec = () => {
    if (_codec == null) {
      _codec = message((obj, w, opts = {}) => {
        if (opts.lengthDelimited !== false) {
          w.fork();
        }
        if (obj.MimeType != null) {
          w.uint32(10);
          w.string(obj.MimeType);
        }
        if (opts.lengthDelimited !== false) {
          w.ldelim();
        }
      }, (reader, length5) => {
        const obj = {};
        const end = length5 == null ? reader.len : reader.pos + length5;
        while (reader.pos < end) {
          const tag = reader.uint32();
          switch (tag >>> 3) {
            case 1:
              obj.MimeType = reader.string();
              break;
            default:
              reader.skipType(tag & 7);
              break;
          }
        }
        return obj;
      });
    }
    return _codec;
  };
  Metadata2.encode = (obj) => {
    return encodeMessage(obj, Metadata2.codec());
  };
  Metadata2.decode = (buf) => {
    return decodeMessage(buf, Metadata2.codec());
  };
})(Metadata || (Metadata = {}));

// node_modules/ipfs-unixfs/dist/src/index.js
var types = {
  Raw: "raw",
  Directory: "directory",
  File: "file",
  Metadata: "metadata",
  Symlink: "symlink",
  HAMTShard: "hamt-sharded-directory"
};
var dirTypes = [
  "directory",
  "hamt-sharded-directory"
];
var DEFAULT_FILE_MODE = parseInt("0644", 8);
var DEFAULT_DIRECTORY_MODE = parseInt("0755", 8);
var MAX_FANOUT = BigInt(1 << 10);
var UnixFS = class _UnixFS {
  /**
   * Decode from protobuf https://github.com/ipfs/specs/blob/master/UNIXFS.md
   */
  static unmarshal(marshaled) {
    const message2 = Data.decode(marshaled);
    if (message2.fanout != null && message2.fanout > MAX_FANOUT) {
      throw new InvalidUnixFSMessageError(`Fanout size was too large - ${message2.fanout} > ${MAX_FANOUT}`);
    }
    const data = new _UnixFS({
      type: types[message2.Type != null ? message2.Type.toString() : "File"],
      data: message2.Data,
      blockSizes: message2.blocksizes,
      mode: message2.mode,
      mtime: message2.mtime != null ? {
        secs: message2.mtime.Seconds ?? 0n,
        nsecs: message2.mtime.FractionalNanoseconds
      } : void 0,
      fanout: message2.fanout
    });
    data._originalMode = message2.mode ?? 0;
    return data;
  }
  type;
  data;
  blockSizes;
  hashType;
  fanout;
  mtime;
  _mode;
  _originalMode;
  constructor(options = {
    type: "file"
  }) {
    const { type, data, blockSizes, hashType, fanout, mtime, mode } = options;
    if (type != null && !Object.values(types).includes(type)) {
      throw new InvalidTypeError("Type: " + type + " is not valid");
    }
    this.type = type ?? "file";
    this.data = data;
    this.hashType = hashType;
    this.fanout = fanout;
    this.blockSizes = blockSizes ?? [];
    this._originalMode = 0;
    this.mode = mode;
    this.mtime = mtime;
  }
  set mode(mode) {
    if (mode == null) {
      this._mode = this.isDirectory() ? DEFAULT_DIRECTORY_MODE : DEFAULT_FILE_MODE;
    } else {
      this._mode = mode & 4095;
    }
  }
  get mode() {
    return this._mode;
  }
  isDirectory() {
    return dirTypes.includes(this.type);
  }
  addBlockSize(size) {
    this.blockSizes.push(size);
  }
  removeBlockSize(index) {
    this.blockSizes.splice(index, 1);
  }
  /**
   * Returns `0n` for directories or `data.length + sum(blockSizes)` for everything else
   */
  fileSize() {
    if (this.isDirectory()) {
      return 0n;
    }
    let sum = 0n;
    this.blockSizes.forEach((size) => {
      sum += size;
    });
    if (this.data != null) {
      sum += BigInt(this.data.length);
    }
    return sum;
  }
  /**
   * encode to protobuf Uint8Array
   */
  marshal() {
    let type;
    switch (this.type) {
      case "raw":
        type = Data.DataType.Raw;
        break;
      case "directory":
        type = Data.DataType.Directory;
        break;
      case "file":
        type = Data.DataType.File;
        break;
      case "metadata":
        type = Data.DataType.Metadata;
        break;
      case "symlink":
        type = Data.DataType.Symlink;
        break;
      case "hamt-sharded-directory":
        type = Data.DataType.HAMTShard;
        break;
      default:
        throw new InvalidTypeError(`Type: ${type} is not valid`);
    }
    let data = this.data;
    if (this.data == null || this.data.length === 0) {
      data = void 0;
    }
    let mode;
    if (this.mode != null) {
      mode = this._originalMode & 4294963200 | (this.mode ?? 0);
      if (mode === DEFAULT_FILE_MODE && !this.isDirectory()) {
        mode = void 0;
      }
      if (mode === DEFAULT_DIRECTORY_MODE && this.isDirectory()) {
        mode = void 0;
      }
    }
    let mtime;
    if (this.mtime != null) {
      mtime = {
        Seconds: this.mtime.secs,
        FractionalNanoseconds: this.mtime.nsecs
      };
    }
    return Data.encode({
      Type: type,
      Data: data,
      filesize: this.isDirectory() ? void 0 : this.fileSize(),
      blocksizes: this.blockSizes,
      hashType: this.hashType,
      fanout: this.fanout,
      mode,
      mtime
    });
  }
};

// node_modules/ipfs-unixfs-importer/node_modules/multiformats/dist/src/codecs/raw.js
var raw_exports = {};
__export(raw_exports, {
  code: () => code4,
  decode: () => decode4,
  encode: () => encode2,
  name: () => name
});

// node_modules/ipfs-unixfs-importer/node_modules/multiformats/dist/src/bytes.js
var empty = new Uint8Array(0);
function equals(aa, bb) {
  if (aa === bb) {
    return true;
  }
  if (aa.byteLength !== bb.byteLength) {
    return false;
  }
  for (let ii = 0; ii < aa.byteLength; ii++) {
    if (aa[ii] !== bb[ii]) {
      return false;
    }
  }
  return true;
}
function coerce(o) {
  if (o instanceof Uint8Array && o.constructor.name === "Uint8Array") {
    return o;
  }
  if (o instanceof ArrayBuffer) {
    return new Uint8Array(o);
  }
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength);
  }
  throw new Error("Unknown type, must be binary type");
}

// node_modules/ipfs-unixfs-importer/node_modules/multiformats/dist/src/codecs/raw.js
var name = "raw";
var code4 = 85;
function encode2(node) {
  return coerce(node);
}
function decode4(data) {
  return coerce(data);
}

// node_modules/ipfs-unixfs-importer/node_modules/multiformats/dist/src/vendor/base-x.js
function base(ALPHABET, name3) {
  if (ALPHABET.length >= 255) {
    throw new TypeError("Alphabet too long");
  }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) {
      throw new TypeError(x + " is ambiguous");
    }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256);
  var iFACTOR = Math.log(256) / Math.log(BASE);
  function encode12(source) {
    if (source instanceof Uint8Array)
      ;
    else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) {
      throw new TypeError("Expected Uint8Array");
    }
    if (source.length === 0) {
      return "";
    }
    var zeroes = 0;
    var length5 = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
    var size = (pend - pbegin) * iFACTOR + 1 >>> 0;
    var b58 = new Uint8Array(size);
    while (pbegin !== pend) {
      var carry = source[pbegin];
      var i2 = 0;
      for (var it1 = size - 1; (carry !== 0 || i2 < length5) && it1 !== -1; it1--, i2++) {
        carry += 256 * b58[it1] >>> 0;
        b58[it1] = carry % BASE >>> 0;
        carry = carry / BASE >>> 0;
      }
      if (carry !== 0) {
        throw new Error("Non-zero carry");
      }
      length5 = i2;
      pbegin++;
    }
    var it2 = size - length5;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
    var str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) {
      str += ALPHABET.charAt(b58[it2]);
    }
    return str;
  }
  function decodeUnsafe(source) {
    if (typeof source !== "string") {
      throw new TypeError("Expected String");
    }
    if (source.length === 0) {
      return new Uint8Array();
    }
    var psz = 0;
    if (source[psz] === " ") {
      return;
    }
    var zeroes = 0;
    var length5 = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
    var size = (source.length - psz) * FACTOR + 1 >>> 0;
    var b256 = new Uint8Array(size);
    while (source[psz]) {
      var carry = BASE_MAP[source.charCodeAt(psz)];
      if (carry === 255) {
        return;
      }
      var i2 = 0;
      for (var it3 = size - 1; (carry !== 0 || i2 < length5) && it3 !== -1; it3--, i2++) {
        carry += BASE * b256[it3] >>> 0;
        b256[it3] = carry % 256 >>> 0;
        carry = carry / 256 >>> 0;
      }
      if (carry !== 0) {
        throw new Error("Non-zero carry");
      }
      length5 = i2;
      psz++;
    }
    if (source[psz] === " ") {
      return;
    }
    var it4 = size - length5;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size - it4));
    var j2 = zeroes;
    while (it4 !== size) {
      vch[j2++] = b256[it4++];
    }
    return vch;
  }
  function decode22(string) {
    var buffer = decodeUnsafe(string);
    if (buffer) {
      return buffer;
    }
    throw new Error(`Non-${name3} character`);
  }
  return {
    encode: encode12,
    decodeUnsafe,
    decode: decode22
  };
}
var src = base;
var _brrp__multiformats_scope_baseX = src;
var base_x_default = _brrp__multiformats_scope_baseX;

// node_modules/ipfs-unixfs-importer/node_modules/multiformats/dist/src/bases/base.js
var Encoder = class {
  name;
  prefix;
  baseEncode;
  constructor(name3, prefix, baseEncode) {
    this.name = name3;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
  }
  encode(bytes) {
    if (bytes instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes)}`;
    } else {
      throw Error("Unknown type, must be binary type");
    }
  }
};
var Decoder = class {
  name;
  prefix;
  baseDecode;
  prefixCodePoint;
  constructor(name3, prefix, baseDecode) {
    this.name = name3;
    this.prefix = prefix;
    const prefixCodePoint = prefix.codePointAt(0);
    if (prefixCodePoint === void 0) {
      throw new Error("Invalid prefix character");
    }
    this.prefixCodePoint = prefixCodePoint;
    this.baseDecode = baseDecode;
  }
  decode(text) {
    if (typeof text === "string") {
      if (text.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`);
      }
      return this.baseDecode(text.slice(this.prefix.length));
    } else {
      throw Error("Can only multibase decode strings");
    }
  }
  or(decoder) {
    return or(this, decoder);
  }
};
var ComposedDecoder = class {
  decoders;
  constructor(decoders) {
    this.decoders = decoders;
  }
  or(decoder) {
    return or(this, decoder);
  }
  decode(input) {
    const prefix = input[0];
    const decoder = this.decoders[prefix];
    if (decoder != null) {
      return decoder.decode(input);
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`);
    }
  }
};
function or(left, right) {
  return new ComposedDecoder({
    ...left.decoders ?? { [left.prefix]: left },
    ...right.decoders ?? { [right.prefix]: right }
  });
}
var Codec = class {
  name;
  prefix;
  baseEncode;
  baseDecode;
  encoder;
  decoder;
  constructor(name3, prefix, baseEncode, baseDecode) {
    this.name = name3;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder(name3, prefix, baseEncode);
    this.decoder = new Decoder(name3, prefix, baseDecode);
  }
  encode(input) {
    return this.encoder.encode(input);
  }
  decode(input) {
    return this.decoder.decode(input);
  }
};
function from({ name: name3, prefix, encode: encode12, decode: decode22 }) {
  return new Codec(name3, prefix, encode12, decode22);
}
function baseX({ name: name3, prefix, alphabet }) {
  const { encode: encode12, decode: decode22 } = base_x_default(alphabet, name3);
  return from({
    prefix,
    name: name3,
    encode: encode12,
    decode: (text) => coerce(decode22(text))
  });
}
function decode5(string, alphabetIdx, bitsPerChar, name3) {
  let end = string.length;
  while (string[end - 1] === "=") {
    --end;
  }
  const out = new Uint8Array(end * bitsPerChar / 8 | 0);
  let bits = 0;
  let buffer = 0;
  let written = 0;
  for (let i = 0; i < end; ++i) {
    const value = alphabetIdx[string[i]];
    if (value === void 0) {
      throw new SyntaxError(`Non-${name3} character`);
    }
    buffer = buffer << bitsPerChar | value;
    bits += bitsPerChar;
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 255 & buffer >> bits;
    }
  }
  if (bits >= bitsPerChar || (255 & buffer << 8 - bits) !== 0) {
    throw new SyntaxError("Unexpected end of data");
  }
  return out;
}
function encode3(data, alphabet, bitsPerChar) {
  const pad = alphabet[alphabet.length - 1] === "=";
  const mask = (1 << bitsPerChar) - 1;
  let out = "";
  let bits = 0;
  let buffer = 0;
  for (let i = 0; i < data.length; ++i) {
    buffer = buffer << 8 | data[i];
    bits += 8;
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet[mask & buffer >> bits];
    }
  }
  if (bits !== 0) {
    out += alphabet[mask & buffer << bitsPerChar - bits];
  }
  if (pad) {
    while ((out.length * bitsPerChar & 7) !== 0) {
      out += "=";
    }
  }
  return out;
}
function createAlphabetIdx(alphabet) {
  const alphabetIdx = {};
  for (let i = 0; i < alphabet.length; ++i) {
    alphabetIdx[alphabet[i]] = i;
  }
  return alphabetIdx;
}
function rfc4648({ name: name3, prefix, bitsPerChar, alphabet }) {
  const alphabetIdx = createAlphabetIdx(alphabet);
  return from({
    prefix,
    name: name3,
    encode(input) {
      return encode3(input, alphabet, bitsPerChar);
    },
    decode(input) {
      return decode5(input, alphabetIdx, bitsPerChar, name3);
    }
  });
}

// node_modules/ipfs-unixfs-importer/node_modules/multiformats/dist/src/bases/base32.js
var base32 = rfc4648({
  prefix: "b",
  name: "base32",
  alphabet: "abcdefghijklmnopqrstuvwxyz234567",
  bitsPerChar: 5
});
var base32upper = rfc4648({
  prefix: "B",
  name: "base32upper",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZ234567",
  bitsPerChar: 5
});
var base32pad = rfc4648({
  prefix: "c",
  name: "base32pad",
  alphabet: "abcdefghijklmnopqrstuvwxyz234567=",
  bitsPerChar: 5
});
var base32padupper = rfc4648({
  prefix: "C",
  name: "base32padupper",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=",
  bitsPerChar: 5
});
var base32hex = rfc4648({
  prefix: "v",
  name: "base32hex",
  alphabet: "0123456789abcdefghijklmnopqrstuv",
  bitsPerChar: 5
});
var base32hexupper = rfc4648({
  prefix: "V",
  name: "base32hexupper",
  alphabet: "0123456789ABCDEFGHIJKLMNOPQRSTUV",
  bitsPerChar: 5
});
var base32hexpad = rfc4648({
  prefix: "t",
  name: "base32hexpad",
  alphabet: "0123456789abcdefghijklmnopqrstuv=",
  bitsPerChar: 5
});
var base32hexpadupper = rfc4648({
  prefix: "T",
  name: "base32hexpadupper",
  alphabet: "0123456789ABCDEFGHIJKLMNOPQRSTUV=",
  bitsPerChar: 5
});
var base32z = rfc4648({
  prefix: "h",
  name: "base32z",
  alphabet: "ybndrfg8ejkmcpqxot1uwisza345h769",
  bitsPerChar: 5
});

// node_modules/ipfs-unixfs-importer/node_modules/multiformats/dist/src/bases/base36.js
var base36 = baseX({
  prefix: "k",
  name: "base36",
  alphabet: "0123456789abcdefghijklmnopqrstuvwxyz"
});
var base36upper = baseX({
  prefix: "K",
  name: "base36upper",
  alphabet: "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ"
});

// node_modules/ipfs-unixfs-importer/node_modules/multiformats/dist/src/bases/base58.js
var base58btc = baseX({
  name: "base58btc",
  prefix: "z",
  alphabet: "123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz"
});
var base58flickr = baseX({
  name: "base58flickr",
  prefix: "Z",
  alphabet: "123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ"
});

// node_modules/ipfs-unixfs-importer/node_modules/multiformats/dist/src/vendor/varint.js
var encode_1 = encode4;
var MSB = 128;
var REST = 127;
var MSBALL = ~REST;
var INT = Math.pow(2, 31);
function encode4(num, out, offset) {
  out = out || [];
  offset = offset || 0;
  var oldOffset = offset;
  while (num >= INT) {
    out[offset++] = num & 255 | MSB;
    num /= 128;
  }
  while (num & MSBALL) {
    out[offset++] = num & 255 | MSB;
    num >>>= 7;
  }
  out[offset] = num | 0;
  encode4.bytes = offset - oldOffset + 1;
  return out;
}
var decode6 = read;
var MSB$1 = 128;
var REST$1 = 127;
function read(buf, offset) {
  var res = 0, offset = offset || 0, shift = 0, counter = offset, b, l = buf.length;
  do {
    if (counter >= l) {
      read.bytes = 0;
      throw new RangeError("Could not decode varint");
    }
    b = buf[counter++];
    res += shift < 28 ? (b & REST$1) << shift : (b & REST$1) * Math.pow(2, shift);
    shift += 7;
  } while (b >= MSB$1);
  read.bytes = counter - offset;
  return res;
}
var N1 = Math.pow(2, 7);
var N2 = Math.pow(2, 14);
var N3 = Math.pow(2, 21);
var N4 = Math.pow(2, 28);
var N5 = Math.pow(2, 35);
var N6 = Math.pow(2, 42);
var N7 = Math.pow(2, 49);
var N8 = Math.pow(2, 56);
var N9 = Math.pow(2, 63);
var length = function(value) {
  return value < N1 ? 1 : value < N2 ? 2 : value < N3 ? 3 : value < N4 ? 4 : value < N5 ? 5 : value < N6 ? 6 : value < N7 ? 7 : value < N8 ? 8 : value < N9 ? 9 : 10;
};
var varint = {
  encode: encode_1,
  decode: decode6,
  encodingLength: length
};
var _brrp_varint = varint;
var varint_default = _brrp_varint;

// node_modules/ipfs-unixfs-importer/node_modules/multiformats/dist/src/varint.js
function decode7(data, offset = 0) {
  const code9 = varint_default.decode(data, offset);
  return [code9, varint_default.decode.bytes];
}
function encodeTo(int, target, offset = 0) {
  varint_default.encode(int, target, offset);
  return target;
}
function encodingLength(int) {
  return varint_default.encodingLength(int);
}

// node_modules/ipfs-unixfs-importer/node_modules/multiformats/dist/src/hashes/digest.js
function create(code9, digest2) {
  const size = digest2.byteLength;
  const sizeOffset = encodingLength(code9);
  const digestOffset = sizeOffset + encodingLength(size);
  const bytes = new Uint8Array(digestOffset + size);
  encodeTo(code9, bytes, 0);
  encodeTo(size, bytes, sizeOffset);
  bytes.set(digest2, digestOffset);
  return new Digest(code9, size, digest2, bytes);
}
function decode8(multihash) {
  const bytes = coerce(multihash);
  const [code9, sizeOffset] = decode7(bytes);
  const [size, digestOffset] = decode7(bytes.subarray(sizeOffset));
  const digest2 = bytes.subarray(sizeOffset + digestOffset);
  if (digest2.byteLength !== size) {
    throw new Error("Incorrect length");
  }
  return new Digest(code9, size, digest2, bytes);
}
function equals2(a, b) {
  if (a === b) {
    return true;
  } else {
    const data = b;
    return a.code === data.code && a.size === data.size && data.bytes instanceof Uint8Array && equals(a.bytes, data.bytes);
  }
}
var Digest = class {
  code;
  size;
  digest;
  bytes;
  /**
   * Creates a multihash digest.
   */
  constructor(code9, size, digest2, bytes) {
    this.code = code9;
    this.size = size;
    this.digest = digest2;
    this.bytes = bytes;
  }
};

// node_modules/ipfs-unixfs-importer/node_modules/multiformats/dist/src/cid.js
function format(link, base5) {
  const { bytes, version } = link;
  switch (version) {
    case 0:
      return toStringV0(bytes, baseCache(link), base5 ?? base58btc.encoder);
    default:
      return toStringV1(bytes, baseCache(link), base5 ?? base32.encoder);
  }
}
var cache = /* @__PURE__ */ new WeakMap();
function baseCache(cid) {
  const baseCache5 = cache.get(cid);
  if (baseCache5 == null) {
    const baseCache6 = /* @__PURE__ */ new Map();
    cache.set(cid, baseCache6);
    return baseCache6;
  }
  return baseCache5;
}
var CID = class _CID {
  code;
  version;
  multihash;
  bytes;
  "/";
  /**
   * @param version - Version of the CID
   * @param code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param multihash - (Multi)hash of the of the content.
   */
  constructor(version, code9, multihash, bytes) {
    this.code = code9;
    this.version = version;
    this.multihash = multihash;
    this.bytes = bytes;
    this["/"] = bytes;
  }
  /**
   * Signalling `cid.asCID === cid` has been replaced with `cid['/'] === cid.bytes`
   * please either use `CID.asCID(cid)` or switch to new signalling mechanism
   *
   * @deprecated
   */
  get asCID() {
    return this;
  }
  // ArrayBufferView
  get byteOffset() {
    return this.bytes.byteOffset;
  }
  // ArrayBufferView
  get byteLength() {
    return this.bytes.byteLength;
  }
  toV0() {
    switch (this.version) {
      case 0: {
        return this;
      }
      case 1: {
        const { code: code9, multihash } = this;
        if (code9 !== DAG_PB_CODE) {
          throw new Error("Cannot convert a non dag-pb CID to CIDv0");
        }
        if (multihash.code !== SHA_256_CODE) {
          throw new Error("Cannot convert non sha2-256 multihash CID to CIDv0");
        }
        return _CID.createV0(multihash);
      }
      default: {
        throw Error(`Can not convert CID version ${this.version} to version 0. This is a bug please report`);
      }
    }
  }
  toV1() {
    switch (this.version) {
      case 0: {
        const { code: code9, digest: digest2 } = this.multihash;
        const multihash = create(code9, digest2);
        return _CID.createV1(this.code, multihash);
      }
      case 1: {
        return this;
      }
      default: {
        throw Error(`Can not convert CID version ${this.version} to version 1. This is a bug please report`);
      }
    }
  }
  equals(other) {
    return _CID.equals(this, other);
  }
  static equals(self, other) {
    const unknown = other;
    return unknown != null && self.code === unknown.code && self.version === unknown.version && equals2(self.multihash, unknown.multihash);
  }
  toString(base5) {
    return format(this, base5);
  }
  toJSON() {
    return { "/": format(this) };
  }
  link() {
    return this;
  }
  [Symbol.toStringTag] = "CID";
  // Legacy
  [Symbol.for("nodejs.util.inspect.custom")]() {
    return `CID(${this.toString()})`;
  }
  /**
   * Takes any input `value` and returns a `CID` instance if it was
   * a `CID` otherwise returns `null`. If `value` is instanceof `CID`
   * it will return value back. If `value` is not instance of this CID
   * class, but is compatible CID it will return new instance of this
   * `CID` class. Otherwise returns null.
   *
   * This allows two different incompatible versions of CID library to
   * co-exist and interop as long as binary interface is compatible.
   */
  static asCID(input) {
    if (input == null) {
      return null;
    }
    const value = input;
    if (value instanceof _CID) {
      return value;
    } else if (value["/"] != null && value["/"] === value.bytes || value.asCID === value) {
      const { version, code: code9, multihash, bytes } = value;
      return new _CID(version, code9, multihash, bytes ?? encodeCID(version, code9, multihash.bytes));
    } else if (value[cidSymbol] === true) {
      const { version, multihash, code: code9 } = value;
      const digest2 = decode8(multihash);
      return _CID.create(version, code9, digest2);
    } else {
      return null;
    }
  }
  /**
   * @param version - Version of the CID
   * @param code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param digest - (Multi)hash of the of the content.
   */
  static create(version, code9, digest2) {
    if (typeof code9 !== "number") {
      throw new Error("String codecs are no longer supported");
    }
    if (!(digest2.bytes instanceof Uint8Array)) {
      throw new Error("Invalid digest");
    }
    switch (version) {
      case 0: {
        if (code9 !== DAG_PB_CODE) {
          throw new Error(`Version 0 CID must use dag-pb (code: ${DAG_PB_CODE}) block encoding`);
        } else {
          return new _CID(version, code9, digest2, digest2.bytes);
        }
      }
      case 1: {
        const bytes = encodeCID(version, code9, digest2.bytes);
        return new _CID(version, code9, digest2, bytes);
      }
      default: {
        throw new Error("Invalid version");
      }
    }
  }
  /**
   * Simplified version of `create` for CIDv0.
   */
  static createV0(digest2) {
    return _CID.create(0, DAG_PB_CODE, digest2);
  }
  /**
   * Simplified version of `create` for CIDv1.
   *
   * @param code - Content encoding format code.
   * @param digest - Multihash of the content.
   */
  static createV1(code9, digest2) {
    return _CID.create(1, code9, digest2);
  }
  /**
   * Decoded a CID from its binary representation. The byte array must contain
   * only the CID with no additional bytes.
   *
   * An error will be thrown if the bytes provided do not contain a valid
   * binary representation of a CID.
   */
  static decode(bytes) {
    const [cid, remainder] = _CID.decodeFirst(bytes);
    if (remainder.length !== 0) {
      throw new Error("Incorrect length");
    }
    return cid;
  }
  /**
   * Decoded a CID from its binary representation at the beginning of a byte
   * array.
   *
   * Returns an array with the first element containing the CID and the second
   * element containing the remainder of the original byte array. The remainder
   * will be a zero-length byte array if the provided bytes only contained a
   * binary CID representation.
   */
  static decodeFirst(bytes) {
    const specs = _CID.inspectBytes(bytes);
    const prefixSize = specs.size - specs.multihashSize;
    const multihashBytes = coerce(bytes.subarray(prefixSize, prefixSize + specs.multihashSize));
    if (multihashBytes.byteLength !== specs.multihashSize) {
      throw new Error("Incorrect length");
    }
    const digestBytes = multihashBytes.subarray(specs.multihashSize - specs.digestSize);
    const digest2 = new Digest(specs.multihashCode, specs.digestSize, digestBytes, multihashBytes);
    const cid = specs.version === 0 ? _CID.createV0(digest2) : _CID.createV1(specs.codec, digest2);
    return [cid, bytes.subarray(specs.size)];
  }
  /**
   * Inspect the initial bytes of a CID to determine its properties.
   *
   * Involves decoding up to 4 varints. Typically this will require only 4 to 6
   * bytes but for larger multicodec code values and larger multihash digest
   * lengths these varints can be quite large. It is recommended that at least
   * 10 bytes be made available in the `initialBytes` argument for a complete
   * inspection.
   */
  static inspectBytes(initialBytes) {
    let offset = 0;
    const next = () => {
      const [i, length5] = decode7(initialBytes.subarray(offset));
      offset += length5;
      return i;
    };
    let version = next();
    let codec = DAG_PB_CODE;
    if (version === 18) {
      version = 0;
      offset = 0;
    } else {
      codec = next();
    }
    if (version !== 0 && version !== 1) {
      throw new RangeError(`Invalid CID version ${version}`);
    }
    const prefixSize = offset;
    const multihashCode = next();
    const digestSize = next();
    const size = offset + digestSize;
    const multihashSize = size - prefixSize;
    return { version, codec, multihashCode, digestSize, multihashSize, size };
  }
  /**
   * Takes cid in a string representation and creates an instance. If `base`
   * decoder is not provided will use a default from the configuration. It will
   * throw an error if encoding of the CID is not compatible with supplied (or
   * a default decoder).
   */
  static parse(source, base5) {
    const [prefix, bytes] = parseCIDtoBytes(source, base5);
    const cid = _CID.decode(bytes);
    if (cid.version === 0 && source[0] !== "Q") {
      throw Error("Version 0 CID string must not include multibase prefix");
    }
    baseCache(cid).set(prefix, source);
    return cid;
  }
};
function parseCIDtoBytes(source, base5) {
  switch (source[0]) {
    // CIDv0 is parsed differently
    case "Q": {
      const decoder = base5 ?? base58btc;
      return [
        base58btc.prefix,
        decoder.decode(`${base58btc.prefix}${source}`)
      ];
    }
    case base58btc.prefix: {
      const decoder = base5 ?? base58btc;
      return [base58btc.prefix, decoder.decode(source)];
    }
    case base32.prefix: {
      const decoder = base5 ?? base32;
      return [base32.prefix, decoder.decode(source)];
    }
    case base36.prefix: {
      const decoder = base5 ?? base36;
      return [base36.prefix, decoder.decode(source)];
    }
    default: {
      if (base5 == null) {
        throw Error("To parse non base32, base36 or base58btc encoded CID multibase decoder must be provided");
      }
      return [source[0], base5.decode(source)];
    }
  }
}
function toStringV0(bytes, cache5, base5) {
  const { prefix } = base5;
  if (prefix !== base58btc.prefix) {
    throw Error(`Cannot string encode V0 in ${base5.name} encoding`);
  }
  const cid = cache5.get(prefix);
  if (cid == null) {
    const cid2 = base5.encode(bytes).slice(1);
    cache5.set(prefix, cid2);
    return cid2;
  } else {
    return cid;
  }
}
function toStringV1(bytes, cache5, base5) {
  const { prefix } = base5;
  const cid = cache5.get(prefix);
  if (cid == null) {
    const cid2 = base5.encode(bytes);
    cache5.set(prefix, cid2);
    return cid2;
  } else {
    return cid;
  }
}
var DAG_PB_CODE = 112;
var SHA_256_CODE = 18;
function encodeCID(version, code9, multihash) {
  const codeOffset = encodingLength(version);
  const hashOffset = codeOffset + encodingLength(code9);
  const bytes = new Uint8Array(hashOffset + multihash.byteLength);
  encodeTo(version, bytes, 0);
  encodeTo(code9, bytes, codeOffset);
  bytes.set(multihash, hashOffset);
  return bytes;
}
var cidSymbol = Symbol.for("@ipld/js-cid/CID");

// node_modules/ipfs-unixfs-importer/node_modules/multiformats/dist/src/hashes/hasher.js
function from2({ name: name3, code: code9, encode: encode12 }) {
  return new Hasher(name3, code9, encode12);
}
var Hasher = class {
  name;
  code;
  encode;
  constructor(name3, code9, encode12) {
    this.name = name3;
    this.code = code9;
    this.encode = encode12;
  }
  digest(input) {
    if (input instanceof Uint8Array) {
      const result = this.encode(input);
      return result instanceof Uint8Array ? create(this.code, result) : result.then((digest2) => create(this.code, digest2));
    } else {
      throw Error("Unknown type, must be binary type");
    }
  }
};

// node_modules/ipfs-unixfs-importer/node_modules/multiformats/dist/src/hashes/sha2-browser.js
function sha(name3) {
  return async (data) => new Uint8Array(await crypto.subtle.digest(name3, data));
}
var sha256 = from2({
  name: "sha2-256",
  code: 18,
  encode: sha("SHA-256")
});
var sha512 = from2({
  name: "sha2-512",
  code: 19,
  encode: sha("SHA-512")
});

// node_modules/ipfs-unixfs-importer/dist/src/utils/persist.js
var persist = async (buffer, blockstore, options) => {
  if (options.codec == null) {
    options.codec = src_exports;
  }
  const multihash = await sha256.digest(buffer);
  const cid = CID.create(options.cidVersion, options.codec.code, multihash);
  await blockstore.put(cid, buffer, options);
  return cid;
};

// node_modules/ipfs-unixfs-importer/dist/src/dag-builder/buffer-importer.js
function defaultBufferImporter(options) {
  return async function* bufferImporter(file, blockstore) {
    let bytesWritten = 0n;
    for await (let block of file.content) {
      yield async () => {
        let unixfs2;
        const opts = {
          codec: src_exports,
          cidVersion: options.cidVersion,
          onProgress: options.onProgress
        };
        if (options.rawLeaves) {
          opts.codec = raw_exports;
          opts.cidVersion = 1;
        } else {
          unixfs2 = new UnixFS({
            type: options.leafType,
            data: block
          });
          block = encode({
            Data: unixfs2.marshal(),
            Links: []
          });
        }
        const cid = await persist(block, blockstore, opts);
        bytesWritten += BigInt(block.byteLength);
        options.onProgress?.(new CustomProgressEvent("unixfs:importer:progress:file:write", {
          bytesWritten,
          cid,
          path: file.path
        }));
        return {
          cid,
          unixfs: unixfs2,
          size: BigInt(block.length),
          block
        };
      };
    }
  };
}

// node_modules/ipfs-unixfs-importer/dist/src/errors.js
var InvalidParametersError = class _InvalidParametersError extends Error {
  static name = "InvalidParametersError";
  static code = "ERR_INVALID_PARAMS";
  name = _InvalidParametersError.name;
  code = _InvalidParametersError.code;
  constructor(message2 = "Invalid parameters") {
    super(message2);
  }
};
var InvalidContentError = class _InvalidContentError extends Error {
  static name = "InvalidContentError";
  static code = "ERR_INVALID_CONTENT";
  name = _InvalidContentError.name;
  code = _InvalidContentError.code;
  constructor(message2 = "Invalid content") {
    super(message2);
  }
};

// node_modules/ipfs-unixfs-importer/dist/src/dag-builder/dir.js
var defaultDirBuilder = async (dir, blockstore, options) => {
  const unixfs2 = new UnixFS({
    type: "directory",
    mtime: dir.mtime,
    mode: dir.mode
  });
  const block = encode(prepare({ Data: unixfs2.marshal() }));
  const cid = await persist(block, blockstore, options);
  const path = dir.path;
  return {
    cid,
    path,
    unixfs: unixfs2,
    size: BigInt(block.length),
    originalPath: dir.originalPath,
    block
  };
};

// node_modules/ipfs-unixfs-importer/dist/src/dag-builder/file.js
async function* buildFileBatch(file, blockstore, options) {
  let count = -1;
  let previous;
  for await (const entry of parallelBatch(options.bufferImporter(file, blockstore), options.blockWriteConcurrency)) {
    count++;
    if (count === 0) {
      previous = {
        ...entry,
        single: true
      };
      continue;
    } else if (count === 1 && previous != null) {
      yield {
        ...previous,
        block: void 0,
        single: void 0
      };
      previous = void 0;
    }
    yield {
      ...entry,
      block: void 0
    };
  }
  if (previous != null) {
    yield previous;
  }
}
function isSingleBlockImport(result) {
  return result.single === true;
}
var reduce = (file, blockstore, options) => {
  const reducer = async function(leaves) {
    if (leaves.length === 1 && isSingleBlockImport(leaves[0]) && options.reduceSingleLeafToSelf) {
      const leaf = leaves[0];
      let node2 = leaf.block;
      if (isSingleBlockImport(leaf) && (file.mtime !== void 0 || file.mode !== void 0)) {
        leaf.unixfs = new UnixFS({
          type: "file",
          mtime: file.mtime,
          mode: file.mode,
          data: leaf.block
        });
        node2 = { Data: leaf.unixfs.marshal(), Links: [] };
        leaf.block = encode(prepare(node2));
        leaf.cid = await persist(leaf.block, blockstore, {
          ...options,
          cidVersion: options.cidVersion
        });
        leaf.size = BigInt(leaf.block.length);
      }
      options.onProgress?.(new CustomProgressEvent("unixfs:importer:progress:file:layout", {
        cid: leaf.cid,
        path: leaf.originalPath
      }));
      return {
        cid: leaf.cid,
        path: file.path,
        unixfs: leaf.unixfs,
        size: leaf.size,
        originalPath: leaf.originalPath
      };
    }
    const f = new UnixFS({
      type: "file",
      mtime: file.mtime,
      mode: file.mode
    });
    const links = leaves.filter((leaf) => {
      if (leaf.cid.code === code4 && leaf.size > 0) {
        return true;
      }
      if (leaf.unixfs != null && leaf.unixfs.data == null && leaf.unixfs.fileSize() > 0n) {
        return true;
      }
      return Boolean(leaf.unixfs?.data?.length);
    }).map((leaf) => {
      if (leaf.cid.code === code4) {
        f.addBlockSize(leaf.size);
        return {
          Name: "",
          Tsize: Number(leaf.size),
          Hash: leaf.cid
        };
      }
      if (leaf.unixfs?.data == null) {
        f.addBlockSize(leaf.unixfs?.fileSize() ?? 0n);
      } else {
        f.addBlockSize(BigInt(leaf.unixfs.data.length));
      }
      return {
        Name: "",
        Tsize: Number(leaf.size),
        Hash: leaf.cid
      };
    });
    const node = {
      Data: f.marshal(),
      Links: links
    };
    const block = encode(prepare(node));
    const cid = await persist(block, blockstore, options);
    options.onProgress?.(new CustomProgressEvent("unixfs:importer:progress:file:layout", {
      cid,
      path: file.originalPath
    }));
    return {
      cid,
      path: file.path,
      unixfs: f,
      size: BigInt(block.length + node.Links.reduce((acc, curr) => acc + (curr.Tsize ?? 0), 0)),
      originalPath: file.originalPath,
      block
    };
  };
  return reducer;
};
var defaultFileBuilder = async (file, block, options) => {
  return options.layout(buildFileBatch(file, block, options), reduce(file, block, options));
};

// node_modules/ipfs-unixfs-importer/dist/src/dag-builder/index.js
function isIterable(thing) {
  return Symbol.iterator in thing;
}
function isAsyncIterable2(thing) {
  return Symbol.asyncIterator in thing;
}
function contentAsAsyncIterable(content) {
  try {
    if (content instanceof Uint8Array) {
      return async function* () {
        yield content;
      }();
    } else if (isIterable(content)) {
      return async function* () {
        yield* content;
      }();
    } else if (isAsyncIterable2(content)) {
      return content;
    }
  } catch {
    throw new InvalidContentError("Content was invalid");
  }
  throw new InvalidContentError("Content was invalid");
}
function defaultDagBuilder(options) {
  return async function* dagBuilder(source, blockstore) {
    for await (const entry of source) {
      let originalPath;
      if (entry.path != null) {
        originalPath = entry.path;
        entry.path = entry.path.split("/").filter((path) => path != null && path !== ".").join("/");
      }
      if (isFileCandidate(entry)) {
        const file = {
          path: entry.path,
          mtime: entry.mtime,
          mode: entry.mode,
          content: async function* () {
            let bytesRead = 0n;
            for await (const chunk of options.chunker(options.chunkValidator(contentAsAsyncIterable(entry.content)))) {
              const currentChunkSize = BigInt(chunk.byteLength);
              bytesRead += currentChunkSize;
              options.onProgress?.(new CustomProgressEvent("unixfs:importer:progress:file:read", {
                bytesRead,
                chunkSize: currentChunkSize,
                path: entry.path
              }));
              yield chunk;
            }
          }(),
          originalPath
        };
        const fileBuilder = options.fileBuilder ?? defaultFileBuilder;
        yield async () => fileBuilder(file, blockstore, options);
      } else if (entry.path != null) {
        const dir = {
          path: entry.path,
          mtime: entry.mtime,
          mode: entry.mode,
          originalPath
        };
        const dirBuilder = options.dirBuilder ?? defaultDirBuilder;
        yield async () => dirBuilder(dir, blockstore, options);
      } else {
        throw new Error("Import candidate must have content or path or both");
      }
    }
  };
}
function isFileCandidate(entry) {
  return entry.content != null;
}

// node_modules/ipfs-unixfs-importer/dist/src/dag-builder/validate-chunks.js
var defaultChunkValidator = () => {
  return async function* validateChunks(source) {
    for await (const content of source) {
      if (content.length === void 0) {
        throw new InvalidContentError("Content was invalid");
      }
      if (typeof content === "string" || content instanceof String) {
        yield fromString(content.toString());
      } else if (Array.isArray(content)) {
        yield Uint8Array.from(content);
      } else if (content instanceof Uint8Array) {
        yield content;
      } else {
        throw new InvalidContentError("Content was invalid");
      }
    }
  };
};

// node_modules/ipfs-unixfs-importer/dist/src/layout/balanced.js
var DEFAULT_MAX_CHILDREN_PER_NODE = 174;
function balanced(options) {
  const maxChildrenPerNode = options?.maxChildrenPerNode ?? DEFAULT_MAX_CHILDREN_PER_NODE;
  return async function balancedLayout(source, reduce2) {
    const roots = [];
    for await (const chunked of src_default5(source, maxChildrenPerNode)) {
      roots.push(await reduce2(chunked));
    }
    if (roots.length > 1) {
      return balancedLayout(roots, reduce2);
    }
    return roots[0];
  };
}

// node_modules/ipfs-unixfs-importer/dist/src/dir.js
var Dir = class {
  options;
  root;
  dir;
  path;
  dirty;
  flat;
  parent;
  parentKey;
  unixfs;
  mode;
  mtime;
  cid;
  size;
  nodeSize;
  constructor(props, options) {
    this.options = options ?? {};
    this.root = props.root;
    this.dir = props.dir;
    this.path = props.path;
    this.dirty = props.dirty;
    this.flat = props.flat;
    this.parent = props.parent;
    this.parentKey = props.parentKey;
    this.unixfs = props.unixfs;
    this.mode = props.mode;
    this.mtime = props.mtime;
  }
};
var CID_V0 = CID.parse("QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn");
var CID_V1 = CID.parse("zdj7WbTaiJT1fgatdet9Ei9iDB5hdCxkbVyhyh8YTUnXMiwYi");

// node_modules/ipfs-unixfs-importer/dist/src/dir-flat.js
var DirFlat = class extends Dir {
  _children;
  constructor(props, options) {
    super(props, options);
    this._children = /* @__PURE__ */ new Map();
  }
  async put(name3, value) {
    this.cid = void 0;
    this.size = void 0;
    this.nodeSize = void 0;
    this._children.set(name3, value);
  }
  async get(name3) {
    return Promise.resolve(this._children.get(name3));
  }
  childCount() {
    return this._children.size;
  }
  directChildrenCount() {
    return this.childCount();
  }
  onlyChild() {
    return this._children.values().next().value;
  }
  *eachChildSeries() {
    for (const [key, child] of this._children.entries()) {
      yield {
        key,
        child
      };
    }
  }
  estimateNodeSize() {
    if (this.nodeSize !== void 0) {
      return this.nodeSize;
    }
    this.nodeSize = 0;
    for (const [name3, child] of this._children.entries()) {
      if (child.size != null && child.cid != null) {
        this.nodeSize += name3.length + (this.options.cidVersion === 1 ? CID_V1.bytes.byteLength : CID_V0.bytes.byteLength);
      }
    }
    return this.nodeSize;
  }
  async *flush(block) {
    const links = [];
    for (const [name3, child] of this._children.entries()) {
      let result = child;
      if (child instanceof Dir) {
        for await (const entry of child.flush(block)) {
          result = entry;
          yield entry;
        }
      }
      if (result.size != null && result.cid != null) {
        links.push({
          Name: name3,
          Tsize: Number(result.size),
          Hash: result.cid
        });
      }
    }
    const unixfs2 = new UnixFS({
      type: "directory",
      mtime: this.mtime,
      mode: this.mode
    });
    const node = { Data: unixfs2.marshal(), Links: links };
    const buffer = encode(prepare(node));
    const cid = await persist(buffer, block, this.options);
    const size = buffer.length + node.Links.reduce(
      /**
       * @param {number} acc
       * @param {PBLink} curr
       */
      (acc, curr) => acc + (curr.Tsize ?? 0),
      0
    );
    this.cid = cid;
    this.size = size;
    yield {
      cid,
      unixfs: unixfs2,
      path: this.path,
      size: BigInt(size)
    };
  }
};

// node_modules/@multiformats/murmur3/node_modules/multiformats/dist/src/bytes.js
var bytes_exports = {};
__export(bytes_exports, {
  coerce: () => coerce2,
  empty: () => empty2,
  equals: () => equals3,
  fromHex: () => fromHex,
  fromString: () => fromString2,
  isBinary: () => isBinary,
  toHex: () => toHex,
  toString: () => toString
});
var empty2 = new Uint8Array(0);
function toHex(d) {
  return d.reduce((hex, byte) => hex + byte.toString(16).padStart(2, "0"), "");
}
function fromHex(hex) {
  const hexes = hex.match(/../g);
  return hexes != null ? new Uint8Array(hexes.map((b) => parseInt(b, 16))) : empty2;
}
function equals3(aa, bb) {
  if (aa === bb) {
    return true;
  }
  if (aa.byteLength !== bb.byteLength) {
    return false;
  }
  for (let ii = 0; ii < aa.byteLength; ii++) {
    if (aa[ii] !== bb[ii]) {
      return false;
    }
  }
  return true;
}
function coerce2(o) {
  if (o instanceof Uint8Array && o.constructor.name === "Uint8Array") {
    return o;
  }
  if (o instanceof ArrayBuffer) {
    return new Uint8Array(o);
  }
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength);
  }
  throw new Error("Unknown type, must be binary type");
}
function isBinary(o) {
  return o instanceof ArrayBuffer || ArrayBuffer.isView(o);
}
function fromString2(str) {
  return new TextEncoder().encode(str);
}
function toString(b) {
  return new TextDecoder().decode(b);
}

// node_modules/@multiformats/murmur3/node_modules/multiformats/dist/src/vendor/base-x.js
function base2(ALPHABET, name3) {
  if (ALPHABET.length >= 255) {
    throw new TypeError("Alphabet too long");
  }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) {
      throw new TypeError(x + " is ambiguous");
    }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256);
  var iFACTOR = Math.log(256) / Math.log(BASE);
  function encode12(source) {
    if (source instanceof Uint8Array)
      ;
    else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) {
      throw new TypeError("Expected Uint8Array");
    }
    if (source.length === 0) {
      return "";
    }
    var zeroes = 0;
    var length5 = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
    var size = (pend - pbegin) * iFACTOR + 1 >>> 0;
    var b58 = new Uint8Array(size);
    while (pbegin !== pend) {
      var carry = source[pbegin];
      var i2 = 0;
      for (var it1 = size - 1; (carry !== 0 || i2 < length5) && it1 !== -1; it1--, i2++) {
        carry += 256 * b58[it1] >>> 0;
        b58[it1] = carry % BASE >>> 0;
        carry = carry / BASE >>> 0;
      }
      if (carry !== 0) {
        throw new Error("Non-zero carry");
      }
      length5 = i2;
      pbegin++;
    }
    var it2 = size - length5;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
    var str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) {
      str += ALPHABET.charAt(b58[it2]);
    }
    return str;
  }
  function decodeUnsafe(source) {
    if (typeof source !== "string") {
      throw new TypeError("Expected String");
    }
    if (source.length === 0) {
      return new Uint8Array();
    }
    var psz = 0;
    if (source[psz] === " ") {
      return;
    }
    var zeroes = 0;
    var length5 = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
    var size = (source.length - psz) * FACTOR + 1 >>> 0;
    var b256 = new Uint8Array(size);
    while (source[psz]) {
      var carry = BASE_MAP[source.charCodeAt(psz)];
      if (carry === 255) {
        return;
      }
      var i2 = 0;
      for (var it3 = size - 1; (carry !== 0 || i2 < length5) && it3 !== -1; it3--, i2++) {
        carry += BASE * b256[it3] >>> 0;
        b256[it3] = carry % 256 >>> 0;
        carry = carry / 256 >>> 0;
      }
      if (carry !== 0) {
        throw new Error("Non-zero carry");
      }
      length5 = i2;
      psz++;
    }
    if (source[psz] === " ") {
      return;
    }
    var it4 = size - length5;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size - it4));
    var j2 = zeroes;
    while (it4 !== size) {
      vch[j2++] = b256[it4++];
    }
    return vch;
  }
  function decode22(string) {
    var buffer = decodeUnsafe(string);
    if (buffer) {
      return buffer;
    }
    throw new Error(`Non-${name3} character`);
  }
  return {
    encode: encode12,
    decodeUnsafe,
    decode: decode22
  };
}
var src2 = base2;
var _brrp__multiformats_scope_baseX2 = src2;
var base_x_default2 = _brrp__multiformats_scope_baseX2;

// node_modules/@multiformats/murmur3/node_modules/multiformats/dist/src/bases/base.js
var Encoder2 = class {
  name;
  prefix;
  baseEncode;
  constructor(name3, prefix, baseEncode) {
    this.name = name3;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
  }
  encode(bytes) {
    if (bytes instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes)}`;
    } else {
      throw Error("Unknown type, must be binary type");
    }
  }
};
var Decoder2 = class {
  name;
  prefix;
  baseDecode;
  prefixCodePoint;
  constructor(name3, prefix, baseDecode) {
    this.name = name3;
    this.prefix = prefix;
    const prefixCodePoint = prefix.codePointAt(0);
    if (prefixCodePoint === void 0) {
      throw new Error("Invalid prefix character");
    }
    this.prefixCodePoint = prefixCodePoint;
    this.baseDecode = baseDecode;
  }
  decode(text) {
    if (typeof text === "string") {
      if (text.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`);
      }
      return this.baseDecode(text.slice(this.prefix.length));
    } else {
      throw Error("Can only multibase decode strings");
    }
  }
  or(decoder) {
    return or2(this, decoder);
  }
};
var ComposedDecoder2 = class {
  decoders;
  constructor(decoders) {
    this.decoders = decoders;
  }
  or(decoder) {
    return or2(this, decoder);
  }
  decode(input) {
    const prefix = input[0];
    const decoder = this.decoders[prefix];
    if (decoder != null) {
      return decoder.decode(input);
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`);
    }
  }
};
function or2(left, right) {
  return new ComposedDecoder2({
    ...left.decoders ?? { [left.prefix]: left },
    ...right.decoders ?? { [right.prefix]: right }
  });
}
var Codec2 = class {
  name;
  prefix;
  baseEncode;
  baseDecode;
  encoder;
  decoder;
  constructor(name3, prefix, baseEncode, baseDecode) {
    this.name = name3;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder2(name3, prefix, baseEncode);
    this.decoder = new Decoder2(name3, prefix, baseDecode);
  }
  encode(input) {
    return this.encoder.encode(input);
  }
  decode(input) {
    return this.decoder.decode(input);
  }
};
function from3({ name: name3, prefix, encode: encode12, decode: decode22 }) {
  return new Codec2(name3, prefix, encode12, decode22);
}
function baseX2({ name: name3, prefix, alphabet }) {
  const { encode: encode12, decode: decode22 } = base_x_default2(alphabet, name3);
  return from3({
    prefix,
    name: name3,
    encode: encode12,
    decode: (text) => coerce2(decode22(text))
  });
}
function decode9(string, alphabetIdx, bitsPerChar, name3) {
  let end = string.length;
  while (string[end - 1] === "=") {
    --end;
  }
  const out = new Uint8Array(end * bitsPerChar / 8 | 0);
  let bits = 0;
  let buffer = 0;
  let written = 0;
  for (let i = 0; i < end; ++i) {
    const value = alphabetIdx[string[i]];
    if (value === void 0) {
      throw new SyntaxError(`Non-${name3} character`);
    }
    buffer = buffer << bitsPerChar | value;
    bits += bitsPerChar;
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 255 & buffer >> bits;
    }
  }
  if (bits >= bitsPerChar || (255 & buffer << 8 - bits) !== 0) {
    throw new SyntaxError("Unexpected end of data");
  }
  return out;
}
function encode5(data, alphabet, bitsPerChar) {
  const pad = alphabet[alphabet.length - 1] === "=";
  const mask = (1 << bitsPerChar) - 1;
  let out = "";
  let bits = 0;
  let buffer = 0;
  for (let i = 0; i < data.length; ++i) {
    buffer = buffer << 8 | data[i];
    bits += 8;
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet[mask & buffer >> bits];
    }
  }
  if (bits !== 0) {
    out += alphabet[mask & buffer << bitsPerChar - bits];
  }
  if (pad) {
    while ((out.length * bitsPerChar & 7) !== 0) {
      out += "=";
    }
  }
  return out;
}
function createAlphabetIdx2(alphabet) {
  const alphabetIdx = {};
  for (let i = 0; i < alphabet.length; ++i) {
    alphabetIdx[alphabet[i]] = i;
  }
  return alphabetIdx;
}
function rfc46482({ name: name3, prefix, bitsPerChar, alphabet }) {
  const alphabetIdx = createAlphabetIdx2(alphabet);
  return from3({
    prefix,
    name: name3,
    encode(input) {
      return encode5(input, alphabet, bitsPerChar);
    },
    decode(input) {
      return decode9(input, alphabetIdx, bitsPerChar, name3);
    }
  });
}

// node_modules/@multiformats/murmur3/node_modules/multiformats/dist/src/bases/base32.js
var base322 = rfc46482({
  prefix: "b",
  name: "base32",
  alphabet: "abcdefghijklmnopqrstuvwxyz234567",
  bitsPerChar: 5
});
var base32upper2 = rfc46482({
  prefix: "B",
  name: "base32upper",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZ234567",
  bitsPerChar: 5
});
var base32pad2 = rfc46482({
  prefix: "c",
  name: "base32pad",
  alphabet: "abcdefghijklmnopqrstuvwxyz234567=",
  bitsPerChar: 5
});
var base32padupper2 = rfc46482({
  prefix: "C",
  name: "base32padupper",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=",
  bitsPerChar: 5
});
var base32hex2 = rfc46482({
  prefix: "v",
  name: "base32hex",
  alphabet: "0123456789abcdefghijklmnopqrstuv",
  bitsPerChar: 5
});
var base32hexupper2 = rfc46482({
  prefix: "V",
  name: "base32hexupper",
  alphabet: "0123456789ABCDEFGHIJKLMNOPQRSTUV",
  bitsPerChar: 5
});
var base32hexpad2 = rfc46482({
  prefix: "t",
  name: "base32hexpad",
  alphabet: "0123456789abcdefghijklmnopqrstuv=",
  bitsPerChar: 5
});
var base32hexpadupper2 = rfc46482({
  prefix: "T",
  name: "base32hexpadupper",
  alphabet: "0123456789ABCDEFGHIJKLMNOPQRSTUV=",
  bitsPerChar: 5
});
var base32z2 = rfc46482({
  prefix: "h",
  name: "base32z",
  alphabet: "ybndrfg8ejkmcpqxot1uwisza345h769",
  bitsPerChar: 5
});

// node_modules/@multiformats/murmur3/node_modules/multiformats/dist/src/bases/base36.js
var base362 = baseX2({
  prefix: "k",
  name: "base36",
  alphabet: "0123456789abcdefghijklmnopqrstuvwxyz"
});
var base36upper2 = baseX2({
  prefix: "K",
  name: "base36upper",
  alphabet: "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ"
});

// node_modules/@multiformats/murmur3/node_modules/multiformats/dist/src/bases/base58.js
var base58btc2 = baseX2({
  name: "base58btc",
  prefix: "z",
  alphabet: "123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz"
});
var base58flickr2 = baseX2({
  name: "base58flickr",
  prefix: "Z",
  alphabet: "123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ"
});

// node_modules/@multiformats/murmur3/node_modules/multiformats/dist/src/vendor/varint.js
var encode_12 = encode6;
var MSB2 = 128;
var REST2 = 127;
var MSBALL2 = ~REST2;
var INT2 = Math.pow(2, 31);
function encode6(num, out, offset) {
  out = out || [];
  offset = offset || 0;
  var oldOffset = offset;
  while (num >= INT2) {
    out[offset++] = num & 255 | MSB2;
    num /= 128;
  }
  while (num & MSBALL2) {
    out[offset++] = num & 255 | MSB2;
    num >>>= 7;
  }
  out[offset] = num | 0;
  encode6.bytes = offset - oldOffset + 1;
  return out;
}
var decode10 = read2;
var MSB$12 = 128;
var REST$12 = 127;
function read2(buf, offset) {
  var res = 0, offset = offset || 0, shift = 0, counter = offset, b, l = buf.length;
  do {
    if (counter >= l) {
      read2.bytes = 0;
      throw new RangeError("Could not decode varint");
    }
    b = buf[counter++];
    res += shift < 28 ? (b & REST$12) << shift : (b & REST$12) * Math.pow(2, shift);
    shift += 7;
  } while (b >= MSB$12);
  read2.bytes = counter - offset;
  return res;
}
var N12 = Math.pow(2, 7);
var N22 = Math.pow(2, 14);
var N32 = Math.pow(2, 21);
var N42 = Math.pow(2, 28);
var N52 = Math.pow(2, 35);
var N62 = Math.pow(2, 42);
var N72 = Math.pow(2, 49);
var N82 = Math.pow(2, 56);
var N92 = Math.pow(2, 63);
var length2 = function(value) {
  return value < N12 ? 1 : value < N22 ? 2 : value < N32 ? 3 : value < N42 ? 4 : value < N52 ? 5 : value < N62 ? 6 : value < N72 ? 7 : value < N82 ? 8 : value < N92 ? 9 : 10;
};
var varint2 = {
  encode: encode_12,
  decode: decode10,
  encodingLength: length2
};
var _brrp_varint2 = varint2;
var varint_default2 = _brrp_varint2;

// node_modules/@multiformats/murmur3/node_modules/multiformats/dist/src/varint.js
function decode11(data, offset = 0) {
  const code9 = varint_default2.decode(data, offset);
  return [code9, varint_default2.decode.bytes];
}
function encodeTo2(int, target, offset = 0) {
  varint_default2.encode(int, target, offset);
  return target;
}
function encodingLength2(int) {
  return varint_default2.encodingLength(int);
}

// node_modules/@multiformats/murmur3/node_modules/multiformats/dist/src/hashes/digest.js
function create2(code9, digest2) {
  const size = digest2.byteLength;
  const sizeOffset = encodingLength2(code9);
  const digestOffset = sizeOffset + encodingLength2(size);
  const bytes = new Uint8Array(digestOffset + size);
  encodeTo2(code9, bytes, 0);
  encodeTo2(size, bytes, sizeOffset);
  bytes.set(digest2, digestOffset);
  return new Digest2(code9, size, digest2, bytes);
}
function decode12(multihash) {
  const bytes = coerce2(multihash);
  const [code9, sizeOffset] = decode11(bytes);
  const [size, digestOffset] = decode11(bytes.subarray(sizeOffset));
  const digest2 = bytes.subarray(sizeOffset + digestOffset);
  if (digest2.byteLength !== size) {
    throw new Error("Incorrect length");
  }
  return new Digest2(code9, size, digest2, bytes);
}
function equals4(a, b) {
  if (a === b) {
    return true;
  } else {
    const data = b;
    return a.code === data.code && a.size === data.size && data.bytes instanceof Uint8Array && equals3(a.bytes, data.bytes);
  }
}
var Digest2 = class {
  code;
  size;
  digest;
  bytes;
  /**
   * Creates a multihash digest.
   */
  constructor(code9, size, digest2, bytes) {
    this.code = code9;
    this.size = size;
    this.digest = digest2;
    this.bytes = bytes;
  }
};

// node_modules/@multiformats/murmur3/node_modules/multiformats/dist/src/cid.js
function format2(link, base5) {
  const { bytes, version } = link;
  switch (version) {
    case 0:
      return toStringV02(bytes, baseCache2(link), base5 ?? base58btc2.encoder);
    default:
      return toStringV12(bytes, baseCache2(link), base5 ?? base322.encoder);
  }
}
var cache2 = /* @__PURE__ */ new WeakMap();
function baseCache2(cid) {
  const baseCache5 = cache2.get(cid);
  if (baseCache5 == null) {
    const baseCache6 = /* @__PURE__ */ new Map();
    cache2.set(cid, baseCache6);
    return baseCache6;
  }
  return baseCache5;
}
var CID2 = class _CID {
  code;
  version;
  multihash;
  bytes;
  "/";
  /**
   * @param version - Version of the CID
   * @param code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param multihash - (Multi)hash of the of the content.
   */
  constructor(version, code9, multihash, bytes) {
    this.code = code9;
    this.version = version;
    this.multihash = multihash;
    this.bytes = bytes;
    this["/"] = bytes;
  }
  /**
   * Signalling `cid.asCID === cid` has been replaced with `cid['/'] === cid.bytes`
   * please either use `CID.asCID(cid)` or switch to new signalling mechanism
   *
   * @deprecated
   */
  get asCID() {
    return this;
  }
  // ArrayBufferView
  get byteOffset() {
    return this.bytes.byteOffset;
  }
  // ArrayBufferView
  get byteLength() {
    return this.bytes.byteLength;
  }
  toV0() {
    switch (this.version) {
      case 0: {
        return this;
      }
      case 1: {
        const { code: code9, multihash } = this;
        if (code9 !== DAG_PB_CODE2) {
          throw new Error("Cannot convert a non dag-pb CID to CIDv0");
        }
        if (multihash.code !== SHA_256_CODE2) {
          throw new Error("Cannot convert non sha2-256 multihash CID to CIDv0");
        }
        return _CID.createV0(multihash);
      }
      default: {
        throw Error(`Can not convert CID version ${this.version} to version 0. This is a bug please report`);
      }
    }
  }
  toV1() {
    switch (this.version) {
      case 0: {
        const { code: code9, digest: digest2 } = this.multihash;
        const multihash = create2(code9, digest2);
        return _CID.createV1(this.code, multihash);
      }
      case 1: {
        return this;
      }
      default: {
        throw Error(`Can not convert CID version ${this.version} to version 1. This is a bug please report`);
      }
    }
  }
  equals(other) {
    return _CID.equals(this, other);
  }
  static equals(self, other) {
    const unknown = other;
    return unknown != null && self.code === unknown.code && self.version === unknown.version && equals4(self.multihash, unknown.multihash);
  }
  toString(base5) {
    return format2(this, base5);
  }
  toJSON() {
    return { "/": format2(this) };
  }
  link() {
    return this;
  }
  [Symbol.toStringTag] = "CID";
  // Legacy
  [Symbol.for("nodejs.util.inspect.custom")]() {
    return `CID(${this.toString()})`;
  }
  /**
   * Takes any input `value` and returns a `CID` instance if it was
   * a `CID` otherwise returns `null`. If `value` is instanceof `CID`
   * it will return value back. If `value` is not instance of this CID
   * class, but is compatible CID it will return new instance of this
   * `CID` class. Otherwise returns null.
   *
   * This allows two different incompatible versions of CID library to
   * co-exist and interop as long as binary interface is compatible.
   */
  static asCID(input) {
    if (input == null) {
      return null;
    }
    const value = input;
    if (value instanceof _CID) {
      return value;
    } else if (value["/"] != null && value["/"] === value.bytes || value.asCID === value) {
      const { version, code: code9, multihash, bytes } = value;
      return new _CID(version, code9, multihash, bytes ?? encodeCID2(version, code9, multihash.bytes));
    } else if (value[cidSymbol2] === true) {
      const { version, multihash, code: code9 } = value;
      const digest2 = decode12(multihash);
      return _CID.create(version, code9, digest2);
    } else {
      return null;
    }
  }
  /**
   * @param version - Version of the CID
   * @param code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param digest - (Multi)hash of the of the content.
   */
  static create(version, code9, digest2) {
    if (typeof code9 !== "number") {
      throw new Error("String codecs are no longer supported");
    }
    if (!(digest2.bytes instanceof Uint8Array)) {
      throw new Error("Invalid digest");
    }
    switch (version) {
      case 0: {
        if (code9 !== DAG_PB_CODE2) {
          throw new Error(`Version 0 CID must use dag-pb (code: ${DAG_PB_CODE2}) block encoding`);
        } else {
          return new _CID(version, code9, digest2, digest2.bytes);
        }
      }
      case 1: {
        const bytes = encodeCID2(version, code9, digest2.bytes);
        return new _CID(version, code9, digest2, bytes);
      }
      default: {
        throw new Error("Invalid version");
      }
    }
  }
  /**
   * Simplified version of `create` for CIDv0.
   */
  static createV0(digest2) {
    return _CID.create(0, DAG_PB_CODE2, digest2);
  }
  /**
   * Simplified version of `create` for CIDv1.
   *
   * @param code - Content encoding format code.
   * @param digest - Multihash of the content.
   */
  static createV1(code9, digest2) {
    return _CID.create(1, code9, digest2);
  }
  /**
   * Decoded a CID from its binary representation. The byte array must contain
   * only the CID with no additional bytes.
   *
   * An error will be thrown if the bytes provided do not contain a valid
   * binary representation of a CID.
   */
  static decode(bytes) {
    const [cid, remainder] = _CID.decodeFirst(bytes);
    if (remainder.length !== 0) {
      throw new Error("Incorrect length");
    }
    return cid;
  }
  /**
   * Decoded a CID from its binary representation at the beginning of a byte
   * array.
   *
   * Returns an array with the first element containing the CID and the second
   * element containing the remainder of the original byte array. The remainder
   * will be a zero-length byte array if the provided bytes only contained a
   * binary CID representation.
   */
  static decodeFirst(bytes) {
    const specs = _CID.inspectBytes(bytes);
    const prefixSize = specs.size - specs.multihashSize;
    const multihashBytes = coerce2(bytes.subarray(prefixSize, prefixSize + specs.multihashSize));
    if (multihashBytes.byteLength !== specs.multihashSize) {
      throw new Error("Incorrect length");
    }
    const digestBytes = multihashBytes.subarray(specs.multihashSize - specs.digestSize);
    const digest2 = new Digest2(specs.multihashCode, specs.digestSize, digestBytes, multihashBytes);
    const cid = specs.version === 0 ? _CID.createV0(digest2) : _CID.createV1(specs.codec, digest2);
    return [cid, bytes.subarray(specs.size)];
  }
  /**
   * Inspect the initial bytes of a CID to determine its properties.
   *
   * Involves decoding up to 4 varints. Typically this will require only 4 to 6
   * bytes but for larger multicodec code values and larger multihash digest
   * lengths these varints can be quite large. It is recommended that at least
   * 10 bytes be made available in the `initialBytes` argument for a complete
   * inspection.
   */
  static inspectBytes(initialBytes) {
    let offset = 0;
    const next = () => {
      const [i, length5] = decode11(initialBytes.subarray(offset));
      offset += length5;
      return i;
    };
    let version = next();
    let codec = DAG_PB_CODE2;
    if (version === 18) {
      version = 0;
      offset = 0;
    } else {
      codec = next();
    }
    if (version !== 0 && version !== 1) {
      throw new RangeError(`Invalid CID version ${version}`);
    }
    const prefixSize = offset;
    const multihashCode = next();
    const digestSize = next();
    const size = offset + digestSize;
    const multihashSize = size - prefixSize;
    return { version, codec, multihashCode, digestSize, multihashSize, size };
  }
  /**
   * Takes cid in a string representation and creates an instance. If `base`
   * decoder is not provided will use a default from the configuration. It will
   * throw an error if encoding of the CID is not compatible with supplied (or
   * a default decoder).
   */
  static parse(source, base5) {
    const [prefix, bytes] = parseCIDtoBytes2(source, base5);
    const cid = _CID.decode(bytes);
    if (cid.version === 0 && source[0] !== "Q") {
      throw Error("Version 0 CID string must not include multibase prefix");
    }
    baseCache2(cid).set(prefix, source);
    return cid;
  }
};
function parseCIDtoBytes2(source, base5) {
  switch (source[0]) {
    // CIDv0 is parsed differently
    case "Q": {
      const decoder = base5 ?? base58btc2;
      return [
        base58btc2.prefix,
        decoder.decode(`${base58btc2.prefix}${source}`)
      ];
    }
    case base58btc2.prefix: {
      const decoder = base5 ?? base58btc2;
      return [base58btc2.prefix, decoder.decode(source)];
    }
    case base322.prefix: {
      const decoder = base5 ?? base322;
      return [base322.prefix, decoder.decode(source)];
    }
    case base362.prefix: {
      const decoder = base5 ?? base362;
      return [base362.prefix, decoder.decode(source)];
    }
    default: {
      if (base5 == null) {
        throw Error("To parse non base32, base36 or base58btc encoded CID multibase decoder must be provided");
      }
      return [source[0], base5.decode(source)];
    }
  }
}
function toStringV02(bytes, cache5, base5) {
  const { prefix } = base5;
  if (prefix !== base58btc2.prefix) {
    throw Error(`Cannot string encode V0 in ${base5.name} encoding`);
  }
  const cid = cache5.get(prefix);
  if (cid == null) {
    const cid2 = base5.encode(bytes).slice(1);
    cache5.set(prefix, cid2);
    return cid2;
  } else {
    return cid;
  }
}
function toStringV12(bytes, cache5, base5) {
  const { prefix } = base5;
  const cid = cache5.get(prefix);
  if (cid == null) {
    const cid2 = base5.encode(bytes);
    cache5.set(prefix, cid2);
    return cid2;
  } else {
    return cid;
  }
}
var DAG_PB_CODE2 = 112;
var SHA_256_CODE2 = 18;
function encodeCID2(version, code9, multihash) {
  const codeOffset = encodingLength2(version);
  const hashOffset = codeOffset + encodingLength2(code9);
  const bytes = new Uint8Array(hashOffset + multihash.byteLength);
  encodeTo2(version, bytes, 0);
  encodeTo2(code9, bytes, codeOffset);
  bytes.set(multihash, hashOffset);
  return bytes;
}
var cidSymbol2 = Symbol.for("@ipld/js-cid/CID");

// node_modules/@multiformats/murmur3/node_modules/multiformats/dist/src/hashes/hasher.js
function from4({ name: name3, code: code9, encode: encode12 }) {
  return new Hasher2(name3, code9, encode12);
}
var Hasher2 = class {
  name;
  code;
  encode;
  constructor(name3, code9, encode12) {
    this.name = name3;
    this.code = code9;
    this.encode = encode12;
  }
  digest(input) {
    if (input instanceof Uint8Array) {
      const result = this.encode(input);
      return result instanceof Uint8Array ? create2(this.code, result) : result.then((digest2) => create2(this.code, digest2));
    } else {
      throw Error("Unknown type, must be binary type");
    }
  }
};

// node_modules/@multiformats/murmur3/src/index.js
var import_murmurhash3js_revisited = __toESM(require_murmurhash3js_revisited());
function fromNumberTo32BitBuf(number) {
  const bytes = new Array(4);
  for (let i = 0; i < 4; i++) {
    bytes[i] = number & 255;
    number = number >> 8;
  }
  return new Uint8Array(bytes);
}
var murmur332 = from4({
  name: "murmur3-32",
  code: 35,
  encode: (input) => fromNumberTo32BitBuf(import_murmurhash3js_revisited.default.x86.hash32(input))
});
var murmur3128 = from4({
  name: "murmur3-128",
  code: 34,
  encode: (input) => bytes_exports.fromHex(import_murmurhash3js_revisited.default.x64.hash128(input))
});
var murmur364 = from4({
  name: "murmur3-x64-64",
  code: 34,
  encode: (input) => bytes_exports.fromHex(import_murmurhash3js_revisited.default.x64.hash128(input)).subarray(0, 8)
});

// node_modules/hamt-sharding/dist/src/bucket.js
var import_sparse_array = __toESM(require_sparse_array(), 1);
var Bucket = class _Bucket {
  _options;
  _popCount;
  _parent;
  _posAtParent;
  _children;
  key;
  constructor(options, parent, posAtParent = 0) {
    this._options = options;
    this._popCount = 0;
    this._parent = parent;
    this._posAtParent = posAtParent;
    this._children = new import_sparse_array.default();
    this.key = null;
  }
  async put(key, value) {
    const place = await this._findNewBucketAndPos(key);
    place.bucket._putAt(place, key, value);
  }
  async get(key) {
    const child = await this._findChild(key);
    if (child != null) {
      return child.value;
    }
  }
  async del(key) {
    const place = await this._findPlace(key);
    const child = place.bucket._at(place.pos);
    if (child != null && child.key === key) {
      place.bucket._delAt(place.pos);
    }
  }
  leafCount() {
    const children = this._children.compactArray();
    return children.reduce((acc, child) => {
      if (child instanceof _Bucket) {
        return acc + child.leafCount();
      }
      return acc + 1;
    }, 0);
  }
  childrenCount() {
    return this._children.length;
  }
  onlyChild() {
    return this._children.get(0);
  }
  *eachLeafSeries() {
    const children = this._children.compactArray();
    for (const child of children) {
      if (child instanceof _Bucket) {
        yield* child.eachLeafSeries();
      } else {
        yield child;
      }
    }
  }
  serialize(map, reduce2) {
    const acc = [];
    return reduce2(this._children.reduce((acc2, child, index) => {
      if (child != null) {
        if (child instanceof _Bucket) {
          acc2.push(child.serialize(map, reduce2));
        } else {
          acc2.push(map(child, index));
        }
      }
      return acc2;
    }, acc));
  }
  async asyncTransform(asyncMap, asyncReduce) {
    return asyncTransformBucket(this, asyncMap, asyncReduce);
  }
  toJSON() {
    return this.serialize(mapNode, reduceNodes);
  }
  prettyPrint() {
    return JSON.stringify(this.toJSON(), null, "  ");
  }
  tableSize() {
    return Math.pow(2, this._options.bits);
  }
  async _findChild(key) {
    const result = await this._findPlace(key);
    const child = result.bucket._at(result.pos);
    if (child instanceof _Bucket) {
      return void 0;
    }
    if (child != null && child.key === key) {
      return child;
    }
  }
  async _findPlace(key) {
    const hashValue = this._options.hash(typeof key === "string" ? fromString(key) : key);
    const index = await hashValue.take(this._options.bits);
    const child = this._children.get(index);
    if (child instanceof _Bucket) {
      return child._findPlace(hashValue);
    }
    return {
      bucket: this,
      pos: index,
      hash: hashValue,
      existingChild: child
    };
  }
  async _findNewBucketAndPos(key) {
    const place = await this._findPlace(key);
    if (place.existingChild != null && place.existingChild.key !== key) {
      const bucket = new _Bucket(this._options, place.bucket, place.pos);
      place.bucket._putObjectAt(place.pos, bucket);
      const newPlace = await bucket._findPlace(place.existingChild.hash);
      newPlace.bucket._putAt(newPlace, place.existingChild.key, place.existingChild.value);
      return bucket._findNewBucketAndPos(place.hash);
    }
    return place;
  }
  _putAt(place, key, value) {
    this._putObjectAt(place.pos, {
      key,
      value,
      hash: place.hash
    });
  }
  _putObjectAt(pos, object) {
    if (this._children.get(pos) == null) {
      this._popCount++;
    }
    this._children.set(pos, object);
  }
  _delAt(pos) {
    if (pos === -1) {
      throw new Error("Invalid position");
    }
    if (this._children.get(pos) != null) {
      this._popCount--;
    }
    this._children.unset(pos);
    this._level();
  }
  _level() {
    if (this._parent != null && this._popCount <= 1) {
      if (this._popCount === 1) {
        const onlyChild = this._children.find(exists);
        if (onlyChild != null && !(onlyChild instanceof _Bucket)) {
          const hash = onlyChild.hash;
          hash.untake(this._options.bits);
          const place = {
            pos: this._posAtParent,
            hash,
            bucket: this._parent
          };
          this._parent._putAt(place, onlyChild.key, onlyChild.value);
        }
      } else {
        this._parent._delAt(this._posAtParent);
      }
    }
  }
  _at(index) {
    return this._children.get(index);
  }
};
function exists(o) {
  return Boolean(o);
}
function mapNode(node, _) {
  return node.key;
}
function reduceNodes(nodes) {
  return nodes;
}
async function asyncTransformBucket(bucket, asyncMap, asyncReduce) {
  const output = [];
  for (const child of bucket._children.compactArray()) {
    if (child instanceof Bucket) {
      await asyncTransformBucket(child, asyncMap, asyncReduce);
    } else {
      const mappedChildren = await asyncMap(child);
      output.push({
        bitField: bucket._children.bitField(),
        children: mappedChildren
      });
    }
  }
  return asyncReduce(output);
}

// node_modules/hamt-sharding/dist/src/consumable-buffer.js
var START_MASKS = [
  255,
  254,
  252,
  248,
  240,
  224,
  192,
  128
];
var STOP_MASKS = [
  1,
  3,
  7,
  15,
  31,
  63,
  127,
  255
];
var ConsumableBuffer = class {
  _value;
  _currentBytePos;
  _currentBitPos;
  constructor(value) {
    this._value = value;
    this._currentBytePos = value.length - 1;
    this._currentBitPos = 7;
  }
  availableBits() {
    return this._currentBitPos + 1 + this._currentBytePos * 8;
  }
  totalBits() {
    return this._value.length * 8;
  }
  take(bits) {
    let pendingBits = bits;
    let result = 0;
    while (pendingBits > 0 && this._haveBits()) {
      const byte = this._value[this._currentBytePos];
      const availableBits = this._currentBitPos + 1;
      const taking = Math.min(availableBits, pendingBits);
      const value = byteBitsToInt(byte, availableBits - taking, taking);
      result = (result << taking) + value;
      pendingBits -= taking;
      this._currentBitPos -= taking;
      if (this._currentBitPos < 0) {
        this._currentBitPos = 7;
        this._currentBytePos--;
      }
    }
    return result;
  }
  untake(bits) {
    this._currentBitPos += bits;
    while (this._currentBitPos > 7) {
      this._currentBitPos -= 8;
      this._currentBytePos += 1;
    }
  }
  _haveBits() {
    return this._currentBytePos >= 0;
  }
};
function byteBitsToInt(byte, start, length5) {
  const mask = maskFor(start, length5);
  return (byte & mask) >>> start;
}
function maskFor(start, length5) {
  return START_MASKS[start] & STOP_MASKS[Math.min(length5 + start - 1, 7)];
}

// node_modules/hamt-sharding/dist/src/consumable-hash.js
function wrapHash(hashFn2) {
  function hashing(value) {
    if (value instanceof InfiniteHash) {
      return value;
    } else {
      return new InfiniteHash(value, hashFn2);
    }
  }
  return hashing;
}
var InfiniteHash = class {
  _value;
  _hashFn;
  _depth;
  _availableBits;
  _currentBufferIndex;
  _buffers;
  constructor(value, hashFn2) {
    if (!(value instanceof Uint8Array)) {
      throw new Error("can only hash Uint8Arrays");
    }
    this._value = value;
    this._hashFn = hashFn2;
    this._depth = -1;
    this._availableBits = 0;
    this._currentBufferIndex = 0;
    this._buffers = [];
  }
  async take(bits) {
    let pendingBits = bits;
    while (this._availableBits < pendingBits) {
      await this._produceMoreBits();
    }
    let result = 0;
    while (pendingBits > 0) {
      const hash = this._buffers[this._currentBufferIndex];
      const available = Math.min(hash.availableBits(), pendingBits);
      const took = hash.take(available);
      result = (result << available) + took;
      pendingBits -= available;
      this._availableBits -= available;
      if (hash.availableBits() === 0) {
        this._currentBufferIndex++;
      }
    }
    return result;
  }
  untake(bits) {
    let pendingBits = bits;
    while (pendingBits > 0) {
      const hash = this._buffers[this._currentBufferIndex];
      const availableForUntake = Math.min(hash.totalBits() - hash.availableBits(), pendingBits);
      hash.untake(availableForUntake);
      pendingBits -= availableForUntake;
      this._availableBits += availableForUntake;
      if (this._currentBufferIndex > 0 && hash.totalBits() === hash.availableBits()) {
        this._depth--;
        this._currentBufferIndex--;
      }
    }
  }
  async _produceMoreBits() {
    this._depth++;
    const value = this._depth > 0 ? concat([this._value, Uint8Array.from([this._depth])]) : this._value;
    const hashValue = await this._hashFn(value);
    const buffer = new ConsumableBuffer(hashValue);
    this._buffers.push(buffer);
    this._availableBits += buffer.availableBits();
  }
};

// node_modules/hamt-sharding/dist/src/index.js
function createHAMT(options) {
  if (options == null || options.hashFn == null) {
    throw new Error("please define an options.hashFn");
  }
  const bucketOptions = {
    bits: options.bits ?? 8,
    hash: wrapHash(options.hashFn)
  };
  return new Bucket(bucketOptions);
}

// node_modules/ipfs-unixfs-importer/dist/src/dir-sharded.js
async function hamtHashFn(buf) {
  return (await murmur3128.encode(buf)).slice(0, 8).reverse();
}
var HAMT_HASH_CODE = BigInt(34);
var DEFAULT_FANOUT_BITS = 8;
var DirSharded = class extends Dir {
  _bucket;
  constructor(props, options) {
    super(props, options);
    this._bucket = createHAMT({
      hashFn: hamtHashFn,
      bits: options.shardFanoutBits ?? DEFAULT_FANOUT_BITS
    });
  }
  async put(name3, value) {
    this.cid = void 0;
    this.size = void 0;
    this.nodeSize = void 0;
    await this._bucket.put(name3, value);
  }
  async get(name3) {
    return this._bucket.get(name3);
  }
  childCount() {
    return this._bucket.leafCount();
  }
  directChildrenCount() {
    return this._bucket.childrenCount();
  }
  onlyChild() {
    return this._bucket.onlyChild();
  }
  *eachChildSeries() {
    for (const { key, value } of this._bucket.eachLeafSeries()) {
      yield {
        key,
        child: value
      };
    }
  }
  estimateNodeSize() {
    if (this.nodeSize !== void 0) {
      return this.nodeSize;
    }
    this.nodeSize = calculateSize(this._bucket, this, this.options);
    return this.nodeSize;
  }
  async *flush(blockstore) {
    for await (const entry of flush(this._bucket, blockstore, this, this.options)) {
      yield {
        ...entry,
        path: this.path
      };
    }
  }
};
var dir_sharded_default = DirSharded;
async function* flush(bucket, blockstore, shardRoot, options) {
  const children = bucket._children;
  const padLength = (bucket.tableSize() - 1).toString(16).length;
  const links = [];
  let childrenSize = 0n;
  for (let i = 0; i < children.length; i++) {
    const child = children.get(i);
    if (child == null) {
      continue;
    }
    const labelPrefix = i.toString(16).toUpperCase().padStart(padLength, "0");
    if (child instanceof Bucket) {
      let shard;
      for await (const subShard of flush(child, blockstore, null, options)) {
        shard = subShard;
      }
      if (shard == null) {
        throw new Error("Could not flush sharded directory, no subshard found");
      }
      links.push({
        Name: labelPrefix,
        Tsize: Number(shard.size),
        Hash: shard.cid
      });
      childrenSize += shard.size;
    } else if (isDir(child.value)) {
      const dir2 = child.value;
      let flushedDir;
      for await (const entry of dir2.flush(blockstore)) {
        flushedDir = entry;
        yield flushedDir;
      }
      if (flushedDir == null) {
        throw new Error("Did not flush dir");
      }
      const label = labelPrefix + child.key;
      links.push({
        Name: label,
        Tsize: Number(flushedDir.size),
        Hash: flushedDir.cid
      });
      childrenSize += flushedDir.size;
    } else {
      const value = child.value;
      if (value.cid == null) {
        continue;
      }
      const label = labelPrefix + child.key;
      const size2 = value.size;
      links.push({
        Name: label,
        Tsize: Number(size2),
        Hash: value.cid
      });
      childrenSize += BigInt(size2 ?? 0);
    }
  }
  const data = Uint8Array.from(children.bitField().reverse());
  const dir = new UnixFS({
    type: "hamt-sharded-directory",
    data,
    fanout: BigInt(bucket.tableSize()),
    hashType: HAMT_HASH_CODE,
    mtime: shardRoot?.mtime,
    mode: shardRoot?.mode
  });
  const node = {
    Data: dir.marshal(),
    Links: links
  };
  const buffer = encode(prepare(node));
  const cid = await persist(buffer, blockstore, options);
  const size = BigInt(buffer.byteLength) + childrenSize;
  yield {
    cid,
    unixfs: dir,
    size
  };
}
function isDir(obj) {
  return typeof obj.flush === "function";
}
function calculateSize(bucket, shardRoot, options) {
  const children = bucket._children;
  const padLength = (bucket.tableSize() - 1).toString(16).length;
  const links = [];
  for (let i = 0; i < children.length; i++) {
    const child = children.get(i);
    if (child == null) {
      continue;
    }
    const labelPrefix = i.toString(16).toUpperCase().padStart(padLength, "0");
    if (child instanceof Bucket) {
      const size = calculateSize(child, null, options);
      links.push({
        Name: labelPrefix,
        Tsize: Number(size),
        Hash: options.cidVersion === 0 ? CID_V0 : CID_V1
      });
    } else if (typeof child.value.flush === "function") {
      const dir2 = child.value;
      const size = dir2.nodeSize();
      links.push({
        Name: labelPrefix + child.key,
        Tsize: Number(size),
        Hash: options.cidVersion === 0 ? CID_V0 : CID_V1
      });
    } else {
      const value = child.value;
      if (value.cid == null) {
        continue;
      }
      const label = labelPrefix + child.key;
      const size = value.size;
      links.push({
        Name: label,
        Tsize: Number(size),
        Hash: value.cid
      });
    }
  }
  const data = Uint8Array.from(children.bitField().reverse());
  const dir = new UnixFS({
    type: "hamt-sharded-directory",
    data,
    fanout: BigInt(bucket.tableSize()),
    hashType: HAMT_HASH_CODE,
    mtime: shardRoot?.mtime,
    mode: shardRoot?.mode
  });
  const buffer = encode(prepare({
    Data: dir.marshal(),
    Links: links
  }));
  return buffer.length;
}

// node_modules/ipfs-unixfs-importer/dist/src/flat-to-shard.js
async function flatToShard(child, dir, threshold, options) {
  let newDir = dir;
  if (dir instanceof DirFlat && dir.estimateNodeSize() > threshold) {
    newDir = await convertToShard(dir, options);
  }
  const parent = newDir.parent;
  if (parent != null) {
    if (newDir !== dir) {
      if (child != null) {
        child.parent = newDir;
      }
      if (newDir.parentKey == null) {
        throw new Error("No parent key found");
      }
      await parent.put(newDir.parentKey, newDir);
    }
    return flatToShard(newDir, parent, threshold, options);
  }
  return newDir;
}
async function convertToShard(oldDir, options) {
  const newDir = new dir_sharded_default({
    root: oldDir.root,
    dir: true,
    parent: oldDir.parent,
    parentKey: oldDir.parentKey,
    path: oldDir.path,
    dirty: oldDir.dirty,
    flat: false,
    mtime: oldDir.mtime,
    mode: oldDir.mode
  }, options);
  for (const { key, child } of oldDir.eachChildSeries()) {
    await newDir.put(key, child);
  }
  return newDir;
}

// node_modules/ipfs-unixfs-importer/dist/src/utils/to-path-components.js
var toPathComponents = (path = "") => {
  return path.split(new RegExp("(?<!\\\\)\\/")).filter(Boolean);
};

// node_modules/ipfs-unixfs-importer/dist/src/tree-builder.js
async function addToTree(elem, tree, options) {
  const pathElems = toPathComponents(elem.path ?? "");
  const lastIndex = pathElems.length - 1;
  let parent = tree;
  let currentPath = "";
  for (let i = 0; i < pathElems.length; i++) {
    const pathElem = pathElems[i];
    currentPath += `${currentPath !== "" ? "/" : ""}${pathElem}`;
    const last2 = i === lastIndex;
    parent.dirty = true;
    parent.cid = void 0;
    parent.size = void 0;
    if (last2) {
      await parent.put(pathElem, elem);
      tree = await flatToShard(null, parent, options.shardSplitThresholdBytes, options);
    } else {
      let dir = await parent.get(pathElem);
      if (dir == null || !(dir instanceof Dir)) {
        dir = new DirFlat({
          root: false,
          dir: true,
          parent,
          parentKey: pathElem,
          path: currentPath,
          dirty: true,
          flat: true,
          mtime: dir?.unixfs?.mtime,
          mode: dir?.unixfs?.mode
        }, options);
      }
      await parent.put(pathElem, dir);
      parent = dir;
    }
  }
  return tree;
}
async function* flushAndYield(tree, blockstore) {
  if (!(tree instanceof Dir)) {
    if (tree.unixfs?.isDirectory() === true) {
      yield tree;
    }
    return;
  }
  yield* tree.flush(blockstore);
}
function defaultTreeBuilder(options) {
  return async function* treeBuilder(source, block) {
    let tree = new DirFlat({
      root: true,
      dir: true,
      path: "",
      dirty: true,
      flat: true
    }, options);
    let rootDir;
    let singleRoot = false;
    for await (const entry of source) {
      if (entry == null) {
        continue;
      }
      const dir = `${entry.originalPath ?? ""}`.split("/")[0];
      if (dir != null && dir !== "") {
        if (rootDir == null) {
          rootDir = dir;
          singleRoot = true;
        } else if (rootDir !== dir) {
          singleRoot = false;
        }
      }
      tree = await addToTree(entry, tree, options);
      if (entry.unixfs?.isDirectory() !== true) {
        yield entry;
      }
    }
    if (options.wrapWithDirectory || singleRoot && tree.childCount() > 1) {
      yield* flushAndYield(tree, block);
    } else {
      for (const unwrapped of tree.eachChildSeries()) {
        if (unwrapped == null) {
          continue;
        }
        yield* flushAndYield(unwrapped.child, block);
      }
    }
  };
}

// node_modules/ipfs-unixfs-importer/dist/src/index.js
async function* importer(source, blockstore, options = {}) {
  let candidates;
  if (Symbol.asyncIterator in source || Symbol.iterator in source) {
    candidates = source;
  } else {
    candidates = [source];
  }
  const wrapWithDirectory = options.wrapWithDirectory ?? false;
  const shardSplitThresholdBytes = options.shardSplitThresholdBytes ?? 262144;
  const shardFanoutBits = options.shardFanoutBits ?? 8;
  const cidVersion = options.cidVersion ?? 1;
  const rawLeaves = options.rawLeaves ?? true;
  const leafType = options.leafType ?? "file";
  const fileImportConcurrency = options.fileImportConcurrency ?? 50;
  const blockWriteConcurrency = options.blockWriteConcurrency ?? 10;
  const reduceSingleLeafToSelf = options.reduceSingleLeafToSelf ?? true;
  const chunker = options.chunker ?? fixedSize();
  const chunkValidator = options.chunkValidator ?? defaultChunkValidator();
  const buildDag = options.dagBuilder ?? defaultDagBuilder({
    chunker,
    chunkValidator,
    wrapWithDirectory,
    layout: options.layout ?? balanced(),
    bufferImporter: options.bufferImporter ?? defaultBufferImporter({
      cidVersion,
      rawLeaves,
      leafType,
      onProgress: options.onProgress
    }),
    blockWriteConcurrency,
    reduceSingleLeafToSelf,
    cidVersion,
    onProgress: options.onProgress,
    dirBuilder: options.dirBuilder,
    fileBuilder: options.fileBuilder
  });
  const buildTree = options.treeBuilder ?? defaultTreeBuilder({
    wrapWithDirectory,
    shardSplitThresholdBytes,
    shardFanoutBits,
    cidVersion,
    onProgress: options.onProgress
  });
  for await (const entry of buildTree(parallelBatch(buildDag(candidates, blockstore), fileImportConcurrency), blockstore)) {
    yield {
      cid: entry.cid,
      path: entry.path,
      unixfs: entry.unixfs,
      size: entry.size
    };
  }
}
async function importFile(content, blockstore, options = {}) {
  const result = await src_default3(importer([content], blockstore, options));
  if (result == null) {
    throw new InvalidParametersError("Nothing imported");
  }
  return result;
}
async function importBytes(buf, blockstore, options = {}) {
  return importFile({
    content: buf
  }, blockstore, options);
}
async function importByteStream(bufs, blockstore, options = {}) {
  return importFile({
    content: bufs
  }, blockstore, options);
}

// node_modules/ipfs-unixfs-importer/dist/src/chunker/rabin.js
var import_rabin_wasm = __toESM(require_src(), 1);

// node_modules/it-last/dist/src/index.js
function isAsyncIterable3(thing) {
  return thing[Symbol.asyncIterator] != null;
}
function last(source) {
  if (isAsyncIterable3(source)) {
    return (async () => {
      let res2;
      for await (const entry of source) {
        res2 = entry;
      }
      return res2;
    })();
  }
  let res;
  for (const entry of source) {
    res = entry;
  }
  return res;
}
var src_default6 = last;

// node_modules/@helia/unixfs/dist/src/errors.js
var UnixFSError = class extends Error {
  name;
  code;
  constructor(message2, name3, code9) {
    super(message2);
    this.name = name3;
    this.code = code9;
  }
};
var NotUnixFSError = class extends UnixFSError {
  constructor(message2 = "not a Unixfs node") {
    super(message2, "NotUnixFSError", "ERR_NOT_UNIXFS");
  }
};
var InvalidPBNodeError = class extends UnixFSError {
  constructor(message2 = "invalid PBNode") {
    super(message2, "InvalidPBNodeError", "ERR_INVALID_PB_NODE");
  }
};
var UnknownError = class extends UnixFSError {
  constructor(message2 = "unknown error") {
    super(message2, "InvalidPBNodeError", "ERR_UNKNOWN_ERROR");
  }
};
var AlreadyExistsError = class extends UnixFSError {
  constructor(message2 = "path already exists") {
    super(message2, "AlreadyExistsError", "ERR_ALREADY_EXISTS");
  }
};
var DoesNotExistError = class extends UnixFSError {
  constructor(message2 = "path does not exist") {
    super(message2, "DoesNotExistError", "ERR_DOES_NOT_EXIST");
  }
};
var NoContentError = class extends UnixFSError {
  constructor(message2 = "no content") {
    super(message2, "NoContentError", "ERR_NO_CONTENT");
  }
};
var NotAFileError = class extends UnixFSError {
  constructor(message2 = "not a file") {
    super(message2, "NotAFileError", "ERR_NOT_A_FILE");
  }
};
var NotADirectoryError = class extends UnixFSError {
  constructor(message2 = "not a directory") {
    super(message2, "NotADirectoryError", "ERR_NOT_A_DIRECTORY");
  }
};
var InvalidParametersError2 = class extends UnixFSError {
  constructor(message2 = "invalid parameters") {
    super(message2, "InvalidParametersError", "ERR_INVALID_PARAMETERS");
  }
};

// node_modules/@helia/unixfs/dist/src/commands/add.js
var defaultImporterSettings = {
  cidVersion: 1,
  rawLeaves: true,
  layout: balanced({
    maxChildrenPerNode: 1024
  }),
  chunker: fixedSize({
    chunkSize: 1048576
  })
};
async function* addAll(source, blockstore, options = {}) {
  yield* importer(source, blockstore, {
    ...defaultImporterSettings,
    ...options
  });
}
async function addBytes(bytes, blockstore, options = {}) {
  const { cid } = await importBytes(bytes, blockstore, {
    ...defaultImporterSettings,
    ...options
  });
  return cid;
}
async function addByteStream(bytes, blockstore, options = {}) {
  const { cid } = await importByteStream(bytes, blockstore, {
    ...defaultImporterSettings,
    ...options
  });
  return cid;
}
async function addFile(file, blockstore, options = {}) {
  if (file.path == null) {
    throw new InvalidParametersError2("path is required");
  }
  if (file.content == null) {
    throw new InvalidParametersError2("content is required");
  }
  const result = await src_default6(addAll([file], blockstore, {
    ...defaultImporterSettings,
    ...options,
    wrapWithDirectory: true
  }));
  if (result == null) {
    throw new InvalidParametersError2("Nothing imported");
  }
  return result.cid;
}
async function addDirectory(dir, blockstore, options = {}) {
  if (dir.content != null) {
    throw new InvalidParametersError2("Directories cannot have content, use addFile instead");
  }
  const ord = dir.path == null ? src_default3 : src_default6;
  const result = await ord(addAll([{
    ...dir,
    path: dir.path ?? "-"
  }], blockstore, {
    ...defaultImporterSettings,
    ...options,
    wrapWithDirectory: dir.path != null
  }));
  if (result == null) {
    throw new InvalidParametersError2("Nothing imported");
  }
  return result.cid;
}

// node_modules/ipfs-unixfs-exporter/node_modules/multiformats/dist/src/bytes.js
var empty3 = new Uint8Array(0);
function equals5(aa, bb) {
  if (aa === bb) {
    return true;
  }
  if (aa.byteLength !== bb.byteLength) {
    return false;
  }
  for (let ii = 0; ii < aa.byteLength; ii++) {
    if (aa[ii] !== bb[ii]) {
      return false;
    }
  }
  return true;
}
function coerce3(o) {
  if (o instanceof Uint8Array && o.constructor.name === "Uint8Array") {
    return o;
  }
  if (o instanceof ArrayBuffer) {
    return new Uint8Array(o);
  }
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength);
  }
  throw new Error("Unknown type, must be binary type");
}

// node_modules/ipfs-unixfs-exporter/node_modules/multiformats/dist/src/vendor/base-x.js
function base3(ALPHABET, name3) {
  if (ALPHABET.length >= 255) {
    throw new TypeError("Alphabet too long");
  }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) {
      throw new TypeError(x + " is ambiguous");
    }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256);
  var iFACTOR = Math.log(256) / Math.log(BASE);
  function encode12(source) {
    if (source instanceof Uint8Array)
      ;
    else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) {
      throw new TypeError("Expected Uint8Array");
    }
    if (source.length === 0) {
      return "";
    }
    var zeroes = 0;
    var length5 = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
    var size = (pend - pbegin) * iFACTOR + 1 >>> 0;
    var b58 = new Uint8Array(size);
    while (pbegin !== pend) {
      var carry = source[pbegin];
      var i2 = 0;
      for (var it1 = size - 1; (carry !== 0 || i2 < length5) && it1 !== -1; it1--, i2++) {
        carry += 256 * b58[it1] >>> 0;
        b58[it1] = carry % BASE >>> 0;
        carry = carry / BASE >>> 0;
      }
      if (carry !== 0) {
        throw new Error("Non-zero carry");
      }
      length5 = i2;
      pbegin++;
    }
    var it2 = size - length5;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
    var str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) {
      str += ALPHABET.charAt(b58[it2]);
    }
    return str;
  }
  function decodeUnsafe(source) {
    if (typeof source !== "string") {
      throw new TypeError("Expected String");
    }
    if (source.length === 0) {
      return new Uint8Array();
    }
    var psz = 0;
    if (source[psz] === " ") {
      return;
    }
    var zeroes = 0;
    var length5 = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
    var size = (source.length - psz) * FACTOR + 1 >>> 0;
    var b256 = new Uint8Array(size);
    while (source[psz]) {
      var carry = BASE_MAP[source.charCodeAt(psz)];
      if (carry === 255) {
        return;
      }
      var i2 = 0;
      for (var it3 = size - 1; (carry !== 0 || i2 < length5) && it3 !== -1; it3--, i2++) {
        carry += BASE * b256[it3] >>> 0;
        b256[it3] = carry % 256 >>> 0;
        carry = carry / 256 >>> 0;
      }
      if (carry !== 0) {
        throw new Error("Non-zero carry");
      }
      length5 = i2;
      psz++;
    }
    if (source[psz] === " ") {
      return;
    }
    var it4 = size - length5;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size - it4));
    var j2 = zeroes;
    while (it4 !== size) {
      vch[j2++] = b256[it4++];
    }
    return vch;
  }
  function decode22(string) {
    var buffer = decodeUnsafe(string);
    if (buffer) {
      return buffer;
    }
    throw new Error(`Non-${name3} character`);
  }
  return {
    encode: encode12,
    decodeUnsafe,
    decode: decode22
  };
}
var src3 = base3;
var _brrp__multiformats_scope_baseX3 = src3;
var base_x_default3 = _brrp__multiformats_scope_baseX3;

// node_modules/ipfs-unixfs-exporter/node_modules/multiformats/dist/src/bases/base.js
var Encoder3 = class {
  name;
  prefix;
  baseEncode;
  constructor(name3, prefix, baseEncode) {
    this.name = name3;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
  }
  encode(bytes) {
    if (bytes instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes)}`;
    } else {
      throw Error("Unknown type, must be binary type");
    }
  }
};
var Decoder3 = class {
  name;
  prefix;
  baseDecode;
  prefixCodePoint;
  constructor(name3, prefix, baseDecode) {
    this.name = name3;
    this.prefix = prefix;
    const prefixCodePoint = prefix.codePointAt(0);
    if (prefixCodePoint === void 0) {
      throw new Error("Invalid prefix character");
    }
    this.prefixCodePoint = prefixCodePoint;
    this.baseDecode = baseDecode;
  }
  decode(text) {
    if (typeof text === "string") {
      if (text.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`);
      }
      return this.baseDecode(text.slice(this.prefix.length));
    } else {
      throw Error("Can only multibase decode strings");
    }
  }
  or(decoder) {
    return or3(this, decoder);
  }
};
var ComposedDecoder3 = class {
  decoders;
  constructor(decoders) {
    this.decoders = decoders;
  }
  or(decoder) {
    return or3(this, decoder);
  }
  decode(input) {
    const prefix = input[0];
    const decoder = this.decoders[prefix];
    if (decoder != null) {
      return decoder.decode(input);
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`);
    }
  }
};
function or3(left, right) {
  return new ComposedDecoder3({
    ...left.decoders ?? { [left.prefix]: left },
    ...right.decoders ?? { [right.prefix]: right }
  });
}
var Codec3 = class {
  name;
  prefix;
  baseEncode;
  baseDecode;
  encoder;
  decoder;
  constructor(name3, prefix, baseEncode, baseDecode) {
    this.name = name3;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder3(name3, prefix, baseEncode);
    this.decoder = new Decoder3(name3, prefix, baseDecode);
  }
  encode(input) {
    return this.encoder.encode(input);
  }
  decode(input) {
    return this.decoder.decode(input);
  }
};
function from5({ name: name3, prefix, encode: encode12, decode: decode22 }) {
  return new Codec3(name3, prefix, encode12, decode22);
}
function baseX3({ name: name3, prefix, alphabet }) {
  const { encode: encode12, decode: decode22 } = base_x_default3(alphabet, name3);
  return from5({
    prefix,
    name: name3,
    encode: encode12,
    decode: (text) => coerce3(decode22(text))
  });
}
function decode13(string, alphabetIdx, bitsPerChar, name3) {
  let end = string.length;
  while (string[end - 1] === "=") {
    --end;
  }
  const out = new Uint8Array(end * bitsPerChar / 8 | 0);
  let bits = 0;
  let buffer = 0;
  let written = 0;
  for (let i = 0; i < end; ++i) {
    const value = alphabetIdx[string[i]];
    if (value === void 0) {
      throw new SyntaxError(`Non-${name3} character`);
    }
    buffer = buffer << bitsPerChar | value;
    bits += bitsPerChar;
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 255 & buffer >> bits;
    }
  }
  if (bits >= bitsPerChar || (255 & buffer << 8 - bits) !== 0) {
    throw new SyntaxError("Unexpected end of data");
  }
  return out;
}
function encode7(data, alphabet, bitsPerChar) {
  const pad = alphabet[alphabet.length - 1] === "=";
  const mask = (1 << bitsPerChar) - 1;
  let out = "";
  let bits = 0;
  let buffer = 0;
  for (let i = 0; i < data.length; ++i) {
    buffer = buffer << 8 | data[i];
    bits += 8;
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet[mask & buffer >> bits];
    }
  }
  if (bits !== 0) {
    out += alphabet[mask & buffer << bitsPerChar - bits];
  }
  if (pad) {
    while ((out.length * bitsPerChar & 7) !== 0) {
      out += "=";
    }
  }
  return out;
}
function createAlphabetIdx3(alphabet) {
  const alphabetIdx = {};
  for (let i = 0; i < alphabet.length; ++i) {
    alphabetIdx[alphabet[i]] = i;
  }
  return alphabetIdx;
}
function rfc46483({ name: name3, prefix, bitsPerChar, alphabet }) {
  const alphabetIdx = createAlphabetIdx3(alphabet);
  return from5({
    prefix,
    name: name3,
    encode(input) {
      return encode7(input, alphabet, bitsPerChar);
    },
    decode(input) {
      return decode13(input, alphabetIdx, bitsPerChar, name3);
    }
  });
}

// node_modules/ipfs-unixfs-exporter/node_modules/multiformats/dist/src/bases/base32.js
var base323 = rfc46483({
  prefix: "b",
  name: "base32",
  alphabet: "abcdefghijklmnopqrstuvwxyz234567",
  bitsPerChar: 5
});
var base32upper3 = rfc46483({
  prefix: "B",
  name: "base32upper",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZ234567",
  bitsPerChar: 5
});
var base32pad3 = rfc46483({
  prefix: "c",
  name: "base32pad",
  alphabet: "abcdefghijklmnopqrstuvwxyz234567=",
  bitsPerChar: 5
});
var base32padupper3 = rfc46483({
  prefix: "C",
  name: "base32padupper",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=",
  bitsPerChar: 5
});
var base32hex3 = rfc46483({
  prefix: "v",
  name: "base32hex",
  alphabet: "0123456789abcdefghijklmnopqrstuv",
  bitsPerChar: 5
});
var base32hexupper3 = rfc46483({
  prefix: "V",
  name: "base32hexupper",
  alphabet: "0123456789ABCDEFGHIJKLMNOPQRSTUV",
  bitsPerChar: 5
});
var base32hexpad3 = rfc46483({
  prefix: "t",
  name: "base32hexpad",
  alphabet: "0123456789abcdefghijklmnopqrstuv=",
  bitsPerChar: 5
});
var base32hexpadupper3 = rfc46483({
  prefix: "T",
  name: "base32hexpadupper",
  alphabet: "0123456789ABCDEFGHIJKLMNOPQRSTUV=",
  bitsPerChar: 5
});
var base32z3 = rfc46483({
  prefix: "h",
  name: "base32z",
  alphabet: "ybndrfg8ejkmcpqxot1uwisza345h769",
  bitsPerChar: 5
});

// node_modules/ipfs-unixfs-exporter/node_modules/multiformats/dist/src/bases/base36.js
var base363 = baseX3({
  prefix: "k",
  name: "base36",
  alphabet: "0123456789abcdefghijklmnopqrstuvwxyz"
});
var base36upper3 = baseX3({
  prefix: "K",
  name: "base36upper",
  alphabet: "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ"
});

// node_modules/ipfs-unixfs-exporter/node_modules/multiformats/dist/src/bases/base58.js
var base58btc3 = baseX3({
  name: "base58btc",
  prefix: "z",
  alphabet: "123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz"
});
var base58flickr3 = baseX3({
  name: "base58flickr",
  prefix: "Z",
  alphabet: "123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ"
});

// node_modules/ipfs-unixfs-exporter/node_modules/multiformats/dist/src/vendor/varint.js
var encode_13 = encode8;
var MSB3 = 128;
var REST3 = 127;
var MSBALL3 = ~REST3;
var INT3 = Math.pow(2, 31);
function encode8(num, out, offset) {
  out = out || [];
  offset = offset || 0;
  var oldOffset = offset;
  while (num >= INT3) {
    out[offset++] = num & 255 | MSB3;
    num /= 128;
  }
  while (num & MSBALL3) {
    out[offset++] = num & 255 | MSB3;
    num >>>= 7;
  }
  out[offset] = num | 0;
  encode8.bytes = offset - oldOffset + 1;
  return out;
}
var decode14 = read3;
var MSB$13 = 128;
var REST$13 = 127;
function read3(buf, offset) {
  var res = 0, offset = offset || 0, shift = 0, counter = offset, b, l = buf.length;
  do {
    if (counter >= l) {
      read3.bytes = 0;
      throw new RangeError("Could not decode varint");
    }
    b = buf[counter++];
    res += shift < 28 ? (b & REST$13) << shift : (b & REST$13) * Math.pow(2, shift);
    shift += 7;
  } while (b >= MSB$13);
  read3.bytes = counter - offset;
  return res;
}
var N13 = Math.pow(2, 7);
var N23 = Math.pow(2, 14);
var N33 = Math.pow(2, 21);
var N43 = Math.pow(2, 28);
var N53 = Math.pow(2, 35);
var N63 = Math.pow(2, 42);
var N73 = Math.pow(2, 49);
var N83 = Math.pow(2, 56);
var N93 = Math.pow(2, 63);
var length3 = function(value) {
  return value < N13 ? 1 : value < N23 ? 2 : value < N33 ? 3 : value < N43 ? 4 : value < N53 ? 5 : value < N63 ? 6 : value < N73 ? 7 : value < N83 ? 8 : value < N93 ? 9 : 10;
};
var varint3 = {
  encode: encode_13,
  decode: decode14,
  encodingLength: length3
};
var _brrp_varint3 = varint3;
var varint_default3 = _brrp_varint3;

// node_modules/ipfs-unixfs-exporter/node_modules/multiformats/dist/src/varint.js
function decode15(data, offset = 0) {
  const code9 = varint_default3.decode(data, offset);
  return [code9, varint_default3.decode.bytes];
}
function encodeTo3(int, target, offset = 0) {
  varint_default3.encode(int, target, offset);
  return target;
}
function encodingLength3(int) {
  return varint_default3.encodingLength(int);
}

// node_modules/ipfs-unixfs-exporter/node_modules/multiformats/dist/src/hashes/digest.js
function create4(code9, digest2) {
  const size = digest2.byteLength;
  const sizeOffset = encodingLength3(code9);
  const digestOffset = sizeOffset + encodingLength3(size);
  const bytes = new Uint8Array(digestOffset + size);
  encodeTo3(code9, bytes, 0);
  encodeTo3(size, bytes, sizeOffset);
  bytes.set(digest2, digestOffset);
  return new Digest3(code9, size, digest2, bytes);
}
function decode16(multihash) {
  const bytes = coerce3(multihash);
  const [code9, sizeOffset] = decode15(bytes);
  const [size, digestOffset] = decode15(bytes.subarray(sizeOffset));
  const digest2 = bytes.subarray(sizeOffset + digestOffset);
  if (digest2.byteLength !== size) {
    throw new Error("Incorrect length");
  }
  return new Digest3(code9, size, digest2, bytes);
}
function equals6(a, b) {
  if (a === b) {
    return true;
  } else {
    const data = b;
    return a.code === data.code && a.size === data.size && data.bytes instanceof Uint8Array && equals5(a.bytes, data.bytes);
  }
}
var Digest3 = class {
  code;
  size;
  digest;
  bytes;
  /**
   * Creates a multihash digest.
   */
  constructor(code9, size, digest2, bytes) {
    this.code = code9;
    this.size = size;
    this.digest = digest2;
    this.bytes = bytes;
  }
};

// node_modules/ipfs-unixfs-exporter/node_modules/multiformats/dist/src/cid.js
function format3(link, base5) {
  const { bytes, version } = link;
  switch (version) {
    case 0:
      return toStringV03(bytes, baseCache3(link), base5 ?? base58btc3.encoder);
    default:
      return toStringV13(bytes, baseCache3(link), base5 ?? base323.encoder);
  }
}
var cache3 = /* @__PURE__ */ new WeakMap();
function baseCache3(cid) {
  const baseCache5 = cache3.get(cid);
  if (baseCache5 == null) {
    const baseCache6 = /* @__PURE__ */ new Map();
    cache3.set(cid, baseCache6);
    return baseCache6;
  }
  return baseCache5;
}
var CID3 = class _CID {
  code;
  version;
  multihash;
  bytes;
  "/";
  /**
   * @param version - Version of the CID
   * @param code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param multihash - (Multi)hash of the of the content.
   */
  constructor(version, code9, multihash, bytes) {
    this.code = code9;
    this.version = version;
    this.multihash = multihash;
    this.bytes = bytes;
    this["/"] = bytes;
  }
  /**
   * Signalling `cid.asCID === cid` has been replaced with `cid['/'] === cid.bytes`
   * please either use `CID.asCID(cid)` or switch to new signalling mechanism
   *
   * @deprecated
   */
  get asCID() {
    return this;
  }
  // ArrayBufferView
  get byteOffset() {
    return this.bytes.byteOffset;
  }
  // ArrayBufferView
  get byteLength() {
    return this.bytes.byteLength;
  }
  toV0() {
    switch (this.version) {
      case 0: {
        return this;
      }
      case 1: {
        const { code: code9, multihash } = this;
        if (code9 !== DAG_PB_CODE3) {
          throw new Error("Cannot convert a non dag-pb CID to CIDv0");
        }
        if (multihash.code !== SHA_256_CODE3) {
          throw new Error("Cannot convert non sha2-256 multihash CID to CIDv0");
        }
        return _CID.createV0(multihash);
      }
      default: {
        throw Error(`Can not convert CID version ${this.version} to version 0. This is a bug please report`);
      }
    }
  }
  toV1() {
    switch (this.version) {
      case 0: {
        const { code: code9, digest: digest2 } = this.multihash;
        const multihash = create4(code9, digest2);
        return _CID.createV1(this.code, multihash);
      }
      case 1: {
        return this;
      }
      default: {
        throw Error(`Can not convert CID version ${this.version} to version 1. This is a bug please report`);
      }
    }
  }
  equals(other) {
    return _CID.equals(this, other);
  }
  static equals(self, other) {
    const unknown = other;
    return unknown != null && self.code === unknown.code && self.version === unknown.version && equals6(self.multihash, unknown.multihash);
  }
  toString(base5) {
    return format3(this, base5);
  }
  toJSON() {
    return { "/": format3(this) };
  }
  link() {
    return this;
  }
  [Symbol.toStringTag] = "CID";
  // Legacy
  [Symbol.for("nodejs.util.inspect.custom")]() {
    return `CID(${this.toString()})`;
  }
  /**
   * Takes any input `value` and returns a `CID` instance if it was
   * a `CID` otherwise returns `null`. If `value` is instanceof `CID`
   * it will return value back. If `value` is not instance of this CID
   * class, but is compatible CID it will return new instance of this
   * `CID` class. Otherwise returns null.
   *
   * This allows two different incompatible versions of CID library to
   * co-exist and interop as long as binary interface is compatible.
   */
  static asCID(input) {
    if (input == null) {
      return null;
    }
    const value = input;
    if (value instanceof _CID) {
      return value;
    } else if (value["/"] != null && value["/"] === value.bytes || value.asCID === value) {
      const { version, code: code9, multihash, bytes } = value;
      return new _CID(version, code9, multihash, bytes ?? encodeCID3(version, code9, multihash.bytes));
    } else if (value[cidSymbol3] === true) {
      const { version, multihash, code: code9 } = value;
      const digest2 = decode16(multihash);
      return _CID.create(version, code9, digest2);
    } else {
      return null;
    }
  }
  /**
   * @param version - Version of the CID
   * @param code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param digest - (Multi)hash of the of the content.
   */
  static create(version, code9, digest2) {
    if (typeof code9 !== "number") {
      throw new Error("String codecs are no longer supported");
    }
    if (!(digest2.bytes instanceof Uint8Array)) {
      throw new Error("Invalid digest");
    }
    switch (version) {
      case 0: {
        if (code9 !== DAG_PB_CODE3) {
          throw new Error(`Version 0 CID must use dag-pb (code: ${DAG_PB_CODE3}) block encoding`);
        } else {
          return new _CID(version, code9, digest2, digest2.bytes);
        }
      }
      case 1: {
        const bytes = encodeCID3(version, code9, digest2.bytes);
        return new _CID(version, code9, digest2, bytes);
      }
      default: {
        throw new Error("Invalid version");
      }
    }
  }
  /**
   * Simplified version of `create` for CIDv0.
   */
  static createV0(digest2) {
    return _CID.create(0, DAG_PB_CODE3, digest2);
  }
  /**
   * Simplified version of `create` for CIDv1.
   *
   * @param code - Content encoding format code.
   * @param digest - Multihash of the content.
   */
  static createV1(code9, digest2) {
    return _CID.create(1, code9, digest2);
  }
  /**
   * Decoded a CID from its binary representation. The byte array must contain
   * only the CID with no additional bytes.
   *
   * An error will be thrown if the bytes provided do not contain a valid
   * binary representation of a CID.
   */
  static decode(bytes) {
    const [cid, remainder] = _CID.decodeFirst(bytes);
    if (remainder.length !== 0) {
      throw new Error("Incorrect length");
    }
    return cid;
  }
  /**
   * Decoded a CID from its binary representation at the beginning of a byte
   * array.
   *
   * Returns an array with the first element containing the CID and the second
   * element containing the remainder of the original byte array. The remainder
   * will be a zero-length byte array if the provided bytes only contained a
   * binary CID representation.
   */
  static decodeFirst(bytes) {
    const specs = _CID.inspectBytes(bytes);
    const prefixSize = specs.size - specs.multihashSize;
    const multihashBytes = coerce3(bytes.subarray(prefixSize, prefixSize + specs.multihashSize));
    if (multihashBytes.byteLength !== specs.multihashSize) {
      throw new Error("Incorrect length");
    }
    const digestBytes = multihashBytes.subarray(specs.multihashSize - specs.digestSize);
    const digest2 = new Digest3(specs.multihashCode, specs.digestSize, digestBytes, multihashBytes);
    const cid = specs.version === 0 ? _CID.createV0(digest2) : _CID.createV1(specs.codec, digest2);
    return [cid, bytes.subarray(specs.size)];
  }
  /**
   * Inspect the initial bytes of a CID to determine its properties.
   *
   * Involves decoding up to 4 varints. Typically this will require only 4 to 6
   * bytes but for larger multicodec code values and larger multihash digest
   * lengths these varints can be quite large. It is recommended that at least
   * 10 bytes be made available in the `initialBytes` argument for a complete
   * inspection.
   */
  static inspectBytes(initialBytes) {
    let offset = 0;
    const next = () => {
      const [i, length5] = decode15(initialBytes.subarray(offset));
      offset += length5;
      return i;
    };
    let version = next();
    let codec = DAG_PB_CODE3;
    if (version === 18) {
      version = 0;
      offset = 0;
    } else {
      codec = next();
    }
    if (version !== 0 && version !== 1) {
      throw new RangeError(`Invalid CID version ${version}`);
    }
    const prefixSize = offset;
    const multihashCode = next();
    const digestSize = next();
    const size = offset + digestSize;
    const multihashSize = size - prefixSize;
    return { version, codec, multihashCode, digestSize, multihashSize, size };
  }
  /**
   * Takes cid in a string representation and creates an instance. If `base`
   * decoder is not provided will use a default from the configuration. It will
   * throw an error if encoding of the CID is not compatible with supplied (or
   * a default decoder).
   */
  static parse(source, base5) {
    const [prefix, bytes] = parseCIDtoBytes3(source, base5);
    const cid = _CID.decode(bytes);
    if (cid.version === 0 && source[0] !== "Q") {
      throw Error("Version 0 CID string must not include multibase prefix");
    }
    baseCache3(cid).set(prefix, source);
    return cid;
  }
};
function parseCIDtoBytes3(source, base5) {
  switch (source[0]) {
    // CIDv0 is parsed differently
    case "Q": {
      const decoder = base5 ?? base58btc3;
      return [
        base58btc3.prefix,
        decoder.decode(`${base58btc3.prefix}${source}`)
      ];
    }
    case base58btc3.prefix: {
      const decoder = base5 ?? base58btc3;
      return [base58btc3.prefix, decoder.decode(source)];
    }
    case base323.prefix: {
      const decoder = base5 ?? base323;
      return [base323.prefix, decoder.decode(source)];
    }
    case base363.prefix: {
      const decoder = base5 ?? base363;
      return [base363.prefix, decoder.decode(source)];
    }
    default: {
      if (base5 == null) {
        throw Error("To parse non base32, base36 or base58btc encoded CID multibase decoder must be provided");
      }
      return [source[0], base5.decode(source)];
    }
  }
}
function toStringV03(bytes, cache5, base5) {
  const { prefix } = base5;
  if (prefix !== base58btc3.prefix) {
    throw Error(`Cannot string encode V0 in ${base5.name} encoding`);
  }
  const cid = cache5.get(prefix);
  if (cid == null) {
    const cid2 = base5.encode(bytes).slice(1);
    cache5.set(prefix, cid2);
    return cid2;
  } else {
    return cid;
  }
}
function toStringV13(bytes, cache5, base5) {
  const { prefix } = base5;
  const cid = cache5.get(prefix);
  if (cid == null) {
    const cid2 = base5.encode(bytes);
    cache5.set(prefix, cid2);
    return cid2;
  } else {
    return cid;
  }
}
var DAG_PB_CODE3 = 112;
var SHA_256_CODE3 = 18;
function encodeCID3(version, code9, multihash) {
  const codeOffset = encodingLength3(version);
  const hashOffset = codeOffset + encodingLength3(code9);
  const bytes = new Uint8Array(hashOffset + multihash.byteLength);
  encodeTo3(version, bytes, 0);
  encodeTo3(code9, bytes, codeOffset);
  bytes.set(multihash, hashOffset);
  return bytes;
}
var cidSymbol3 = Symbol.for("@ipld/js-cid/CID");

// node_modules/ipfs-unixfs-exporter/dist/src/errors.js
var BadPathError = class _BadPathError extends Error {
  static name = "BadPathError";
  static code = "ERR_BAD_PATH";
  name = _BadPathError.name;
  code = _BadPathError.code;
  constructor(message2 = "Bad path") {
    super(message2);
  }
};
var NotFoundError = class _NotFoundError extends Error {
  static name = "NotFoundError";
  static code = "ERR_NOT_FOUND";
  name = _NotFoundError.name;
  code = _NotFoundError.code;
  constructor(message2 = "Not found") {
    super(message2);
  }
};
var NoResolverError = class _NoResolverError extends Error {
  static name = "NoResolverError";
  static code = "ERR_NO_RESOLVER";
  name = _NoResolverError.name;
  code = _NoResolverError.code;
  constructor(message2 = "No resolver") {
    super(message2);
  }
};
var NotUnixFSError2 = class _NotUnixFSError extends Error {
  static name = "NotUnixFSError";
  static code = "ERR_NOT_UNIXFS";
  name = _NotUnixFSError.name;
  code = _NotUnixFSError.code;
  constructor(message2 = "Not UnixFS") {
    super(message2);
  }
};
var OverReadError = class _OverReadError extends Error {
  static name = "OverReadError";
  static code = "ERR_OVER_READ";
  name = _OverReadError.name;
  code = _OverReadError.code;
  constructor(message2 = "Over read") {
    super(message2);
  }
};
var UnderReadError = class _UnderReadError extends Error {
  static name = "UnderReadError";
  static code = "ERR_UNDER_READ";
  name = _UnderReadError.name;
  code = _UnderReadError.code;
  constructor(message2 = "Under read") {
    super(message2);
  }
};
var NoPropError = class _NoPropError extends Error {
  static name = "NoPropError";
  static code = "ERR_NO_PROP";
  name = _NoPropError.name;
  code = _NoPropError.code;
  constructor(message2 = "No Property found") {
    super(message2);
  }
};
var InvalidParametersError3 = class _InvalidParametersError extends Error {
  static name = "InvalidParametersError";
  static code = "ERR_INVALID_PARAMS";
  name = _InvalidParametersError.name;
  code = _InvalidParametersError.code;
  constructor(message2 = "Invalid parameters") {
    super(message2);
  }
};

// node_modules/ipfs-unixfs-exporter/node_modules/multiformats/dist/src/codecs/json.js
var textEncoder = new TextEncoder();
var textDecoder = new TextDecoder();
var code5 = 512;
function decode17(data) {
  return JSON.parse(textDecoder.decode(data));
}

// node_modules/ipfs-unixfs-exporter/node_modules/multiformats/dist/src/codecs/raw.js
var code6 = 85;

// node_modules/ipfs-unixfs-exporter/node_modules/multiformats/dist/src/hashes/identity.js
var code7 = 0;
var name2 = "identity";
var encode9 = coerce3;
function digest(input) {
  return create4(code7, encode9(input));
}
var identity = { code: code7, name: name2, encode: encode9, digest };

// node_modules/ipfs-unixfs-exporter/dist/src/utils/resolve-object-path.js
function resolveObjectPath(object, block, cid, name3, path, toResolve, depth) {
  let subObject = object;
  let subPath = path;
  while (toResolve.length > 0) {
    const prop = toResolve[0];
    if (prop in subObject) {
      toResolve.shift();
      subPath = `${subPath}/${prop}`;
      const subObjectCid = CID3.asCID(subObject[prop]);
      if (subObjectCid != null) {
        return {
          entry: {
            type: "object",
            name: name3,
            path,
            cid,
            node: block,
            depth,
            size: BigInt(block.length),
            content: async function* () {
              yield object;
            }
          },
          next: {
            cid: subObjectCid,
            name: prop,
            path: subPath,
            toResolve
          }
        };
      }
      subObject = subObject[prop];
    } else {
      throw new NoPropError(`No property named ${prop} found in node ${cid}`);
    }
  }
  return {
    entry: {
      type: "object",
      name: name3,
      path,
      cid,
      node: block,
      depth,
      size: BigInt(block.length),
      content: async function* () {
        yield object;
      }
    }
  };
}

// node_modules/ipfs-unixfs-exporter/dist/src/resolvers/dag-cbor.js
var resolve = async (cid, name3, path, toResolve, resolve8, depth, blockstore, options) => {
  const block = await blockstore.get(cid, options);
  const object = decode(block);
  return resolveObjectPath(object, block, cid, name3, path, toResolve, depth);
};
var dag_cbor_default = resolve;

// node_modules/ipfs-unixfs-exporter/dist/src/resolvers/dag-json.js
var resolve2 = async (cid, name3, path, toResolve, resolve8, depth, blockstore, options) => {
  const block = await blockstore.get(cid, options);
  const object = decode2(block);
  return resolveObjectPath(object, block, cid, name3, path, toResolve, depth);
};
var dag_json_default = resolve2;

// node_modules/ipfs-unixfs-exporter/dist/src/utils/extract-data-from-block.js
function extractDataFromBlock(block, blockStart, requestedStart, requestedEnd) {
  const blockLength = BigInt(block.length);
  const blockEnd = BigInt(blockStart + blockLength);
  if (requestedStart >= blockEnd || requestedEnd < blockStart) {
    return new Uint8Array(0);
  }
  if (requestedEnd >= blockStart && requestedEnd < blockEnd) {
    block = block.subarray(0, Number(requestedEnd - blockStart));
  }
  if (requestedStart >= blockStart && requestedStart < blockEnd) {
    block = block.subarray(Number(requestedStart - blockStart));
  }
  return block;
}
var extract_data_from_block_default = extractDataFromBlock;

// node_modules/ipfs-unixfs-exporter/dist/src/utils/validate-offset-and-length.js
var validateOffsetAndLength = (size, offset = 0, length5 = size) => {
  const fileSize = BigInt(size);
  const start = BigInt(offset ?? 0);
  let end = BigInt(length5);
  if (end !== fileSize) {
    end = start + end;
  }
  if (end > fileSize) {
    end = fileSize;
  }
  if (start < 0n) {
    throw new InvalidParametersError3("Offset must be greater than or equal to 0");
  }
  if (start > fileSize) {
    throw new InvalidParametersError3("Offset must be less than the file size");
  }
  if (end < 0n) {
    throw new InvalidParametersError3("Length must be greater than or equal to 0");
  }
  if (end > fileSize) {
    throw new InvalidParametersError3("Length must be less than the file size");
  }
  return {
    start,
    end
  };
};
var validate_offset_and_length_default = validateOffsetAndLength;

// node_modules/ipfs-unixfs-exporter/dist/src/resolvers/identity.js
var rawContent = (node) => {
  async function* contentGenerator(options = {}) {
    const { start, end } = validate_offset_and_length_default(node.length, options.offset, options.length);
    const buf = extract_data_from_block_default(node, 0n, start, end);
    options.onProgress?.(new CustomProgressEvent("unixfs:exporter:progress:identity", {
      bytesRead: BigInt(buf.byteLength),
      totalBytes: end - start,
      fileSize: BigInt(node.byteLength)
    }));
    yield buf;
  }
  return contentGenerator;
};
var resolve3 = async (cid, name3, path, toResolve, resolve8, depth, blockstore, options) => {
  if (toResolve.length > 0) {
    throw new NotFoundError(`No link named ${path} found in raw node ${cid}`);
  }
  const buf = decode16(cid.multihash.bytes);
  return {
    entry: {
      type: "identity",
      name: name3,
      path,
      cid,
      content: rawContent(buf.digest),
      depth,
      size: BigInt(buf.digest.length),
      node: buf.digest
    }
  };
};
var identity_default = resolve3;

// node_modules/ipfs-unixfs-exporter/dist/src/resolvers/json.js
var resolve4 = async (cid, name3, path, toResolve, resolve8, depth, blockstore, options) => {
  const block = await blockstore.get(cid, options);
  const object = decode17(block);
  return resolveObjectPath(object, block, cid, name3, path, toResolve, depth);
};
var json_default = resolve4;

// node_modules/ipfs-unixfs-exporter/dist/src/resolvers/raw.js
var rawContent2 = (node) => {
  async function* contentGenerator(options = {}) {
    const { start, end } = validate_offset_and_length_default(node.length, options.offset, options.length);
    const buf = extract_data_from_block_default(node, 0n, start, end);
    options.onProgress?.(new CustomProgressEvent("unixfs:exporter:progress:raw", {
      bytesRead: BigInt(buf.byteLength),
      totalBytes: end - start,
      fileSize: BigInt(node.byteLength)
    }));
    yield buf;
  }
  return contentGenerator;
};
var resolve5 = async (cid, name3, path, toResolve, resolve8, depth, blockstore, options) => {
  if (toResolve.length > 0) {
    throw new NotFoundError(`No link named ${path} found in raw node ${cid}`);
  }
  const block = await blockstore.get(cid, options);
  return {
    entry: {
      type: "raw",
      name: name3,
      path,
      cid,
      content: rawContent2(block),
      depth,
      size: BigInt(block.length),
      node: block
    }
  };
};
var raw_default = resolve5;

// node_modules/ipfs-unixfs-exporter/dist/src/utils/find-cid-in-shard.js
var hashFn = async function(buf) {
  return (await murmur3128.encode(buf)).slice(0, 8).reverse();
};
var addLinksToHamtBucket = async (links, bucket, rootBucket) => {
  const padLength = (bucket.tableSize() - 1).toString(16).length;
  await Promise.all(links.map(async (link) => {
    if (link.Name == null) {
      throw new Error("Unexpected Link without a Name");
    }
    if (link.Name.length === padLength) {
      const pos = parseInt(link.Name, 16);
      bucket._putObjectAt(pos, new Bucket({
        hash: rootBucket._options.hash,
        bits: rootBucket._options.bits
      }, bucket, pos));
      return;
    }
    await rootBucket.put(link.Name.substring(2), true);
  }));
};
var toPrefix = (position, padLength) => {
  return position.toString(16).toUpperCase().padStart(padLength, "0").substring(0, padLength);
};
var toBucketPath = (position) => {
  let bucket = position.bucket;
  const path = [];
  while (bucket._parent != null) {
    path.push(bucket);
    bucket = bucket._parent;
  }
  path.push(bucket);
  return path.reverse();
};
var findShardCid = async (node, name3, blockstore, context, options) => {
  if (context == null) {
    if (node.Data == null) {
      throw new NotUnixFSError2("no data in PBNode");
    }
    let dir;
    try {
      dir = UnixFS.unmarshal(node.Data);
    } catch (err) {
      throw new NotUnixFSError2(err.message);
    }
    if (dir.type !== "hamt-sharded-directory") {
      throw new NotUnixFSError2("not a HAMT");
    }
    if (dir.fanout == null) {
      throw new NotUnixFSError2("missing fanout");
    }
    const rootBucket = createHAMT({
      hashFn,
      bits: Math.log2(Number(dir.fanout))
    });
    context = {
      rootBucket,
      hamtDepth: 1,
      lastBucket: rootBucket
    };
  }
  const padLength = (context.lastBucket.tableSize() - 1).toString(16).length;
  await addLinksToHamtBucket(node.Links, context.lastBucket, context.rootBucket);
  const position = await context.rootBucket._findNewBucketAndPos(name3);
  let prefix = toPrefix(position.pos, padLength);
  const bucketPath = toBucketPath(position);
  if (bucketPath.length > context.hamtDepth) {
    context.lastBucket = bucketPath[context.hamtDepth];
    prefix = toPrefix(context.lastBucket._posAtParent, padLength);
  }
  const link = node.Links.find((link2) => {
    if (link2.Name == null) {
      return false;
    }
    const entryPrefix = link2.Name.substring(0, padLength);
    const entryName = link2.Name.substring(padLength);
    if (entryPrefix !== prefix) {
      return false;
    }
    if (entryName !== "" && entryName !== name3) {
      return false;
    }
    return true;
  });
  if (link == null) {
    return;
  }
  if (link.Name != null && link.Name.substring(padLength) === name3) {
    return link.Hash;
  }
  context.hamtDepth++;
  const block = await blockstore.get(link.Hash, options);
  node = decode3(block);
  return findShardCid(node, name3, blockstore, context, options);
};
var find_cid_in_shard_default = findShardCid;

// node_modules/ipfs-unixfs-exporter/dist/src/resolvers/unixfs-v1/content/directory.js
var directoryContent = (cid, node, unixfs2, path, resolve8, depth, blockstore) => {
  async function* yieldDirectoryContent(options = {}) {
    const offset = options.offset ?? 0;
    const length5 = options.length ?? node.Links.length;
    const links = node.Links.slice(offset, length5);
    options.onProgress?.(new CustomProgressEvent("unixfs:exporter:walk:directory", {
      cid
    }));
    yield* pipe(links, (source) => src_default2(source, (link) => {
      return async () => {
        const linkName = link.Name ?? "";
        const linkPath = `${path}/${linkName}`;
        const result = await resolve8(link.Hash, linkName, linkPath, [], depth + 1, blockstore, options);
        return result.entry;
      };
    }), (source) => parallel(source, {
      ordered: true,
      concurrency: options.blockReadConcurrency
    }), (source) => src_default(source, (entry) => entry != null));
  }
  return yieldDirectoryContent;
};
var directory_default = directoryContent;

// node_modules/ipfs-unixfs-exporter/dist/src/resolvers/unixfs-v1/content/file.js
async function walkDAG(blockstore, node, queue, streamPosition, start, end, options) {
  if (node instanceof Uint8Array) {
    const buf = extract_data_from_block_default(node, streamPosition, start, end);
    queue.push(buf);
    return;
  }
  if (node.Data == null) {
    throw new NotUnixFSError2("no data in PBNode");
  }
  let file;
  try {
    file = UnixFS.unmarshal(node.Data);
  } catch (err) {
    throw new NotUnixFSError2(err.message);
  }
  if (file.data != null) {
    const data = file.data;
    const buf = extract_data_from_block_default(data, streamPosition, start, end);
    queue.push(buf);
    streamPosition += BigInt(buf.byteLength);
  }
  const childOps = [];
  if (node.Links.length !== file.blockSizes.length) {
    throw new NotUnixFSError2("Inconsistent block sizes and dag links");
  }
  for (let i = 0; i < node.Links.length; i++) {
    const childLink = node.Links[i];
    const childStart = streamPosition;
    const childEnd = childStart + file.blockSizes[i];
    if (start >= childStart && start < childEnd || // child has offset byte
    end >= childStart && end <= childEnd || // child has end byte
    start < childStart && end > childEnd) {
      childOps.push({
        link: childLink,
        blockStart: streamPosition
      });
    }
    streamPosition = childEnd;
    if (streamPosition > end) {
      break;
    }
  }
  await pipe(childOps, (source) => src_default2(source, (op) => {
    return async () => {
      const block = await blockstore.get(op.link.Hash, options);
      return {
        ...op,
        block
      };
    };
  }), (source) => parallel(source, {
    ordered: true,
    concurrency: options.blockReadConcurrency
  }), async (source) => {
    for await (const { link, block, blockStart } of source) {
      let child;
      switch (link.Hash.code) {
        case code3:
          child = decode3(block);
          break;
        case code6:
          child = block;
          break;
        default:
          queue.end(new NotUnixFSError2(`Unsupported codec: ${link.Hash.code}`));
          return;
      }
      const childQueue = new PQueue({
        concurrency: 1
      });
      childQueue.on("error", (error) => {
        queue.end(error);
      });
      void childQueue.add(async () => {
        options.onProgress?.(new CustomProgressEvent("unixfs:exporter:walk:file", {
          cid: link.Hash
        }));
        await walkDAG(blockstore, child, queue, blockStart, start, end, options);
      });
      await childQueue.onIdle();
    }
  });
  if (streamPosition >= end) {
    queue.end();
  }
}
var fileContent = (cid, node, unixfs2, path, resolve8, depth, blockstore) => {
  async function* yieldFileContent(options = {}) {
    const fileSize = unixfs2.fileSize();
    if (fileSize === void 0) {
      throw new Error("File was a directory");
    }
    const { start, end } = validate_offset_and_length_default(fileSize, options.offset, options.length);
    if (end === 0n) {
      return;
    }
    let read5 = 0n;
    const wanted = end - start;
    const queue = pushable();
    options.onProgress?.(new CustomProgressEvent("unixfs:exporter:walk:file", {
      cid
    }));
    void walkDAG(blockstore, node, queue, 0n, start, end, options).catch((err) => {
      queue.end(err);
    });
    for await (const buf of queue) {
      if (buf == null) {
        continue;
      }
      read5 += BigInt(buf.byteLength);
      if (read5 > wanted) {
        queue.end();
        throw new OverReadError("Read too many bytes - the file size reported by the UnixFS data in the root node may be incorrect");
      }
      if (read5 === wanted) {
        queue.end();
      }
      options.onProgress?.(new CustomProgressEvent("unixfs:exporter:progress:unixfs:file", {
        bytesRead: read5,
        totalBytes: wanted,
        fileSize
      }));
      yield buf;
    }
    if (read5 < wanted) {
      throw new UnderReadError("Traversed entire DAG but did not read enough bytes");
    }
  }
  return yieldFileContent;
};
var file_default = fileContent;

// node_modules/ipfs-unixfs-exporter/dist/src/resolvers/unixfs-v1/content/hamt-sharded-directory.js
var hamtShardedDirectoryContent = (cid, node, unixfs2, path, resolve8, depth, blockstore) => {
  function yieldHamtDirectoryContent(options = {}) {
    options.onProgress?.(new CustomProgressEvent("unixfs:exporter:walk:hamt-sharded-directory", {
      cid
    }));
    return listDirectory(node, path, resolve8, depth, blockstore, options);
  }
  return yieldHamtDirectoryContent;
};
async function* listDirectory(node, path, resolve8, depth, blockstore, options) {
  const links = node.Links;
  if (node.Data == null) {
    throw new NotUnixFSError2("no data in PBNode");
  }
  let dir;
  try {
    dir = UnixFS.unmarshal(node.Data);
  } catch (err) {
    throw new NotUnixFSError2(err.message);
  }
  if (dir.fanout == null) {
    throw new NotUnixFSError2("missing fanout");
  }
  const padLength = (dir.fanout - 1n).toString(16).length;
  const results = pipe(links, (source) => src_default2(source, (link) => {
    return async () => {
      const name3 = link.Name != null ? link.Name.substring(padLength) : null;
      if (name3 != null && name3 !== "") {
        const result = await resolve8(link.Hash, name3, `${path}/${name3}`, [], depth + 1, blockstore, options);
        return { entries: result.entry == null ? [] : [result.entry] };
      } else {
        const block = await blockstore.get(link.Hash, options);
        node = decode3(block);
        options.onProgress?.(new CustomProgressEvent("unixfs:exporter:walk:hamt-sharded-directory", {
          cid: link.Hash
        }));
        return { entries: listDirectory(node, path, resolve8, depth, blockstore, options) };
      }
    };
  }), (source) => parallel(source, {
    ordered: true,
    concurrency: options.blockReadConcurrency
  }));
  for await (const { entries } of results) {
    yield* entries;
  }
}
var hamt_sharded_directory_default = hamtShardedDirectoryContent;

// node_modules/ipfs-unixfs-exporter/dist/src/resolvers/unixfs-v1/index.js
var findLinkCid = (node, name3) => {
  const link = node.Links.find((link2) => link2.Name === name3);
  return link?.Hash;
};
var contentExporters = {
  raw: file_default,
  file: file_default,
  directory: directory_default,
  "hamt-sharded-directory": hamt_sharded_directory_default,
  metadata: (cid, node, unixfs2, path, resolve8, depth, blockstore) => {
    return () => [];
  },
  symlink: (cid, node, unixfs2, path, resolve8, depth, blockstore) => {
    return () => [];
  }
};
var unixFsResolver = async (cid, name3, path, toResolve, resolve8, depth, blockstore, options) => {
  const block = await blockstore.get(cid, options);
  const node = decode3(block);
  let unixfs2;
  let next;
  if (name3 == null) {
    name3 = cid.toString();
  }
  if (node.Data == null) {
    throw new NotUnixFSError2("no data in PBNode");
  }
  try {
    unixfs2 = UnixFS.unmarshal(node.Data);
  } catch (err) {
    throw new NotUnixFSError2(err.message);
  }
  if (path == null) {
    path = name3;
  }
  if (toResolve.length > 0) {
    let linkCid;
    if (unixfs2?.type === "hamt-sharded-directory") {
      linkCid = await find_cid_in_shard_default(node, toResolve[0], blockstore);
    } else {
      linkCid = findLinkCid(node, toResolve[0]);
    }
    if (linkCid == null) {
      throw new NotFoundError("file does not exist");
    }
    const nextName = toResolve.shift();
    const nextPath = `${path}/${nextName}`;
    next = {
      cid: linkCid,
      toResolve,
      name: nextName ?? "",
      path: nextPath
    };
  }
  const content = contentExporters[unixfs2.type](cid, node, unixfs2, path, resolve8, depth, blockstore);
  if (content == null) {
    throw new NotFoundError("could not find content exporter");
  }
  if (unixfs2.isDirectory()) {
    return {
      entry: {
        type: "directory",
        name: name3,
        path,
        cid,
        content,
        unixfs: unixfs2,
        depth,
        node,
        size: unixfs2.fileSize()
      },
      next
    };
  }
  return {
    entry: {
      type: "file",
      name: name3,
      path,
      cid,
      content,
      unixfs: unixfs2,
      depth,
      node,
      size: unixfs2.fileSize()
    },
    next
  };
};
var unixfs_v1_default = unixFsResolver;

// node_modules/ipfs-unixfs-exporter/dist/src/resolvers/index.js
var resolvers = {
  [code3]: unixfs_v1_default,
  [code6]: raw_default,
  [code]: dag_cbor_default,
  [code2]: dag_json_default,
  [identity.code]: identity_default,
  [code5]: json_default
};
var resolve6 = async (cid, name3, path, toResolve, depth, blockstore, options) => {
  const resolver = resolvers[cid.code];
  if (resolver == null) {
    throw new NoResolverError(`No resolver for code ${cid.code}`);
  }
  return resolver(cid, name3, path, toResolve, resolve6, depth, blockstore, options);
};
var resolvers_default = resolve6;

// node_modules/ipfs-unixfs-exporter/dist/src/index.js
var toPathComponents2 = (path = "") => {
  return (path.trim().match(/([^\\^/]|\\\/)+/g) ?? []).filter(Boolean);
};
var cidAndRest = (path) => {
  if (path instanceof Uint8Array) {
    return {
      cid: CID3.decode(path),
      toResolve: []
    };
  }
  const cid = CID3.asCID(path);
  if (cid != null) {
    return {
      cid,
      toResolve: []
    };
  }
  if (typeof path === "string") {
    if (path.indexOf("/ipfs/") === 0) {
      path = path.substring(6);
    }
    const output = toPathComponents2(path);
    return {
      cid: CID3.parse(output[0]),
      toResolve: output.slice(1)
    };
  }
  throw new BadPathError(`Unknown path type ${path}`);
};
async function* walkPath(path, blockstore, options = {}) {
  let { cid, toResolve } = cidAndRest(path);
  let name3 = cid.toString();
  let entryPath = name3;
  const startingDepth = toResolve.length;
  while (true) {
    const result = await resolvers_default(cid, name3, entryPath, toResolve, startingDepth, blockstore, options);
    if (result.entry == null && result.next == null) {
      throw new NotFoundError(`Could not resolve ${path}`);
    }
    if (result.entry != null) {
      yield result.entry;
    }
    if (result.next == null) {
      return;
    }
    toResolve = result.next.toResolve;
    cid = result.next.cid;
    name3 = result.next.name;
    entryPath = result.next.path;
  }
}
async function exporter(path, blockstore, options = {}) {
  const result = await src_default6(walkPath(path, blockstore, options));
  if (result == null) {
    throw new NotFoundError(`Could not resolve ${path}`);
  }
  return result;
}
async function* recursive(path, blockstore, options = {}) {
  const node = await exporter(path, blockstore, options);
  if (node == null) {
    return;
  }
  yield node;
  if (node.type === "directory") {
    for await (const child of recurse(node, options)) {
      yield child;
    }
  }
  async function* recurse(node2, options2) {
    for await (const file of node2.content(options2)) {
      yield file;
      if (file instanceof Uint8Array) {
        continue;
      }
      if (file.type === "directory") {
        yield* recurse(file, options2);
      }
    }
  }
}

// node_modules/@helia/unixfs/node_modules/multiformats/dist/src/bytes.js
var empty4 = new Uint8Array(0);
function equals7(aa, bb) {
  if (aa === bb) {
    return true;
  }
  if (aa.byteLength !== bb.byteLength) {
    return false;
  }
  for (let ii = 0; ii < aa.byteLength; ii++) {
    if (aa[ii] !== bb[ii]) {
      return false;
    }
  }
  return true;
}
function coerce4(o) {
  if (o instanceof Uint8Array && o.constructor.name === "Uint8Array") {
    return o;
  }
  if (o instanceof ArrayBuffer) {
    return new Uint8Array(o);
  }
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength);
  }
  throw new Error("Unknown type, must be binary type");
}

// node_modules/@helia/unixfs/node_modules/multiformats/dist/src/vendor/base-x.js
function base4(ALPHABET, name3) {
  if (ALPHABET.length >= 255) {
    throw new TypeError("Alphabet too long");
  }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) {
      throw new TypeError(x + " is ambiguous");
    }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256);
  var iFACTOR = Math.log(256) / Math.log(BASE);
  function encode12(source) {
    if (source instanceof Uint8Array)
      ;
    else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) {
      throw new TypeError("Expected Uint8Array");
    }
    if (source.length === 0) {
      return "";
    }
    var zeroes = 0;
    var length5 = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
    var size = (pend - pbegin) * iFACTOR + 1 >>> 0;
    var b58 = new Uint8Array(size);
    while (pbegin !== pend) {
      var carry = source[pbegin];
      var i2 = 0;
      for (var it1 = size - 1; (carry !== 0 || i2 < length5) && it1 !== -1; it1--, i2++) {
        carry += 256 * b58[it1] >>> 0;
        b58[it1] = carry % BASE >>> 0;
        carry = carry / BASE >>> 0;
      }
      if (carry !== 0) {
        throw new Error("Non-zero carry");
      }
      length5 = i2;
      pbegin++;
    }
    var it2 = size - length5;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
    var str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) {
      str += ALPHABET.charAt(b58[it2]);
    }
    return str;
  }
  function decodeUnsafe(source) {
    if (typeof source !== "string") {
      throw new TypeError("Expected String");
    }
    if (source.length === 0) {
      return new Uint8Array();
    }
    var psz = 0;
    if (source[psz] === " ") {
      return;
    }
    var zeroes = 0;
    var length5 = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
    var size = (source.length - psz) * FACTOR + 1 >>> 0;
    var b256 = new Uint8Array(size);
    while (source[psz]) {
      var carry = BASE_MAP[source.charCodeAt(psz)];
      if (carry === 255) {
        return;
      }
      var i2 = 0;
      for (var it3 = size - 1; (carry !== 0 || i2 < length5) && it3 !== -1; it3--, i2++) {
        carry += BASE * b256[it3] >>> 0;
        b256[it3] = carry % 256 >>> 0;
        carry = carry / 256 >>> 0;
      }
      if (carry !== 0) {
        throw new Error("Non-zero carry");
      }
      length5 = i2;
      psz++;
    }
    if (source[psz] === " ") {
      return;
    }
    var it4 = size - length5;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size - it4));
    var j2 = zeroes;
    while (it4 !== size) {
      vch[j2++] = b256[it4++];
    }
    return vch;
  }
  function decode22(string) {
    var buffer = decodeUnsafe(string);
    if (buffer) {
      return buffer;
    }
    throw new Error(`Non-${name3} character`);
  }
  return {
    encode: encode12,
    decodeUnsafe,
    decode: decode22
  };
}
var src4 = base4;
var _brrp__multiformats_scope_baseX4 = src4;
var base_x_default4 = _brrp__multiformats_scope_baseX4;

// node_modules/@helia/unixfs/node_modules/multiformats/dist/src/bases/base.js
var Encoder4 = class {
  name;
  prefix;
  baseEncode;
  constructor(name3, prefix, baseEncode) {
    this.name = name3;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
  }
  encode(bytes) {
    if (bytes instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes)}`;
    } else {
      throw Error("Unknown type, must be binary type");
    }
  }
};
var Decoder4 = class {
  name;
  prefix;
  baseDecode;
  prefixCodePoint;
  constructor(name3, prefix, baseDecode) {
    this.name = name3;
    this.prefix = prefix;
    const prefixCodePoint = prefix.codePointAt(0);
    if (prefixCodePoint === void 0) {
      throw new Error("Invalid prefix character");
    }
    this.prefixCodePoint = prefixCodePoint;
    this.baseDecode = baseDecode;
  }
  decode(text) {
    if (typeof text === "string") {
      if (text.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`);
      }
      return this.baseDecode(text.slice(this.prefix.length));
    } else {
      throw Error("Can only multibase decode strings");
    }
  }
  or(decoder) {
    return or4(this, decoder);
  }
};
var ComposedDecoder4 = class {
  decoders;
  constructor(decoders) {
    this.decoders = decoders;
  }
  or(decoder) {
    return or4(this, decoder);
  }
  decode(input) {
    const prefix = input[0];
    const decoder = this.decoders[prefix];
    if (decoder != null) {
      return decoder.decode(input);
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`);
    }
  }
};
function or4(left, right) {
  return new ComposedDecoder4({
    ...left.decoders ?? { [left.prefix]: left },
    ...right.decoders ?? { [right.prefix]: right }
  });
}
var Codec4 = class {
  name;
  prefix;
  baseEncode;
  baseDecode;
  encoder;
  decoder;
  constructor(name3, prefix, baseEncode, baseDecode) {
    this.name = name3;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder4(name3, prefix, baseEncode);
    this.decoder = new Decoder4(name3, prefix, baseDecode);
  }
  encode(input) {
    return this.encoder.encode(input);
  }
  decode(input) {
    return this.decoder.decode(input);
  }
};
function from6({ name: name3, prefix, encode: encode12, decode: decode22 }) {
  return new Codec4(name3, prefix, encode12, decode22);
}
function baseX4({ name: name3, prefix, alphabet }) {
  const { encode: encode12, decode: decode22 } = base_x_default4(alphabet, name3);
  return from6({
    prefix,
    name: name3,
    encode: encode12,
    decode: (text) => coerce4(decode22(text))
  });
}
function decode18(string, alphabetIdx, bitsPerChar, name3) {
  let end = string.length;
  while (string[end - 1] === "=") {
    --end;
  }
  const out = new Uint8Array(end * bitsPerChar / 8 | 0);
  let bits = 0;
  let buffer = 0;
  let written = 0;
  for (let i = 0; i < end; ++i) {
    const value = alphabetIdx[string[i]];
    if (value === void 0) {
      throw new SyntaxError(`Non-${name3} character`);
    }
    buffer = buffer << bitsPerChar | value;
    bits += bitsPerChar;
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 255 & buffer >> bits;
    }
  }
  if (bits >= bitsPerChar || (255 & buffer << 8 - bits) !== 0) {
    throw new SyntaxError("Unexpected end of data");
  }
  return out;
}
function encode10(data, alphabet, bitsPerChar) {
  const pad = alphabet[alphabet.length - 1] === "=";
  const mask = (1 << bitsPerChar) - 1;
  let out = "";
  let bits = 0;
  let buffer = 0;
  for (let i = 0; i < data.length; ++i) {
    buffer = buffer << 8 | data[i];
    bits += 8;
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet[mask & buffer >> bits];
    }
  }
  if (bits !== 0) {
    out += alphabet[mask & buffer << bitsPerChar - bits];
  }
  if (pad) {
    while ((out.length * bitsPerChar & 7) !== 0) {
      out += "=";
    }
  }
  return out;
}
function createAlphabetIdx4(alphabet) {
  const alphabetIdx = {};
  for (let i = 0; i < alphabet.length; ++i) {
    alphabetIdx[alphabet[i]] = i;
  }
  return alphabetIdx;
}
function rfc46484({ name: name3, prefix, bitsPerChar, alphabet }) {
  const alphabetIdx = createAlphabetIdx4(alphabet);
  return from6({
    prefix,
    name: name3,
    encode(input) {
      return encode10(input, alphabet, bitsPerChar);
    },
    decode(input) {
      return decode18(input, alphabetIdx, bitsPerChar, name3);
    }
  });
}

// node_modules/@helia/unixfs/node_modules/multiformats/dist/src/bases/base32.js
var base324 = rfc46484({
  prefix: "b",
  name: "base32",
  alphabet: "abcdefghijklmnopqrstuvwxyz234567",
  bitsPerChar: 5
});
var base32upper4 = rfc46484({
  prefix: "B",
  name: "base32upper",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZ234567",
  bitsPerChar: 5
});
var base32pad4 = rfc46484({
  prefix: "c",
  name: "base32pad",
  alphabet: "abcdefghijklmnopqrstuvwxyz234567=",
  bitsPerChar: 5
});
var base32padupper4 = rfc46484({
  prefix: "C",
  name: "base32padupper",
  alphabet: "ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=",
  bitsPerChar: 5
});
var base32hex4 = rfc46484({
  prefix: "v",
  name: "base32hex",
  alphabet: "0123456789abcdefghijklmnopqrstuv",
  bitsPerChar: 5
});
var base32hexupper4 = rfc46484({
  prefix: "V",
  name: "base32hexupper",
  alphabet: "0123456789ABCDEFGHIJKLMNOPQRSTUV",
  bitsPerChar: 5
});
var base32hexpad4 = rfc46484({
  prefix: "t",
  name: "base32hexpad",
  alphabet: "0123456789abcdefghijklmnopqrstuv=",
  bitsPerChar: 5
});
var base32hexpadupper4 = rfc46484({
  prefix: "T",
  name: "base32hexpadupper",
  alphabet: "0123456789ABCDEFGHIJKLMNOPQRSTUV=",
  bitsPerChar: 5
});
var base32z4 = rfc46484({
  prefix: "h",
  name: "base32z",
  alphabet: "ybndrfg8ejkmcpqxot1uwisza345h769",
  bitsPerChar: 5
});

// node_modules/@helia/unixfs/node_modules/multiformats/dist/src/bases/base36.js
var base364 = baseX4({
  prefix: "k",
  name: "base36",
  alphabet: "0123456789abcdefghijklmnopqrstuvwxyz"
});
var base36upper4 = baseX4({
  prefix: "K",
  name: "base36upper",
  alphabet: "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ"
});

// node_modules/@helia/unixfs/node_modules/multiformats/dist/src/bases/base58.js
var base58btc4 = baseX4({
  name: "base58btc",
  prefix: "z",
  alphabet: "123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz"
});
var base58flickr4 = baseX4({
  name: "base58flickr",
  prefix: "Z",
  alphabet: "123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ"
});

// node_modules/@helia/unixfs/node_modules/multiformats/dist/src/vendor/varint.js
var encode_14 = encode11;
var MSB4 = 128;
var REST4 = 127;
var MSBALL4 = ~REST4;
var INT4 = Math.pow(2, 31);
function encode11(num, out, offset) {
  out = out || [];
  offset = offset || 0;
  var oldOffset = offset;
  while (num >= INT4) {
    out[offset++] = num & 255 | MSB4;
    num /= 128;
  }
  while (num & MSBALL4) {
    out[offset++] = num & 255 | MSB4;
    num >>>= 7;
  }
  out[offset] = num | 0;
  encode11.bytes = offset - oldOffset + 1;
  return out;
}
var decode19 = read4;
var MSB$14 = 128;
var REST$14 = 127;
function read4(buf, offset) {
  var res = 0, offset = offset || 0, shift = 0, counter = offset, b, l = buf.length;
  do {
    if (counter >= l) {
      read4.bytes = 0;
      throw new RangeError("Could not decode varint");
    }
    b = buf[counter++];
    res += shift < 28 ? (b & REST$14) << shift : (b & REST$14) * Math.pow(2, shift);
    shift += 7;
  } while (b >= MSB$14);
  read4.bytes = counter - offset;
  return res;
}
var N14 = Math.pow(2, 7);
var N24 = Math.pow(2, 14);
var N34 = Math.pow(2, 21);
var N44 = Math.pow(2, 28);
var N54 = Math.pow(2, 35);
var N64 = Math.pow(2, 42);
var N74 = Math.pow(2, 49);
var N84 = Math.pow(2, 56);
var N94 = Math.pow(2, 63);
var length4 = function(value) {
  return value < N14 ? 1 : value < N24 ? 2 : value < N34 ? 3 : value < N44 ? 4 : value < N54 ? 5 : value < N64 ? 6 : value < N74 ? 7 : value < N84 ? 8 : value < N94 ? 9 : 10;
};
var varint4 = {
  encode: encode_14,
  decode: decode19,
  encodingLength: length4
};
var _brrp_varint4 = varint4;
var varint_default4 = _brrp_varint4;

// node_modules/@helia/unixfs/node_modules/multiformats/dist/src/varint.js
function decode20(data, offset = 0) {
  const code9 = varint_default4.decode(data, offset);
  return [code9, varint_default4.decode.bytes];
}
function encodeTo4(int, target, offset = 0) {
  varint_default4.encode(int, target, offset);
  return target;
}
function encodingLength4(int) {
  return varint_default4.encodingLength(int);
}

// node_modules/@helia/unixfs/node_modules/multiformats/dist/src/hashes/digest.js
function create5(code9, digest2) {
  const size = digest2.byteLength;
  const sizeOffset = encodingLength4(code9);
  const digestOffset = sizeOffset + encodingLength4(size);
  const bytes = new Uint8Array(digestOffset + size);
  encodeTo4(code9, bytes, 0);
  encodeTo4(size, bytes, sizeOffset);
  bytes.set(digest2, digestOffset);
  return new Digest4(code9, size, digest2, bytes);
}
function decode21(multihash) {
  const bytes = coerce4(multihash);
  const [code9, sizeOffset] = decode20(bytes);
  const [size, digestOffset] = decode20(bytes.subarray(sizeOffset));
  const digest2 = bytes.subarray(sizeOffset + digestOffset);
  if (digest2.byteLength !== size) {
    throw new Error("Incorrect length");
  }
  return new Digest4(code9, size, digest2, bytes);
}
function equals8(a, b) {
  if (a === b) {
    return true;
  } else {
    const data = b;
    return a.code === data.code && a.size === data.size && data.bytes instanceof Uint8Array && equals7(a.bytes, data.bytes);
  }
}
var Digest4 = class {
  code;
  size;
  digest;
  bytes;
  /**
   * Creates a multihash digest.
   */
  constructor(code9, size, digest2, bytes) {
    this.code = code9;
    this.size = size;
    this.digest = digest2;
    this.bytes = bytes;
  }
};

// node_modules/@helia/unixfs/node_modules/multiformats/dist/src/cid.js
function format4(link, base5) {
  const { bytes, version } = link;
  switch (version) {
    case 0:
      return toStringV04(bytes, baseCache4(link), base5 ?? base58btc4.encoder);
    default:
      return toStringV14(bytes, baseCache4(link), base5 ?? base324.encoder);
  }
}
var cache4 = /* @__PURE__ */ new WeakMap();
function baseCache4(cid) {
  const baseCache5 = cache4.get(cid);
  if (baseCache5 == null) {
    const baseCache6 = /* @__PURE__ */ new Map();
    cache4.set(cid, baseCache6);
    return baseCache6;
  }
  return baseCache5;
}
var CID4 = class _CID {
  code;
  version;
  multihash;
  bytes;
  "/";
  /**
   * @param version - Version of the CID
   * @param code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param multihash - (Multi)hash of the of the content.
   */
  constructor(version, code9, multihash, bytes) {
    this.code = code9;
    this.version = version;
    this.multihash = multihash;
    this.bytes = bytes;
    this["/"] = bytes;
  }
  /**
   * Signalling `cid.asCID === cid` has been replaced with `cid['/'] === cid.bytes`
   * please either use `CID.asCID(cid)` or switch to new signalling mechanism
   *
   * @deprecated
   */
  get asCID() {
    return this;
  }
  // ArrayBufferView
  get byteOffset() {
    return this.bytes.byteOffset;
  }
  // ArrayBufferView
  get byteLength() {
    return this.bytes.byteLength;
  }
  toV0() {
    switch (this.version) {
      case 0: {
        return this;
      }
      case 1: {
        const { code: code9, multihash } = this;
        if (code9 !== DAG_PB_CODE4) {
          throw new Error("Cannot convert a non dag-pb CID to CIDv0");
        }
        if (multihash.code !== SHA_256_CODE4) {
          throw new Error("Cannot convert non sha2-256 multihash CID to CIDv0");
        }
        return _CID.createV0(multihash);
      }
      default: {
        throw Error(`Can not convert CID version ${this.version} to version 0. This is a bug please report`);
      }
    }
  }
  toV1() {
    switch (this.version) {
      case 0: {
        const { code: code9, digest: digest2 } = this.multihash;
        const multihash = create5(code9, digest2);
        return _CID.createV1(this.code, multihash);
      }
      case 1: {
        return this;
      }
      default: {
        throw Error(`Can not convert CID version ${this.version} to version 1. This is a bug please report`);
      }
    }
  }
  equals(other) {
    return _CID.equals(this, other);
  }
  static equals(self, other) {
    const unknown = other;
    return unknown != null && self.code === unknown.code && self.version === unknown.version && equals8(self.multihash, unknown.multihash);
  }
  toString(base5) {
    return format4(this, base5);
  }
  toJSON() {
    return { "/": format4(this) };
  }
  link() {
    return this;
  }
  [Symbol.toStringTag] = "CID";
  // Legacy
  [Symbol.for("nodejs.util.inspect.custom")]() {
    return `CID(${this.toString()})`;
  }
  /**
   * Takes any input `value` and returns a `CID` instance if it was
   * a `CID` otherwise returns `null`. If `value` is instanceof `CID`
   * it will return value back. If `value` is not instance of this CID
   * class, but is compatible CID it will return new instance of this
   * `CID` class. Otherwise returns null.
   *
   * This allows two different incompatible versions of CID library to
   * co-exist and interop as long as binary interface is compatible.
   */
  static asCID(input) {
    if (input == null) {
      return null;
    }
    const value = input;
    if (value instanceof _CID) {
      return value;
    } else if (value["/"] != null && value["/"] === value.bytes || value.asCID === value) {
      const { version, code: code9, multihash, bytes } = value;
      return new _CID(version, code9, multihash, bytes ?? encodeCID4(version, code9, multihash.bytes));
    } else if (value[cidSymbol4] === true) {
      const { version, multihash, code: code9 } = value;
      const digest2 = decode21(multihash);
      return _CID.create(version, code9, digest2);
    } else {
      return null;
    }
  }
  /**
   * @param version - Version of the CID
   * @param code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param digest - (Multi)hash of the of the content.
   */
  static create(version, code9, digest2) {
    if (typeof code9 !== "number") {
      throw new Error("String codecs are no longer supported");
    }
    if (!(digest2.bytes instanceof Uint8Array)) {
      throw new Error("Invalid digest");
    }
    switch (version) {
      case 0: {
        if (code9 !== DAG_PB_CODE4) {
          throw new Error(`Version 0 CID must use dag-pb (code: ${DAG_PB_CODE4}) block encoding`);
        } else {
          return new _CID(version, code9, digest2, digest2.bytes);
        }
      }
      case 1: {
        const bytes = encodeCID4(version, code9, digest2.bytes);
        return new _CID(version, code9, digest2, bytes);
      }
      default: {
        throw new Error("Invalid version");
      }
    }
  }
  /**
   * Simplified version of `create` for CIDv0.
   */
  static createV0(digest2) {
    return _CID.create(0, DAG_PB_CODE4, digest2);
  }
  /**
   * Simplified version of `create` for CIDv1.
   *
   * @param code - Content encoding format code.
   * @param digest - Multihash of the content.
   */
  static createV1(code9, digest2) {
    return _CID.create(1, code9, digest2);
  }
  /**
   * Decoded a CID from its binary representation. The byte array must contain
   * only the CID with no additional bytes.
   *
   * An error will be thrown if the bytes provided do not contain a valid
   * binary representation of a CID.
   */
  static decode(bytes) {
    const [cid, remainder] = _CID.decodeFirst(bytes);
    if (remainder.length !== 0) {
      throw new Error("Incorrect length");
    }
    return cid;
  }
  /**
   * Decoded a CID from its binary representation at the beginning of a byte
   * array.
   *
   * Returns an array with the first element containing the CID and the second
   * element containing the remainder of the original byte array. The remainder
   * will be a zero-length byte array if the provided bytes only contained a
   * binary CID representation.
   */
  static decodeFirst(bytes) {
    const specs = _CID.inspectBytes(bytes);
    const prefixSize = specs.size - specs.multihashSize;
    const multihashBytes = coerce4(bytes.subarray(prefixSize, prefixSize + specs.multihashSize));
    if (multihashBytes.byteLength !== specs.multihashSize) {
      throw new Error("Incorrect length");
    }
    const digestBytes = multihashBytes.subarray(specs.multihashSize - specs.digestSize);
    const digest2 = new Digest4(specs.multihashCode, specs.digestSize, digestBytes, multihashBytes);
    const cid = specs.version === 0 ? _CID.createV0(digest2) : _CID.createV1(specs.codec, digest2);
    return [cid, bytes.subarray(specs.size)];
  }
  /**
   * Inspect the initial bytes of a CID to determine its properties.
   *
   * Involves decoding up to 4 varints. Typically this will require only 4 to 6
   * bytes but for larger multicodec code values and larger multihash digest
   * lengths these varints can be quite large. It is recommended that at least
   * 10 bytes be made available in the `initialBytes` argument for a complete
   * inspection.
   */
  static inspectBytes(initialBytes) {
    let offset = 0;
    const next = () => {
      const [i, length5] = decode20(initialBytes.subarray(offset));
      offset += length5;
      return i;
    };
    let version = next();
    let codec = DAG_PB_CODE4;
    if (version === 18) {
      version = 0;
      offset = 0;
    } else {
      codec = next();
    }
    if (version !== 0 && version !== 1) {
      throw new RangeError(`Invalid CID version ${version}`);
    }
    const prefixSize = offset;
    const multihashCode = next();
    const digestSize = next();
    const size = offset + digestSize;
    const multihashSize = size - prefixSize;
    return { version, codec, multihashCode, digestSize, multihashSize, size };
  }
  /**
   * Takes cid in a string representation and creates an instance. If `base`
   * decoder is not provided will use a default from the configuration. It will
   * throw an error if encoding of the CID is not compatible with supplied (or
   * a default decoder).
   */
  static parse(source, base5) {
    const [prefix, bytes] = parseCIDtoBytes4(source, base5);
    const cid = _CID.decode(bytes);
    if (cid.version === 0 && source[0] !== "Q") {
      throw Error("Version 0 CID string must not include multibase prefix");
    }
    baseCache4(cid).set(prefix, source);
    return cid;
  }
};
function parseCIDtoBytes4(source, base5) {
  switch (source[0]) {
    // CIDv0 is parsed differently
    case "Q": {
      const decoder = base5 ?? base58btc4;
      return [
        base58btc4.prefix,
        decoder.decode(`${base58btc4.prefix}${source}`)
      ];
    }
    case base58btc4.prefix: {
      const decoder = base5 ?? base58btc4;
      return [base58btc4.prefix, decoder.decode(source)];
    }
    case base324.prefix: {
      const decoder = base5 ?? base324;
      return [base324.prefix, decoder.decode(source)];
    }
    case base364.prefix: {
      const decoder = base5 ?? base364;
      return [base364.prefix, decoder.decode(source)];
    }
    default: {
      if (base5 == null) {
        throw Error("To parse non base32, base36 or base58btc encoded CID multibase decoder must be provided");
      }
      return [source[0], base5.decode(source)];
    }
  }
}
function toStringV04(bytes, cache5, base5) {
  const { prefix } = base5;
  if (prefix !== base58btc4.prefix) {
    throw Error(`Cannot string encode V0 in ${base5.name} encoding`);
  }
  const cid = cache5.get(prefix);
  if (cid == null) {
    const cid2 = base5.encode(bytes).slice(1);
    cache5.set(prefix, cid2);
    return cid2;
  } else {
    return cid;
  }
}
function toStringV14(bytes, cache5, base5) {
  const { prefix } = base5;
  const cid = cache5.get(prefix);
  if (cid == null) {
    const cid2 = base5.encode(bytes);
    cache5.set(prefix, cid2);
    return cid2;
  } else {
    return cid;
  }
}
var DAG_PB_CODE4 = 112;
var SHA_256_CODE4 = 18;
function encodeCID4(version, code9, multihash) {
  const codeOffset = encodingLength4(version);
  const hashOffset = codeOffset + encodingLength4(code9);
  const bytes = new Uint8Array(hashOffset + multihash.byteLength);
  encodeTo4(version, bytes, 0);
  encodeTo4(code9, bytes, codeOffset);
  bytes.set(multihash, hashOffset);
  return bytes;
}
var cidSymbol4 = Symbol.for("@ipld/js-cid/CID");

// node_modules/@helia/unixfs/node_modules/multiformats/dist/src/hashes/hasher.js
function from7({ name: name3, code: code9, encode: encode12 }) {
  return new Hasher3(name3, code9, encode12);
}
var Hasher3 = class {
  name;
  code;
  encode;
  constructor(name3, code9, encode12) {
    this.name = name3;
    this.code = code9;
    this.encode = encode12;
  }
  digest(input) {
    if (input instanceof Uint8Array) {
      const result = this.encode(input);
      return result instanceof Uint8Array ? create5(this.code, result) : result.then((digest2) => create5(this.code, digest2));
    } else {
      throw Error("Unknown type, must be binary type");
    }
  }
};

// node_modules/@helia/unixfs/node_modules/multiformats/dist/src/hashes/sha2-browser.js
function sha2(name3) {
  return async (data) => new Uint8Array(await crypto.subtle.digest(name3, data));
}
var sha2562 = from7({
  name: "sha2-256",
  code: 18,
  encode: sha2("SHA-256")
});
var sha5122 = from7({
  name: "sha2-512",
  code: 19,
  encode: sha2("SHA-512")
});

// node_modules/@helia/unixfs/dist/src/commands/utils/add-link.js
var import_sparse_array3 = __toESM(require_sparse_array(), 1);

// node_modules/@helia/unixfs/dist/src/commands/utils/consumable-hash.js
function wrapHash2(hashFn2) {
  function hashing(value) {
    if (value instanceof InfiniteHash2) {
      return value;
    } else {
      return new InfiniteHash2(value, hashFn2);
    }
  }
  return hashing;
}
var InfiniteHash2 = class {
  _value;
  _hashFn;
  _depth;
  _availableBits;
  _currentBufferIndex;
  _buffers;
  constructor(value, hashFn2) {
    if (!(value instanceof Uint8Array)) {
      throw new Error("can only hash Uint8Arrays");
    }
    this._value = value;
    this._hashFn = hashFn2;
    this._depth = -1;
    this._availableBits = 0;
    this._currentBufferIndex = 0;
    this._buffers = [];
  }
  async take(bits) {
    let pendingBits = bits;
    while (this._availableBits < pendingBits) {
      await this._produceMoreBits();
    }
    let result = 0;
    while (pendingBits > 0) {
      const hash = this._buffers[this._currentBufferIndex];
      const available = Math.min(hash.availableBits(), pendingBits);
      const took = hash.take(available);
      result = (result << available) + took;
      pendingBits -= available;
      this._availableBits -= available;
      if (hash.availableBits() === 0) {
        this._currentBufferIndex++;
      }
    }
    return result;
  }
  untake(bits) {
    let pendingBits = bits;
    while (pendingBits > 0) {
      const hash = this._buffers[this._currentBufferIndex];
      const availableForUntake = Math.min(hash.totalBits() - hash.availableBits(), pendingBits);
      hash.untake(availableForUntake);
      pendingBits -= availableForUntake;
      this._availableBits += availableForUntake;
      if (this._currentBufferIndex > 0 && hash.totalBits() === hash.availableBits()) {
        this._depth--;
        this._currentBufferIndex--;
      }
    }
  }
  async _produceMoreBits() {
    this._depth++;
    const value = this._depth > 0 ? concat([this._value, Uint8Array.from([this._depth])]) : this._value;
    const hashValue = await this._hashFn(value);
    const buffer = new ConsumableBuffer2(hashValue);
    this._buffers.push(buffer);
    this._availableBits += buffer.availableBits();
  }
};
var START_MASKS2 = [
  255,
  254,
  252,
  248,
  240,
  224,
  192,
  128
];
var STOP_MASKS2 = [
  1,
  3,
  7,
  15,
  31,
  63,
  127,
  255
];
var ConsumableBuffer2 = class {
  _value;
  _currentBytePos;
  _currentBitPos;
  constructor(value) {
    this._value = value;
    this._currentBytePos = value.length - 1;
    this._currentBitPos = 7;
  }
  availableBits() {
    return this._currentBitPos + 1 + this._currentBytePos * 8;
  }
  totalBits() {
    return this._value.length * 8;
  }
  take(bits) {
    let pendingBits = bits;
    let result = 0;
    while (pendingBits > 0 && this._haveBits()) {
      const byte = this._value[this._currentBytePos];
      const availableBits = this._currentBitPos + 1;
      const taking = Math.min(availableBits, pendingBits);
      const value = byteBitsToInt2(byte, availableBits - taking, taking);
      result = (result << taking) + value;
      pendingBits -= taking;
      this._currentBitPos -= taking;
      if (this._currentBitPos < 0) {
        this._currentBitPos = 7;
        this._currentBytePos--;
      }
    }
    return result;
  }
  untake(bits) {
    this._currentBitPos += bits;
    while (this._currentBitPos > 7) {
      this._currentBitPos -= 8;
      this._currentBytePos += 1;
    }
  }
  _haveBits() {
    return this._currentBytePos >= 0;
  }
};
function byteBitsToInt2(byte, start, length5) {
  const mask = maskFor2(start, length5);
  return (byte & mask) >>> start;
}
function maskFor2(start, length5) {
  return START_MASKS2[start] & STOP_MASKS2[Math.min(length5 + start - 1, 7)];
}

// node_modules/@helia/unixfs/dist/src/commands/utils/hamt-constants.js
var hamtHashCode = BigInt(murmur3128.code);
var hamtBucketBits = 8;
async function hamtHashFn2(buf) {
  return (await murmur3128.encode(buf)).subarray(0, 8).reverse();
}

// node_modules/@helia/unixfs/dist/src/commands/utils/hamt-utils.js
var import_sparse_array2 = __toESM(require_sparse_array(), 1);

// node_modules/@helia/unixfs/dist/src/commands/utils/persist.js
var persist2 = async (buffer, blockstore, options) => {
  if (options.codec == null) {
    options.codec = src_exports;
  }
  const multihash = await sha2562.digest(buffer);
  const cid = CID4.create(options.cidVersion, options.codec.code, multihash);
  await blockstore.put(cid, buffer, {
    ...options,
    signal: options.signal
  });
  return cid;
};

// node_modules/@helia/unixfs/dist/src/commands/utils/dir-sharded.js
var Dir2 = class {
  options;
  root;
  dir;
  path;
  dirty;
  flat;
  parent;
  parentKey;
  unixfs;
  mode;
  mtime;
  cid;
  size;
  nodeSize;
  constructor(props, options) {
    this.options = options ?? {};
    this.root = props.root;
    this.dir = props.dir;
    this.path = props.path;
    this.dirty = props.dirty;
    this.flat = props.flat;
    this.parent = props.parent;
    this.parentKey = props.parentKey;
    this.unixfs = props.unixfs;
    this.mode = props.mode;
    this.mtime = props.mtime;
  }
};
var DirSharded2 = class extends Dir2 {
  _bucket;
  constructor(props, options) {
    super(props, options);
    this._bucket = createHAMT({
      hashFn: hamtHashFn2,
      bits: 8
    });
  }
  async put(name3, value) {
    this.cid = void 0;
    this.size = void 0;
    this.nodeSize = void 0;
    await this._bucket.put(name3, value);
  }
  async get(name3) {
    return this._bucket.get(name3);
  }
  childCount() {
    return this._bucket.leafCount();
  }
  directChildrenCount() {
    return this._bucket.childrenCount();
  }
  onlyChild() {
    return this._bucket.onlyChild();
  }
  async *eachChildSeries() {
    for (const { key, value } of this._bucket.eachLeafSeries()) {
      yield {
        key,
        child: value
      };
    }
  }
  estimateNodeSize() {
    if (this.nodeSize !== void 0) {
      return this.nodeSize;
    }
    this.nodeSize = calculateSize2(this._bucket, this, this.options);
    return this.nodeSize;
  }
  async *flush(blockstore) {
    for await (const entry of flush2(this._bucket, blockstore, this, this.options)) {
      yield {
        ...entry,
        path: this.path
      };
    }
  }
};
async function* flush2(bucket, blockstore, shardRoot, options) {
  const children = bucket._children;
  const links = [];
  let childrenSize = 0n;
  for (let i = 0; i < children.length; i++) {
    const child = children.get(i);
    if (child == null) {
      continue;
    }
    const labelPrefix = i.toString(16).toUpperCase().padStart(2, "0");
    if (child instanceof Bucket) {
      let shard;
      for await (const subShard of flush2(child, blockstore, null, options)) {
        shard = subShard;
      }
      if (shard == null) {
        throw new Error("Could not flush sharded directory, no sub-shard found");
      }
      links.push({
        Name: labelPrefix,
        Tsize: Number(shard.size),
        Hash: shard.cid
      });
      childrenSize += shard.size;
    } else if (isDir2(child.value)) {
      const dir2 = child.value;
      let flushedDir;
      for await (const entry of dir2.flush(blockstore)) {
        flushedDir = entry;
        yield flushedDir;
      }
      if (flushedDir == null) {
        throw new Error("Did not flush dir");
      }
      const label = labelPrefix + child.key;
      links.push({
        Name: label,
        Tsize: Number(flushedDir.size),
        Hash: flushedDir.cid
      });
      childrenSize += flushedDir.size;
    } else {
      const value = child.value;
      if (value.cid == null) {
        continue;
      }
      const label = labelPrefix + child.key;
      const size2 = value.size;
      links.push({
        Name: label,
        Tsize: Number(size2),
        Hash: value.cid
      });
      childrenSize += BigInt(size2 ?? 0);
    }
  }
  const data = Uint8Array.from(children.bitField().reverse());
  const dir = new UnixFS({
    type: "hamt-sharded-directory",
    data,
    fanout: BigInt(bucket.tableSize()),
    hashType: hamtHashCode,
    mtime: shardRoot?.mtime,
    mode: shardRoot?.mode
  });
  const node = {
    Data: dir.marshal(),
    Links: links
  };
  const buffer = encode(prepare(node));
  const cid = await persist2(buffer, blockstore, options);
  const size = BigInt(buffer.byteLength) + childrenSize;
  yield {
    cid,
    unixfs: dir,
    size
  };
}
function isDir2(obj) {
  return typeof obj.flush === "function";
}
function calculateSize2(bucket, shardRoot, options) {
  const children = bucket._children;
  const links = [];
  for (let i = 0; i < children.length; i++) {
    const child = children.get(i);
    if (child == null) {
      continue;
    }
    const labelPrefix = i.toString(16).toUpperCase().padStart(2, "0");
    if (child instanceof Bucket) {
      const size = calculateSize2(child, null, options);
      links.push({
        Name: labelPrefix,
        Tsize: Number(size),
        Hash: options.cidVersion === 0 ? CID_V02 : CID_V12
      });
    } else if (typeof child.value.flush === "function") {
      const dir2 = child.value;
      const size = dir2.nodeSize();
      links.push({
        Name: labelPrefix + child.key,
        Tsize: Number(size),
        Hash: options.cidVersion === 0 ? CID_V02 : CID_V12
      });
    } else {
      const value = child.value;
      if (value.cid == null) {
        continue;
      }
      const label = labelPrefix + child.key;
      const size = value.size;
      links.push({
        Name: label,
        Tsize: Number(size),
        Hash: value.cid
      });
    }
  }
  const data = Uint8Array.from(children.bitField().reverse());
  const dir = new UnixFS({
    type: "hamt-sharded-directory",
    data,
    fanout: BigInt(bucket.tableSize()),
    hashType: hamtHashCode,
    mtime: shardRoot?.mtime,
    mode: shardRoot?.mode
  });
  const buffer = encode(prepare({
    Data: dir.marshal(),
    Links: links
  }));
  return buffer.length;
}
var CID_V02 = CID4.parse("QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn");
var CID_V12 = CID4.parse("zdj7WbTaiJT1fgatdet9Ei9iDB5hdCxkbVyhyh8YTUnXMiwYi");

// node_modules/@helia/unixfs/dist/src/commands/utils/hamt-utils.js
var log = logger("helia:unixfs:commands:utils:hamt-utils");
var toPrefix2 = (position) => {
  return position.toString(16).toUpperCase().padStart(2, "0").substring(0, 2);
};
var createShard = async (blockstore, contents, options) => {
  const shard = new DirSharded2({
    root: true,
    dir: true,
    parent: void 0,
    parentKey: void 0,
    path: "",
    dirty: true,
    flat: false,
    mtime: options.mtime,
    mode: options.mode
  }, options);
  for (let i = 0; i < contents.length; i++) {
    await shard._bucket.put(contents[i].name, {
      size: contents[i].size,
      cid: contents[i].cid
    });
  }
  const res = await src_default6(shard.flush(blockstore));
  if (res == null) {
    throw new Error("Flushing shard yielded no result");
  }
  return res;
};
var updateShardedDirectory = async (path, blockstore, options) => {
  const shardRoot = UnixFS.unmarshal(path[0].node.Data ?? new Uint8Array(0));
  const fanout = BigInt(Math.pow(2, hamtBucketBits));
  path.reverse();
  let cid;
  let node;
  for (let i = 0; i < path.length; i++) {
    const isRoot = i === path.length - 1;
    const segment = path[i];
    const data = Uint8Array.from(segment.children.bitField().reverse());
    const dir = new UnixFS({
      type: "hamt-sharded-directory",
      data,
      fanout,
      hashType: hamtHashCode
    });
    if (isRoot) {
      dir.mtime = shardRoot.mtime;
      dir.mode = shardRoot.mode;
    }
    node = {
      Data: dir.marshal(),
      Links: segment.node.Links
    };
    const block = encode(prepare(node));
    cid = await persist2(block, blockstore, options);
    if (!isRoot) {
      const nextSegment = path[i + 1];
      if (nextSegment == null) {
        throw new Error("Was not operating on shard root but also had no parent?");
      }
      log("updating link in parent sub-shard with prefix %s", nextSegment.prefix);
      nextSegment.node.Links = nextSegment.node.Links.filter((l) => l.Name !== nextSegment.prefix);
      nextSegment.node.Links.push({
        Name: nextSegment.prefix,
        Hash: cid,
        Tsize: segment.node.Links.reduce((acc, curr) => acc + (curr.Tsize ?? 0), block.byteLength)
      });
    }
  }
  if (cid == null || node == null) {
    throw new Error("Noting persisted");
  }
  return { cid, node };
};
var recreateShardedDirectory = async (cid, fileName, blockstore, options) => {
  const wrapped = wrapHash2(hamtHashFn2);
  const hash = wrapped(fromString(fileName));
  const path = [];
  while (true) {
    const block = await blockstore.get(cid, options);
    const node = decode3(block);
    const children = new import_sparse_array2.default();
    const index = await hash.take(hamtBucketBits);
    const prefix = toPrefix2(index);
    path.push({
      prefix,
      children,
      node
    });
    let childLink;
    for (const link of node.Links) {
      const linkName2 = link.Name ?? "";
      if (linkName2.length < 2) {
        throw new Error("Invalid HAMT - link name was too short");
      }
      const position = parseInt(linkName2.substring(0, 2), 16);
      children.set(position, true);
      if (linkName2.startsWith(prefix)) {
        childLink = link;
      }
    }
    if (childLink == null) {
      log("no link found with prefix %s for %s", prefix, fileName);
      break;
    }
    const linkName = childLink.Name ?? "";
    if (linkName.length < 2) {
      throw new Error("Invalid HAMT - link name was too short");
    }
    if (linkName.length === 2) {
      cid = childLink.Hash;
      log("descend into sub-shard with prefix %s", linkName);
      continue;
    }
    break;
  }
  return { path, hash };
};

// node_modules/@helia/unixfs/dist/src/commands/utils/is-over-shard-threshold.js
async function isOverShardThreshold(node, blockstore, threshold, options) {
  if (node.Data == null) {
    throw new Error("DagPB node had no data");
  }
  const unixfs2 = UnixFS.unmarshal(node.Data);
  let size;
  if (unixfs2.type === "directory") {
    size = estimateNodeSize(node);
  } else if (unixfs2.type === "hamt-sharded-directory") {
    size = await estimateShardSize(node, 0, threshold, blockstore, options);
  } else {
    throw new Error("Can only estimate the size of directories or shards");
  }
  return size > threshold;
}
function estimateNodeSize(node) {
  let size = 0;
  for (const link of node.Links) {
    size += (link.Name ?? "").length;
    size += link.Hash.version === 1 ? CID_V12.bytes.byteLength : CID_V02.bytes.byteLength;
  }
  return size;
}
async function estimateShardSize(node, current, max, blockstore, options) {
  if (current > max) {
    return max;
  }
  if (node.Data == null) {
    return current;
  }
  const unixfs2 = UnixFS.unmarshal(node.Data);
  if (!unixfs2.isDirectory()) {
    return current;
  }
  for (const link of node.Links) {
    let name3 = link.Name ?? "";
    name3 = name3.substring(2);
    current += name3.length;
    current += link.Hash.bytes.byteLength;
    if (link.Hash.code === code3) {
      const block = await blockstore.get(link.Hash, options);
      const node2 = decode3(block);
      current += await estimateShardSize(node2, current, max, blockstore, options);
    }
  }
  return current;
}

// node_modules/@helia/unixfs/dist/src/commands/utils/add-link.js
var log2 = logger("helia:unixfs:components:utils:add-link");
async function addLink(parent, child, blockstore, options) {
  if (parent.node.Data == null) {
    throw new InvalidParametersError2("Invalid parent passed to addLink");
  }
  const meta = UnixFS.unmarshal(parent.node.Data);
  if (meta.type === "hamt-sharded-directory") {
    log2("adding link to sharded directory");
    return addToShardedDirectory(parent, child, blockstore, options);
  }
  log2(`adding ${child.Name} (${child.Hash}) to regular directory`);
  const result = await addToDirectory(parent, child, blockstore, options);
  if (await isOverShardThreshold(result.node, blockstore, options.shardSplitThresholdBytes, options)) {
    log2("converting directory to sharded directory");
    const converted = await convertToShardedDirectory(result, blockstore);
    result.cid = converted.cid;
    result.node = decode3(await blockstore.get(converted.cid, options));
  }
  return result;
}
var convertToShardedDirectory = async (parent, blockstore) => {
  if (parent.node.Data == null) {
    throw new InvalidParametersError2("Invalid parent passed to convertToShardedDirectory");
  }
  const unixfs2 = UnixFS.unmarshal(parent.node.Data);
  const result = await createShard(blockstore, parent.node.Links.map((link) => ({
    name: link.Name ?? "",
    size: BigInt(link.Tsize ?? 0),
    cid: link.Hash
  })), {
    mode: unixfs2.mode,
    mtime: unixfs2.mtime,
    cidVersion: parent.cid.version
  });
  log2(`converted directory to sharded directory ${result.cid}`);
  return result;
};
var addToDirectory = async (parent, child, blockstore, options) => {
  const parentLinks = parent.node.Links.filter((link) => {
    const matches = link.Name === child.Name;
    if (matches && !options.allowOverwriting) {
      throw new AlreadyExistsError();
    }
    return !matches;
  });
  parentLinks.push(child);
  if (parent.node.Data == null) {
    throw new InvalidPBNodeError("Parent node with no data passed to addToDirectory");
  }
  const node = UnixFS.unmarshal(parent.node.Data);
  let data;
  if (node.mtime != null) {
    const ms = Date.now();
    const secs = Math.floor(ms / 1e3);
    node.mtime = {
      secs: BigInt(secs),
      nsecs: (ms - secs * 1e3) * 1e3
    };
    data = node.marshal();
  } else {
    data = parent.node.Data;
  }
  parent.node = prepare({
    Data: data,
    Links: parentLinks
  });
  const buf = encode(parent.node);
  const hash = await sha2562.digest(buf);
  const cid = CID4.create(parent.cid.version, code3, hash);
  await blockstore.put(cid, buf);
  return {
    node: parent.node,
    cid
  };
};
var addToShardedDirectory = async (parent, child, blockstore, options) => {
  const { path, hash } = await recreateShardedDirectory(parent.cid, child.Name, blockstore, options);
  const finalSegment = path[path.length - 1];
  if (finalSegment == null) {
    throw new Error("Invalid HAMT, could not generate path");
  }
  const prefix = finalSegment.prefix;
  const index = parseInt(prefix, 16);
  log2("next prefix for %s is %s", child.Name, prefix);
  const linkName = `${prefix}${child.Name}`;
  const existingLink = finalSegment.node.Links.find((l) => (l.Name ?? "").startsWith(prefix));
  if (existingLink != null) {
    log2("link %s was present in shard", linkName);
    if (existingLink.Name === linkName) {
      if (!options.allowOverwriting) {
        throw new AlreadyExistsError();
      }
      log2("overwriting %s in sub-shard", child.Name);
      finalSegment.node.Links = finalSegment.node.Links.filter((l) => l.Name !== linkName);
      finalSegment.node.Links.push({
        Name: linkName,
        Hash: child.Hash,
        Tsize: child.Tsize
      });
    } else if (existingLink.Name?.length === 2) {
      throw new Error("Existing link was sub-shard?!");
    } else {
      log2("prefix %s already exists, creating new sub-shard", prefix);
      const index2 = finalSegment.node.Links.findIndex((l) => l.Name?.startsWith(prefix));
      const sibling = finalSegment.node.Links.splice(index2, 1)[0];
      const siblingName = (sibling.Name ?? "").substring(2);
      const wrapped = wrapHash2(hamtHashFn2);
      const siblingHash = wrapped(fromString(siblingName));
      for (let i = 0; i < path.length; i++) {
        await siblingHash.take(hamtBucketBits);
      }
      while (true) {
        const siblingIndex = await siblingHash.take(hamtBucketBits);
        const siblingPrefix = toPrefix2(siblingIndex);
        sibling.Name = `${siblingPrefix}${siblingName}`;
        const newIndex = await hash.take(hamtBucketBits);
        const newPrefix = toPrefix2(newIndex);
        if (siblingPrefix === newPrefix) {
          const children2 = new import_sparse_array3.default();
          children2.set(newIndex, true);
          path.push({
            prefix: newPrefix,
            children: children2,
            node: {
              Links: []
            }
          });
          continue;
        }
        const children = new import_sparse_array3.default();
        children.set(newIndex, true);
        children.set(siblingIndex, true);
        path.push({
          prefix,
          children,
          node: {
            Links: [
              sibling,
              {
                Name: `${newPrefix}${child.Name}`,
                Hash: child.Hash,
                Tsize: child.Tsize
              }
            ]
          }
        });
        break;
      }
    }
  } else {
    log2("link %s was not present in sub-shard", linkName);
    child.Name = linkName;
    finalSegment.node.Links.push(child);
    finalSegment.children.set(index, true);
    log2("adding %s to existing sub-shard", linkName);
  }
  return updateShardedDirectory(path, blockstore, options);
};

// node_modules/@helia/unixfs/dist/src/commands/utils/cid-to-directory.js
async function cidToDirectory(cid, blockstore, options = {}) {
  const entry = await exporter(cid, blockstore, options);
  if (entry.type !== "directory") {
    throw new NotADirectoryError(`${cid.toString()} was not a UnixFS directory`);
  }
  return {
    cid,
    node: entry.node
  };
}

// node_modules/@helia/unixfs/dist/src/commands/utils/cid-to-pblink.js
async function cidToPBLink(cid, name3, blockstore, options) {
  const sourceEntry = await exporter(cid, blockstore, options);
  if (sourceEntry.type !== "directory" && sourceEntry.type !== "file" && sourceEntry.type !== "raw") {
    throw new NotUnixFSError(`${cid.toString()} was not a UnixFS node`);
  }
  return {
    Name: name3,
    Tsize: sourceEntry.node instanceof Uint8Array ? sourceEntry.node.byteLength : dagNodeTsize(sourceEntry.node),
    Hash: cid
  };
}
function dagNodeTsize(node) {
  const linkSizes = node.Links.reduce((acc, curr) => acc + (curr.Tsize ?? 0), 0);
  return encode(node).byteLength + linkSizes;
}

// node_modules/@helia/unixfs/dist/src/commands/utils/resolve.js
var log3 = logger("helia:unixfs:components:utils:resolve");
async function resolve7(cid, path, blockstore, options) {
  if (path == null || path === "") {
    return { cid };
  }
  const p = `/ipfs/${cid}${path == null ? "" : `/${path}`}`;
  const segments = await src_default4(walkPath(p, blockstore, options));
  if (segments.length === 0) {
    throw new DoesNotExistError("Could not find path in directory");
  }
  log3("resolved %s to %c", path, cid);
  return {
    cid: segments[segments.length - 1].cid,
    path,
    segments
  };
}
async function updatePathCids(cid, result, blockstore, options) {
  if (result.segments == null || result.segments.length === 0) {
    return cid;
  }
  let child = result.segments.pop();
  if (child == null) {
    throw new Error("Insufficient segments");
  }
  child.cid = cid;
  result.segments.reverse();
  for (const parent of result.segments) {
    const [directory, pblink] = await Promise.all([
      cidToDirectory(parent.cid, blockstore, options),
      cidToPBLink(child.cid, child.name, blockstore, options)
    ]);
    const result2 = await addLink(directory, pblink, blockstore, {
      ...options,
      allowOverwriting: true,
      cidVersion: cid.version
    });
    cid = result2.cid;
    parent.cid = cid;
    child = parent;
  }
  return cid;
}

// node_modules/@helia/unixfs/dist/src/commands/cat.js
var mergeOptions2 = mergeOptions.bind({ ignoreUndefined: true });
var defaultOptions = {};
async function* cat(cid, blockstore, options = {}) {
  const opts = mergeOptions2(defaultOptions, options);
  const resolved = await resolve7(cid, opts.path, blockstore, opts);
  const result = await exporter(resolved.cid, blockstore, opts);
  if (result.type !== "file" && result.type !== "raw") {
    throw new NotAFileError();
  }
  if (result.content == null) {
    throw new NoContentError();
  }
  yield* result.content(opts);
}

// node_modules/@helia/unixfs/node_modules/multiformats/dist/src/codecs/raw.js
var code8 = 85;

// node_modules/@helia/unixfs/dist/src/commands/utils/constants.js
var SHARD_SPLIT_THRESHOLD_BYTES = 262144;

// node_modules/@helia/unixfs/dist/src/commands/chmod.js
var mergeOptions3 = mergeOptions.bind({ ignoreUndefined: true });
var log4 = logger("helia:unixfs:chmod");
var defaultOptions2 = {
  recursive: false,
  shardSplitThresholdBytes: SHARD_SPLIT_THRESHOLD_BYTES
};
async function chmod(cid, mode, blockstore, options = {}) {
  const opts = mergeOptions3(defaultOptions2, options);
  const resolved = await resolve7(cid, opts.path, blockstore, options);
  log4("chmod %c %d", resolved.cid, mode);
  if (opts.recursive) {
    const root = await pipe(
      async function* () {
        for await (const entry of recursive(resolved.cid, blockstore, options)) {
          let metadata2;
          let links2 = [];
          if (entry.type === "raw") {
            metadata2 = new UnixFS({ type: "file", data: entry.node });
          } else if (entry.type === "file" || entry.type === "directory") {
            metadata2 = entry.unixfs;
            links2 = entry.node.Links;
          } else {
            throw new NotUnixFSError();
          }
          metadata2.mode = mode;
          const node = {
            Data: metadata2.marshal(),
            Links: links2
          };
          yield {
            path: entry.path,
            content: node
          };
        }
      },
      // @ts-expect-error cannot combine progress types
      (source) => importer(source, blockstore, {
        ...opts,
        dagBuilder: async function* (source2, block2) {
          for await (const entry of source2) {
            yield async function() {
              const node = entry.content;
              const buf = encode(node);
              const updatedCid2 = await persist2(buf, block2, {
                ...opts,
                cidVersion: cid.version
              });
              if (node.Data == null) {
                throw new InvalidPBNodeError(`${updatedCid2} had no data`);
              }
              const unixfs2 = UnixFS.unmarshal(node.Data);
              return {
                cid: updatedCid2,
                size: BigInt(buf.length),
                path: entry.path,
                unixfs: unixfs2
              };
            };
          }
        }
      }),
      async (nodes) => src_default6(nodes)
    );
    if (root == null) {
      throw new UnknownError(`Could not chmod ${resolved.cid.toString()}`);
    }
    return updatePathCids(root.cid, resolved, blockstore, opts);
  }
  const block = await blockstore.get(resolved.cid, options);
  let metadata;
  let links = [];
  if (resolved.cid.code === code8) {
    metadata = new UnixFS({ type: "file", data: block });
  } else {
    const node = decode3(block);
    if (node.Data == null) {
      throw new InvalidPBNodeError(`${resolved.cid.toString()} had no data`);
    }
    links = node.Links;
    metadata = UnixFS.unmarshal(node.Data);
  }
  metadata.mode = mode;
  const updatedBlock = encode({
    Data: metadata.marshal(),
    Links: links
  });
  const hash = await sha2562.digest(updatedBlock);
  const updatedCid = CID4.create(resolved.cid.version, code3, hash);
  await blockstore.put(updatedCid, updatedBlock);
  return updatePathCids(updatedCid, resolved, blockstore, opts);
}

// node_modules/@helia/unixfs/dist/src/commands/cp.js
var mergeOptions4 = mergeOptions.bind({ ignoreUndefined: true });
var log5 = logger("helia:unixfs:cp");
var defaultOptions3 = {
  force: false,
  shardSplitThresholdBytes: SHARD_SPLIT_THRESHOLD_BYTES
};
async function cp(source, target, name3, blockstore, options = {}) {
  const opts = mergeOptions4(defaultOptions3, options);
  if (name3.includes("/")) {
    throw new InvalidParametersError2("Name must not have slashes");
  }
  const [directory, pblink] = await Promise.all([
    cidToDirectory(target, blockstore, opts),
    cidToPBLink(source, name3, blockstore, opts)
  ]);
  log5('Adding %c as "%s" to %c', source, name3, target);
  const result = await addLink(directory, pblink, blockstore, {
    allowOverwriting: opts.force,
    cidVersion: target.version,
    ...opts
  });
  return result.cid;
}

// node_modules/@helia/unixfs/dist/src/commands/ls.js
var mergeOptions5 = mergeOptions.bind({ ignoreUndefined: true });
var defaultOptions4 = {};
async function* ls(cid, blockstore, options = {}) {
  const opts = mergeOptions5(defaultOptions4, options);
  const resolved = await resolve7(cid, opts.path, blockstore, opts);
  const result = await exporter(resolved.cid, blockstore);
  if (result.type === "file" || result.type === "raw") {
    yield result;
    return;
  }
  if (result.content == null) {
    throw new NoContentError();
  }
  if (result.type !== "directory") {
    throw new NotADirectoryError();
  }
  yield* result.content({
    offset: options.offset,
    length: options.length
  });
}

// node_modules/@helia/unixfs/dist/src/commands/mkdir.js
var mergeOptions6 = mergeOptions.bind({ ignoreUndefined: true });
var log6 = logger("helia:unixfs:mkdir");
var defaultOptions5 = {
  cidVersion: 1,
  force: false,
  shardSplitThresholdBytes: SHARD_SPLIT_THRESHOLD_BYTES
};
async function mkdir(parentCid, dirname, blockstore, options = {}) {
  const opts = mergeOptions6(defaultOptions5, options);
  if (dirname.includes("/")) {
    throw new InvalidParametersError2("Path must not have slashes");
  }
  const entry = await exporter(parentCid, blockstore, options);
  if (entry.type !== "directory") {
    throw new NotADirectoryError(`${parentCid.toString()} was not a UnixFS directory`);
  }
  log6("creating %s", dirname);
  const metadata = new UnixFS({
    type: "directory",
    mode: opts.mode,
    mtime: opts.mtime
  });
  const node = {
    Data: metadata.marshal(),
    Links: []
  };
  const buf = encode(node);
  const hash = await sha2562.digest(buf);
  const emptyDirCid = CID4.create(opts.cidVersion, code3, hash);
  await blockstore.put(emptyDirCid, buf);
  const [directory, pblink] = await Promise.all([
    cidToDirectory(parentCid, blockstore, opts),
    cidToPBLink(emptyDirCid, dirname, blockstore, opts)
  ]);
  log6("adding empty dir called %s to %c", dirname, parentCid);
  const result = await addLink(directory, pblink, blockstore, {
    ...opts,
    allowOverwriting: opts.force
  });
  return result.cid;
}

// node_modules/@helia/unixfs/dist/src/commands/utils/remove-link.js
var log7 = logger("helia:unixfs:utils:remove-link");
async function removeLink(parent, name3, blockstore, options) {
  if (parent.node.Data == null) {
    throw new InvalidPBNodeError("Parent node had no data");
  }
  const meta = UnixFS.unmarshal(parent.node.Data);
  if (meta.type === "hamt-sharded-directory") {
    log7(`removing ${name3} from sharded directory`);
    const result = await removeFromShardedDirectory(parent, name3, blockstore, options);
    if (!await isOverShardThreshold(result.node, blockstore, options.shardSplitThresholdBytes, options)) {
      log7("converting shard to flat directory %c", parent.cid);
      return convertToFlatDirectory(result, blockstore, options);
    }
    return result;
  }
  log7(`removing link ${name3} regular directory`);
  return removeFromDirectory(parent, name3, blockstore, options);
}
var removeFromDirectory = async (parent, name3, blockstore, options) => {
  parent.node.Links = parent.node.Links.filter((link) => {
    return link.Name !== name3;
  });
  const parentBlock = encode(parent.node);
  const parentCid = await persist2(parentBlock, blockstore, {
    ...options,
    cidVersion: parent.cid.version
  });
  log7(`Updated regular directory ${parentCid}`);
  return {
    node: parent.node,
    cid: parentCid
  };
};
var removeFromShardedDirectory = async (parent, name3, blockstore, options) => {
  const { path } = await recreateShardedDirectory(parent.cid, name3, blockstore, options);
  const finalSegment = path[path.length - 1];
  if (finalSegment == null) {
    throw new Error("Invalid HAMT, could not generate path");
  }
  const linkName = finalSegment.node.Links.filter((l) => (l.Name ?? "").substring(2) === name3).map((l) => l.Name).pop();
  if (linkName == null) {
    throw new Error("File not found");
  }
  const prefix = linkName.substring(0, 2);
  const index = parseInt(prefix, 16);
  finalSegment.node.Links = finalSegment.node.Links.filter((link) => link.Name !== linkName);
  finalSegment.children.unset(index);
  if (finalSegment.node.Links.length === 1) {
    while (true) {
      if (path.length === 1) {
        break;
      }
      const segment = path[path.length - 1];
      if (segment == null || segment.node.Links.length > 1) {
        break;
      }
      path.pop();
      const nextSegment = path[path.length - 1];
      if (nextSegment == null) {
        break;
      }
      const link = segment.node.Links[0];
      nextSegment.node.Links = nextSegment.node.Links.filter((l) => !(l.Name ?? "").startsWith(nextSegment.prefix));
      nextSegment.node.Links.push({
        Hash: link.Hash,
        Name: `${nextSegment.prefix}${(link.Name ?? "").substring(2)}`,
        Tsize: link.Tsize
      });
    }
  }
  return updateShardedDirectory(path, blockstore, options);
};
var convertToFlatDirectory = async (parent, blockstore, options) => {
  if (parent.node.Data == null) {
    throw new InvalidParametersError2("Invalid parent passed to convertToFlatDirectory");
  }
  const rootNode = {
    Links: []
  };
  const dir = await exporter(parent.cid, blockstore);
  if (dir.type !== "directory") {
    throw new Error("Unexpected node type");
  }
  for await (const entry of dir.content()) {
    let tsize = 0;
    if (entry.node instanceof Uint8Array) {
      tsize = entry.node.byteLength;
    } else {
      tsize = encode(entry.node).length;
    }
    rootNode.Links.push({
      Hash: entry.cid,
      Name: entry.name,
      Tsize: tsize
    });
  }
  const oldUnixfs = UnixFS.unmarshal(parent.node.Data);
  rootNode.Data = new UnixFS({ type: "directory", mode: oldUnixfs.mode, mtime: oldUnixfs.mtime }).marshal();
  const block = encode(prepare(rootNode));
  const cid = await persist2(block, blockstore, {
    codec: src_exports,
    cidVersion: parent.cid.version,
    signal: options.signal
  });
  return {
    cid,
    node: rootNode
  };
};

// node_modules/@helia/unixfs/dist/src/commands/rm.js
var mergeOptions7 = mergeOptions.bind({ ignoreUndefined: true });
var log8 = logger("helia:unixfs:rm");
var defaultOptions6 = {
  shardSplitThresholdBytes: SHARD_SPLIT_THRESHOLD_BYTES
};
async function rm(target, name3, blockstore, options = {}) {
  const opts = mergeOptions7(defaultOptions6, options);
  if (name3.includes("/")) {
    throw new InvalidParametersError2("Name must not have slashes");
  }
  const directory = await cidToDirectory(target, blockstore, opts);
  log8("Removing %s from %c", name3, target);
  const result = await removeLink(directory, name3, blockstore, {
    ...opts,
    cidVersion: target.version
  });
  return result.cid;
}

// node_modules/@helia/unixfs/dist/src/commands/stat.js
var DEFAULT_DIR_MODE = 1877;
var DEFAULT_FILE_MODE2 = 1604;
var mergeOptions8 = mergeOptions.bind({ ignoreUndefined: true });
var log9 = logger("helia:unixfs:stat");
var defaultOptions7 = {};
async function stat(cid, blockstore, options = {}) {
  const opts = mergeOptions8(defaultOptions7, options);
  const resolved = await resolve7(cid, options.path, blockstore, opts);
  log9("stat %c", resolved.cid);
  const result = await exporter(resolved.cid, blockstore, opts);
  if (result.type === "raw") {
    if (options.extended === true) {
      return createExtendedRawStats(result);
    }
    return createRawStats(result);
  } else if (result.type === "file" || result.type === "directory") {
    if (options.extended === true) {
      return createExtendedStats(result, blockstore, options.filter ?? new ScalableCuckooFilter({ filterSize: 1024 }), options);
    }
    return createStats(result);
  }
  throw new NotUnixFSError();
}
function createStats(entry) {
  return {
    type: entry.type,
    cid: entry.cid,
    unixfs: entry.unixfs,
    mode: entry.unixfs.mode ?? (entry.unixfs.isDirectory() ? DEFAULT_DIR_MODE : DEFAULT_FILE_MODE2),
    mtime: entry.unixfs.mtime,
    size: entry.unixfs.fileSize()
  };
}
async function createExtendedStats(entry, blockstore, filter, options) {
  const stats = await inspectDag(entry.cid, blockstore, false, filter, options);
  return {
    type: entry.type,
    cid: entry.cid,
    unixfs: entry.unixfs,
    size: entry.unixfs.isDirectory() ? stats.dirSize : entry.unixfs.fileSize(),
    mode: entry.unixfs.mode ?? (entry.unixfs.isDirectory() ? DEFAULT_DIR_MODE : DEFAULT_FILE_MODE2),
    mtime: entry.unixfs.mtime,
    localSize: stats.localSize,
    dagSize: stats.dagSize,
    deduplicatedDagSize: stats.deduplicatedDagSize,
    blocks: stats.blocks,
    uniqueBlocks: stats.uniqueBlocks
  };
}
function createRawStats(entry) {
  return {
    type: entry.type,
    cid: entry.cid,
    unixfs: void 0,
    mode: DEFAULT_FILE_MODE2,
    mtime: void 0,
    size: BigInt(entry.node.byteLength)
  };
}
function createExtendedRawStats(entry) {
  return {
    type: entry.type,
    cid: entry.cid,
    unixfs: void 0,
    mode: DEFAULT_FILE_MODE2,
    mtime: void 0,
    size: BigInt(entry.node.byteLength),
    localSize: BigInt(entry.node.byteLength),
    dagSize: BigInt(entry.node.byteLength),
    deduplicatedDagSize: BigInt(entry.node.byteLength),
    blocks: 1n,
    uniqueBlocks: 1n
  };
}
async function inspectDag(cid, blockstore, isFile, filter, options) {
  const results = {
    dirSize: 0n,
    localSize: 0n,
    dagSize: 0n,
    deduplicatedDagSize: 0n,
    blocks: 0n,
    uniqueBlocks: 0n
  };
  try {
    const alreadyTraversed = filter.has(cid.bytes);
    filter.add(cid.bytes);
    const block = await blockstore.get(cid, options);
    results.blocks++;
    results.dagSize += BigInt(block.byteLength);
    if (!alreadyTraversed) {
      results.uniqueBlocks++;
      results.deduplicatedDagSize += BigInt(block.byteLength);
    }
    if (cid.code === code8) {
      results.localSize += BigInt(block.byteLength);
      if (isFile) {
        results.dirSize += BigInt(block.byteLength);
      }
    } else if (cid.code === code3) {
      const pbNode = decode3(block);
      let unixfs2;
      if (pbNode.Data != null) {
        unixfs2 = UnixFS.unmarshal(pbNode.Data);
      }
      if (pbNode.Links.length > 0) {
        for (const link of pbNode.Links) {
          const linkResult = await inspectDag(link.Hash, blockstore, linkIsFile(link, unixfs2), filter, options);
          results.localSize += linkResult.localSize;
          results.dagSize += linkResult.dagSize;
          results.deduplicatedDagSize += linkResult.deduplicatedDagSize;
          results.blocks += linkResult.blocks;
          results.uniqueBlocks += linkResult.uniqueBlocks;
          results.dirSize += linkResult.dirSize;
        }
        if (isFile && unixfs2 != null) {
          results.dirSize += unixfs2.fileSize();
        }
      } else {
        if (unixfs2 == null) {
          throw new InvalidPBNodeError(`PBNode ${cid.toString()} had no data`);
        }
        if (unixfs2.data != null) {
          results.localSize += BigInt(unixfs2.data.byteLength ?? 0);
        }
        if (isFile) {
          results.dirSize += unixfs2.fileSize();
        }
      }
    } else {
      throw new UnknownError(`${cid.toString()} was neither DAG_PB nor RAW`);
    }
  } catch (err) {
    if (err.name !== "NotFoundError" || options.offline !== true) {
      throw err;
    }
  }
  return results;
}
function linkIsFile(link, parent) {
  if (parent == null) {
    return false;
  }
  const name3 = link.Name;
  if (name3 == null) {
    return false;
  }
  if (parent.type === "directory") {
    return true;
  } else if (parent.type === "hamt-sharded-directory" && name3.length > 2) {
    return true;
  }
  return false;
}

// node_modules/@helia/unixfs/dist/src/commands/touch.js
var mergeOptions9 = mergeOptions.bind({ ignoreUndefined: true });
var log10 = logger("helia:unixfs:touch");
var defaultOptions8 = {
  recursive: false,
  shardSplitThresholdBytes: SHARD_SPLIT_THRESHOLD_BYTES
};
async function touch(cid, blockstore, options = {}) {
  const opts = mergeOptions9(defaultOptions8, options);
  const resolved = await resolve7(cid, opts.path, blockstore, opts);
  const mtime = opts.mtime ?? {
    secs: BigInt(Math.round(Date.now() / 1e3)),
    nsecs: 0
  };
  log10("touch %c %o", resolved.cid, mtime);
  if (opts.recursive) {
    const root = await pipe(
      async function* () {
        for await (const entry of recursive(resolved.cid, blockstore)) {
          let metadata2;
          let links2;
          if (entry.type === "raw") {
            metadata2 = new UnixFS({ data: entry.node });
            links2 = [];
          } else if (entry.type === "file" || entry.type === "directory") {
            metadata2 = entry.unixfs;
            links2 = entry.node.Links;
          } else {
            throw new NotUnixFSError();
          }
          metadata2.mtime = mtime;
          const node = {
            Data: metadata2.marshal(),
            Links: links2
          };
          yield {
            path: entry.path,
            content: node
          };
        }
      },
      // @ts-expect-error blockstore types are incompatible
      (source) => importer(source, blockstore, {
        ...opts,
        dagBuilder: async function* (source2, block2) {
          for await (const entry of source2) {
            yield async function() {
              const node = entry.content;
              const buf = encode(node);
              const updatedCid2 = await persist2(buf, block2, {
                ...opts,
                cidVersion: cid.version
              });
              if (node.Data == null) {
                throw new InvalidPBNodeError(`${updatedCid2} had no data`);
              }
              const unixfs2 = UnixFS.unmarshal(node.Data);
              return {
                cid: updatedCid2,
                size: BigInt(buf.length),
                path: entry.path,
                unixfs: unixfs2
              };
            };
          }
        }
      }),
      async (nodes) => src_default6(nodes)
    );
    if (root == null) {
      throw new UnknownError(`Could not chmod ${resolved.cid.toString()}`);
    }
    return updatePathCids(root.cid, resolved, blockstore, opts);
  }
  const block = await blockstore.get(resolved.cid, options);
  let metadata;
  let links = [];
  if (resolved.cid.code === code8) {
    metadata = new UnixFS({ data: block });
  } else {
    const node = decode3(block);
    links = node.Links;
    if (node.Data == null) {
      throw new InvalidPBNodeError(`${resolved.cid.toString()} had no data`);
    }
    metadata = UnixFS.unmarshal(node.Data);
  }
  metadata.mtime = mtime;
  const updatedBlock = encode({
    Data: metadata.marshal(),
    Links: links
  });
  const hash = await sha2562.digest(updatedBlock);
  const updatedCid = CID4.create(resolved.cid.version, code3, hash);
  await blockstore.put(updatedCid, updatedBlock);
  return updatePathCids(updatedCid, resolved, blockstore, opts);
}

// node_modules/@helia/unixfs/dist/src/unixfs.js
var UnixFS2 = class {
  components;
  constructor(components) {
    this.components = components;
  }
  async *addAll(source, options = {}) {
    yield* addAll(source, this.components.blockstore, options);
  }
  async addBytes(bytes, options = {}) {
    return addBytes(bytes, this.components.blockstore, options);
  }
  async addByteStream(bytes, options = {}) {
    return addByteStream(bytes, this.components.blockstore, options);
  }
  async addFile(file, options = {}) {
    return addFile(file, this.components.blockstore, options);
  }
  async addDirectory(dir = {}, options = {}) {
    return addDirectory(dir, this.components.blockstore, options);
  }
  async *cat(cid, options = {}) {
    yield* cat(cid, this.components.blockstore, options);
  }
  async chmod(cid, mode, options = {}) {
    return chmod(cid, mode, this.components.blockstore, options);
  }
  async cp(source, target, name3, options = {}) {
    return cp(source, target, name3, this.components.blockstore, options);
  }
  async *ls(cid, options = {}) {
    yield* ls(cid, this.components.blockstore, options);
  }
  async mkdir(cid, dirname, options = {}) {
    return mkdir(cid, dirname, this.components.blockstore, options);
  }
  async rm(cid, path, options = {}) {
    return rm(cid, path, this.components.blockstore, options);
  }
  async stat(cid, options = {}) {
    return stat(cid, this.components.blockstore, options);
  }
  async touch(cid, options = {}) {
    return touch(cid, this.components.blockstore, options);
  }
};

// node_modules/@helia/unixfs/dist/src/utils/glob-source.browser.js
async function* globSource() {
  throw new Error("Not supported in browsers");
}

// node_modules/@helia/unixfs/dist/src/utils/url-source.js
function urlSource(url, options) {
  url = new URL(url);
  return {
    path: decodeURIComponent(new URL(url).pathname.split("/").pop() ?? ""),
    content: readURLContent(url, options)
  };
}
async function* readURLContent(url, options) {
  const response = await globalThis.fetch(url, options);
  if (response.body == null) {
    throw new UnknownError("HTTP response did not have a body");
  }
  const reader = response.body.getReader();
  try {
    while (true) {
      const { done, value } = await reader.read();
      if (done) {
        return;
      }
      if (value != null) {
        yield value;
      }
    }
  } finally {
    reader.releaseLock();
  }
}

// node_modules/@helia/unixfs/dist/src/index.js
function unixfs(helia) {
  return new UnixFS2(helia);
}
export {
  globSource,
  unixfs,
  urlSource
};
//# sourceMappingURL=@helia_unixfs.js.map
